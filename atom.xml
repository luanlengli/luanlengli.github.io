<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>luanlengli&#39;s Blog</title>
  
  <subtitle>“不知道”的五大理由，不读，不查，不试，理解能力差，满脑子想着怎么利用他人</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://luanlengli.github.io/"/>
  <updated>2019-02-11T03:10:52.248Z</updated>
  <id>https://luanlengli.github.io/</id>
  
  <author>
    <name>乱愣黎</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>【施工中】etcd学习笔记</title>
    <link href="https://luanlengli.github.io/2018/12/22/etcd%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0.html"/>
    <id>https://luanlengli.github.io/2018/12/22/etcd学习笔记.html</id>
    <published>2018-12-22T08:49:18.000Z</published>
    <updated>2019-02-11T03:10:52.248Z</updated>
    
    <content type="html"><![CDATA[<h1 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h1><blockquote><ul><li>Etcd 是 CoreOS 推出的分布式一致性键值存储，用于共享配置和服务发现</li><li>Etcd 支持集群模式部署，从而实现自身高可用</li><li>本文以<code>CentOS-7.6</code>和<code>etcd-v3.3.10</code>为例</li></ul></blockquote><h1 id="etcd安装"><a href="#etcd安装" class="headerlink" title="etcd安装"></a>etcd安装</h1><h2 id="二进制文件安装"><a href="#二进制文件安装" class="headerlink" title="二进制文件安装"></a>二进制文件安装</h2><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 下载并解压</span><br><span class="line">wget -q -O - https://github.com/etcd-io/etcd/releases/download/v3.3.10/etcd-v3.3.10-linux-amd64.tar.gz | tar xz</span><br><span class="line"><span class="meta">#</span> 查看解压后的文件</span><br><span class="line">ls etcd-v3.3.10-linux-amd64</span><br><span class="line">Documentation  etcd  etcdctl  README-etcdctl.md  README.md  READMEv2-etcdctl.md</span><br><span class="line"><span class="meta">#</span> 将二进制执行文件移动到/usr/local/bin/</span><br><span class="line">mv etcd-v3.3.10-linux-amd64/etcd etcd-v3.3.10-linux-amd64/etcdctl /usr/local/bin/</span><br></pre></td></tr></table></figure><h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><h4 id="创建用户"><a href="#创建用户" class="headerlink" title="创建用户"></a>创建用户</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">groupadd -r etcd</span><br><span class="line">useradd -r -g etcd -s /bin/false etcd</span><br></pre></td></tr></table></figure><h4 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /var/lib/etcd /etc/etcd/</span><br></pre></td></tr></table></figure><h4 id="配置文件"><a href="#配置文件" class="headerlink" title="配置文件"></a>配置文件</h4><p>创建配置文件etcd.config.yaml，内容如下</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This is the configuration file for the etcd server.</span></span><br><span class="line"><span class="comment"># Human-readable name for this member.</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">'default'</span></span><br><span class="line"><span class="comment"># Path to the data directory.</span></span><br><span class="line"><span class="attr">data-dir:</span> <span class="string">/var/lib/etcd/default.etcd</span></span><br><span class="line"><span class="comment"># Path to the dedicated wal directory.</span></span><br><span class="line"><span class="attr">wal-dir:</span> <span class="string">/var/lib/etcd/wal</span></span><br><span class="line"><span class="comment"># Number of committed transactions to trigger a snapshot to disk.</span></span><br><span class="line"><span class="attr">snapshot-count:</span> <span class="number">10000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) of a heartbeat interval.</span></span><br><span class="line"><span class="attr">heartbeat-interval:</span> <span class="number">100</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for an election to timeout.</span></span><br><span class="line"><span class="attr">election-timeout:</span> <span class="number">1000</span></span><br><span class="line"><span class="comment"># Raise alarms when backend size exceeds the given quota. 0 means use the</span></span><br><span class="line"><span class="comment"># default quota.</span></span><br><span class="line"><span class="attr">quota-backend-bytes:</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># List of comma separated URLs to listen on for peer traffic.</span></span><br><span class="line"><span class="attr">listen-peer-urls:</span> <span class="attr">http://localhost:2380</span></span><br><span class="line"><span class="comment"># List of comma separated URLs to listen on for client traffic.</span></span><br><span class="line"><span class="attr">listen-client-urls:</span> <span class="attr">http://localhost:2379</span></span><br><span class="line"><span class="comment"># Maximum number of snapshot files to retain (0 is unlimited).</span></span><br><span class="line"><span class="attr">max-snapshots:</span> <span class="number">5</span></span><br><span class="line"><span class="comment"># Maximum number of wal files to retain (0 is unlimited).</span></span><br><span class="line"><span class="attr">max-wals:</span> <span class="number">5</span></span><br><span class="line"><span class="comment"># Comma-separated white list of origins for CORS (cross-origin resource sharing).</span></span><br><span class="line"><span class="attr">cors:</span></span><br><span class="line"><span class="comment"># List of this member's peer URLs to advertise to the rest of the cluster.</span></span><br><span class="line"><span class="comment"># The URLs needed to be a comma-separated list.</span></span><br><span class="line"><span class="attr">initial-advertise-peer-urls:</span> <span class="attr">http://localhost:2380</span></span><br><span class="line"><span class="comment"># List of this member's client URLs to advertise to the public.</span></span><br><span class="line"><span class="comment"># The URLs needed to be a comma-separated list.</span></span><br><span class="line"><span class="attr">advertise-client-urls:</span> <span class="attr">http://localhost:2379</span></span><br><span class="line"><span class="comment"># Discovery URL used to bootstrap the cluster.</span></span><br><span class="line"><span class="attr">discovery:</span></span><br><span class="line"><span class="comment"># Valid values include 'exit', 'proxy'</span></span><br><span class="line"><span class="attr">discovery-fallback:</span> <span class="string">'proxy'</span></span><br><span class="line"><span class="comment"># HTTP proxy to use for traffic to discovery service.</span></span><br><span class="line"><span class="attr">discovery-proxy:</span></span><br><span class="line"><span class="comment"># DNS domain used to bootstrap initial cluster.</span></span><br><span class="line"><span class="attr">discovery-srv:</span></span><br><span class="line"><span class="comment"># Initial cluster configuration for bootstrapping.</span></span><br><span class="line"><span class="attr">initial-cluster:</span></span><br><span class="line"><span class="comment"># Initial cluster token for the etcd cluster during bootstrap.</span></span><br><span class="line"><span class="attr">initial-cluster-token:</span> <span class="string">'etcd-cluster'</span></span><br><span class="line"><span class="comment"># Initial cluster state ('new' or 'existing').</span></span><br><span class="line"><span class="attr">initial-cluster-state:</span> <span class="string">'new'</span></span><br><span class="line"><span class="comment"># Reject reconfiguration requests that would cause quorum loss.</span></span><br><span class="line"><span class="attr">strict-reconfig-check:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># Accept etcd V2 client requests</span></span><br><span class="line"><span class="attr">enable-v2:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Enable runtime profiling data via HTTP server</span></span><br><span class="line"><span class="attr">enable-pprof:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Valid values include 'on', 'readonly', 'off'</span></span><br><span class="line"><span class="attr">proxy:</span> <span class="string">'off'</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) an endpoint will be held in a failed state.</span></span><br><span class="line"><span class="attr">proxy-failure-wait:</span> <span class="number">5000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) of the endpoints refresh interval.</span></span><br><span class="line"><span class="attr">proxy-refresh-interval:</span> <span class="number">30000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for a dial to timeout.</span></span><br><span class="line"><span class="attr">proxy-dial-timeout:</span> <span class="number">1000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for a write to timeout.</span></span><br><span class="line"><span class="attr">proxy-write-timeout:</span> <span class="number">5000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for a read to timeout.</span></span><br><span class="line"><span class="attr">proxy-read-timeout:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">client-transport-security:</span></span><br><span class="line">  <span class="comment"># Path to the client server TLS cert file.</span></span><br><span class="line"><span class="attr">  cert-file:</span></span><br><span class="line">  <span class="comment"># Path to the client server TLS key file.</span></span><br><span class="line"><span class="attr">  key-file:</span></span><br><span class="line">  <span class="comment"># Enable client cert authentication.</span></span><br><span class="line"><span class="attr">  client-cert-auth:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Path to the client server TLS trusted CA cert file.</span></span><br><span class="line"><span class="attr">  trusted-ca-file:</span></span><br><span class="line">  <span class="comment"># Client TLS using generated certificates</span></span><br><span class="line"><span class="attr">  auto-tls:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">peer-transport-security:</span></span><br><span class="line">  <span class="comment"># Path to the peer server TLS cert file.</span></span><br><span class="line"><span class="attr">  cert-file:</span></span><br><span class="line">  <span class="comment"># Path to the peer server TLS key file.</span></span><br><span class="line"><span class="attr">  key-file:</span></span><br><span class="line">  <span class="comment"># Enable peer client cert authentication.</span></span><br><span class="line"><span class="attr">  client-cert-auth:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Path to the peer server TLS trusted CA cert file.</span></span><br><span class="line"><span class="attr">  trusted-ca-file:</span></span><br><span class="line">  <span class="comment"># Peer TLS using generated certificates.</span></span><br><span class="line"><span class="attr">  auto-tls:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># Enable debug-level logging for etcd.</span></span><br><span class="line"><span class="attr">debug:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">logger:</span> <span class="string">zap</span></span><br><span class="line"><span class="comment"># Specify 'stdout' or 'stderr' to skip journald logging even when running under systemd.</span></span><br><span class="line"><span class="attr">log-outputs:</span> <span class="string">[stderr]</span></span><br><span class="line"><span class="comment"># Force to create a new one member cluster.</span></span><br><span class="line"><span class="attr">force-new-cluster:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">auto-compaction-mode:</span> <span class="string">periodic</span></span><br><span class="line"><span class="attr">auto-compaction-retention:</span> <span class="string">"1"</span></span><br></pre></td></tr></table></figure><h4 id="创建服务文件"><a href="#创建服务文件" class="headerlink" title="创建服务文件"></a>创建服务文件</h4><p>使用systemd托管etcd的服务</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /usr/lib/systemd/system/etcd.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=etcd key-value store</span><br><span class="line">Documentation=https://github.com/etcd-io/etcd</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=etcd</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/local/bin/etcd --config-file /etc/etcd/etcd.config.yaml</span><br><span class="line">Restart=always</span><br><span class="line">RestartSec=10s</span><br><span class="line">LimitNOFILE=65535</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="运行etcd"><a href="#运行etcd" class="headerlink" title="运行etcd"></a>运行etcd</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chown -R etcd:etcd /var/lib/etcd /etc/etcd</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl start etcd.service</span><br></pre></td></tr></table></figure><h3 id="验证etcd服务"><a href="#验证etcd服务" class="headerlink" title="验证etcd服务"></a>验证etcd服务</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">etcdctl cluster-health</span><br><span class="line">member 8e9e05c52164694d is healthy: got healthy result from http://localhost:2379</span><br><span class="line">cluster is healthy</span><br></pre></td></tr></table></figure><h1 id="etcd集群部署"><a href="#etcd集群部署" class="headerlink" title="etcd集群部署"></a>etcd集群部署</h1><h2 id="构建集群的方式"><a href="#构建集群的方式" class="headerlink" title="构建集群的方式"></a>构建集群的方式</h2><h3 id="静态发现"><a href="#静态发现" class="headerlink" title="静态发现"></a>静态发现</h3><p>预先已知 Etcd 集群中有哪些节点，在启动时直接指定好 Etcd 的各个 node 节点地址</p><h3 id="动态发现"><a href="#动态发现" class="headerlink" title="动态发现"></a>动态发现</h3><p>通过已有的 Etcd 集群作为数据交互点，然后在扩展新的集群时实现通过已有集群进行服务发现的机制</p><h3 id="DNS动态发现"><a href="#DNS动态发现" class="headerlink" title="DNS动态发现"></a>DNS动态发现</h3><p>通过 DNS 查询方式获取其他节点地址信息</p><h2 id="节点信息"><a href="#节点信息" class="headerlink" title="节点信息"></a>节点信息</h2><font color="red">这里只提供静态发现部署etcd集群的流程</font><table><thead><tr><th style="text-align:center">IP地址</th><th style="text-align:center">主机名</th><th style="text-align:center">CPU</th><th style="text-align:center">内存</th></tr></thead><tbody><tr><td style="text-align:center">172.16.80.201</td><td style="text-align:center">etcd1</td><td style="text-align:center">4</td><td style="text-align:center">8G</td></tr><tr><td style="text-align:center">172.16.80.202</td><td style="text-align:center">etcd2</td><td style="text-align:center">4</td><td style="text-align:center">8G</td></tr><tr><td style="text-align:center">172.16.80.203</td><td style="text-align:center">etcd3</td><td style="text-align:center">4</td><td style="text-align:center">8G</td></tr></tbody></table><h2 id="静态发现部署etcd集群"><a href="#静态发现部署etcd集群" class="headerlink" title="静态发现部署etcd集群"></a>静态发现部署etcd集群</h2><h3 id="创建配置文件"><a href="#创建配置文件" class="headerlink" title="创建配置文件"></a>创建配置文件</h3><h4 id="etcd1"><a href="#etcd1" class="headerlink" title="etcd1"></a>etcd1</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This is the configuration file for the etcd server.</span></span><br><span class="line"><span class="comment"># Human-readable name for this member.</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">'etcd1'</span></span><br><span class="line"><span class="comment"># Path to the data directory.</span></span><br><span class="line"><span class="attr">data-dir:</span> <span class="string">/var/lib/etcd/etcd1.etcd</span></span><br><span class="line"><span class="comment"># Path to the dedicated wal directory.</span></span><br><span class="line"><span class="attr">wal-dir:</span> <span class="string">/var/lib/etcd/wal</span></span><br><span class="line"><span class="comment"># Number of committed transactions to trigger a snapshot to disk.</span></span><br><span class="line"><span class="attr">snapshot-count:</span> <span class="number">10000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) of a heartbeat interval.</span></span><br><span class="line"><span class="attr">heartbeat-interval:</span> <span class="number">100</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for an election to timeout.</span></span><br><span class="line"><span class="attr">election-timeout:</span> <span class="number">1000</span></span><br><span class="line"><span class="comment"># Raise alarms when backend size exceeds the given quota. 0 means use the</span></span><br><span class="line"><span class="comment"># default quota.</span></span><br><span class="line"><span class="attr">quota-backend-bytes:</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># List of comma separated URLs to listen on for peer traffic.</span></span><br><span class="line"><span class="attr">listen-peer-urls:</span> <span class="string">'https://172.16.80.201:2380'</span></span><br><span class="line"><span class="comment"># List of comma separated URLs to listen on for client traffic.</span></span><br><span class="line"><span class="attr">listen-client-urls:</span> <span class="string">'https://172.16.80.201:2379,http://127.0.0.1:2379'</span></span><br><span class="line"><span class="comment"># Maximum number of snapshot files to retain (0 is unlimited).</span></span><br><span class="line"><span class="attr">max-snapshots:</span> <span class="number">5</span></span><br><span class="line"><span class="comment"># Maximum number of wal files to retain (0 is unlimited).</span></span><br><span class="line"><span class="attr">max-wals:</span> <span class="number">5</span></span><br><span class="line"><span class="comment"># Comma-separated white list of origins for CORS (cross-origin resource sharing).</span></span><br><span class="line"><span class="attr">cors:</span></span><br><span class="line"><span class="comment"># List of this member's peer URLs to advertise to the rest of the cluster.</span></span><br><span class="line"><span class="comment"># The URLs needed to be a comma-separated list.</span></span><br><span class="line"><span class="attr">initial-advertise-peer-urls:</span> <span class="string">'https://172.16.80.201:2380'</span></span><br><span class="line"><span class="comment"># List of this member's client URLs to advertise to the public.</span></span><br><span class="line"><span class="comment"># The URLs needed to be a comma-separated list.</span></span><br><span class="line"><span class="attr">advertise-client-urls:</span> <span class="string">'https://172.16.80.201:2379'</span></span><br><span class="line"><span class="comment"># Discovery URL used to bootstrap the cluster.</span></span><br><span class="line"><span class="attr">discovery:</span></span><br><span class="line"><span class="comment"># Valid values include 'exit', 'proxy'</span></span><br><span class="line"><span class="attr">discovery-fallback:</span> <span class="string">'proxy'</span></span><br><span class="line"><span class="comment"># HTTP proxy to use for traffic to discovery service.</span></span><br><span class="line"><span class="attr">discovery-proxy:</span></span><br><span class="line"><span class="comment"># DNS domain used to bootstrap initial cluster.</span></span><br><span class="line"><span class="attr">discovery-srv:</span></span><br><span class="line"><span class="comment"># Initial cluster configuration for bootstrapping.</span></span><br><span class="line"><span class="attr">initial-cluster:</span> <span class="string">'etcd1=http://172.16.80.201:2380,etcd2=http://172.16.80.202:2380,etcd3=http://172.16.80.203:2380'</span></span><br><span class="line"><span class="comment"># Initial cluster token for the etcd cluster during bootstrap.</span></span><br><span class="line"><span class="attr">initial-cluster-token:</span> <span class="string">'etcd-cluster'</span></span><br><span class="line"><span class="comment"># Initial cluster state ('new' or 'existing').</span></span><br><span class="line"><span class="attr">initial-cluster-state:</span> <span class="string">'new'</span></span><br><span class="line"><span class="comment"># Reject reconfiguration requests that would cause quorum loss.</span></span><br><span class="line"><span class="attr">strict-reconfig-check:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># Accept etcd V2 client requests</span></span><br><span class="line"><span class="attr">enable-v2:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Enable runtime profiling data via HTTP server</span></span><br><span class="line"><span class="attr">enable-pprof:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Valid values include 'on', 'readonly', 'off'</span></span><br><span class="line"><span class="attr">proxy:</span> <span class="string">'off'</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) an endpoint will be held in a failed state.</span></span><br><span class="line"><span class="attr">proxy-failure-wait:</span> <span class="number">5000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) of the endpoints refresh interval.</span></span><br><span class="line"><span class="attr">proxy-refresh-interval:</span> <span class="number">30000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for a dial to timeout.</span></span><br><span class="line"><span class="attr">proxy-dial-timeout:</span> <span class="number">1000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for a write to timeout.</span></span><br><span class="line"><span class="attr">proxy-write-timeout:</span> <span class="number">5000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for a read to timeout.</span></span><br><span class="line"><span class="attr">proxy-read-timeout:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">client-transport-security:</span></span><br><span class="line">  <span class="comment"># Path to the client server TLS cert file.</span></span><br><span class="line"><span class="attr">  cert-file:</span></span><br><span class="line">  <span class="comment"># Path to the client server TLS key file.</span></span><br><span class="line"><span class="attr">  key-file:</span></span><br><span class="line">  <span class="comment"># Enable client cert authentication.</span></span><br><span class="line"><span class="attr">  client-cert-auth:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Path to the client server TLS trusted CA cert file.</span></span><br><span class="line"><span class="attr">  trusted-ca-file:</span></span><br><span class="line">  <span class="comment"># Client TLS using generated certificates</span></span><br><span class="line"><span class="attr">  auto-tls:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">peer-transport-security:</span></span><br><span class="line">  <span class="comment"># Path to the peer server TLS cert file.</span></span><br><span class="line"><span class="attr">  cert-file:</span></span><br><span class="line">  <span class="comment"># Path to the peer server TLS key file.</span></span><br><span class="line"><span class="attr">  key-file:</span></span><br><span class="line">  <span class="comment"># Enable peer client cert authentication.</span></span><br><span class="line"><span class="attr">  client-cert-auth:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Path to the peer server TLS trusted CA cert file.</span></span><br><span class="line"><span class="attr">  trusted-ca-file:</span></span><br><span class="line">  <span class="comment"># Peer TLS using generated certificates.</span></span><br><span class="line"><span class="attr">  auto-tls:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># Enable debug-level logging for etcd.</span></span><br><span class="line"><span class="attr">debug:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">logger:</span> <span class="string">zap</span></span><br><span class="line"><span class="comment"># Specify 'stdout' or 'stderr' to skip journald logging even when running under systemd.</span></span><br><span class="line"><span class="attr">log-outputs:</span> <span class="string">[stderr]</span></span><br><span class="line"><span class="comment"># Force to create a new one member cluster.</span></span><br><span class="line"><span class="attr">force-new-cluster:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">auto-compaction-mode:</span> <span class="string">periodic</span></span><br><span class="line"><span class="attr">auto-compaction-retention:</span> <span class="string">"1"</span></span><br></pre></td></tr></table></figure><h4 id="etcd2"><a href="#etcd2" class="headerlink" title="etcd2"></a>etcd2</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This is the configuration file for the etcd server.</span></span><br><span class="line"><span class="comment"># Human-readable name for this member.</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">'etcd2'</span></span><br><span class="line"><span class="comment"># Path to the data directory.</span></span><br><span class="line"><span class="attr">data-dir:</span> <span class="string">/var/lib/etcd/etcd2.etcd</span></span><br><span class="line"><span class="comment"># Path to the dedicated wal directory.</span></span><br><span class="line"><span class="attr">wal-dir:</span> <span class="string">/var/lib/etcd/wal</span></span><br><span class="line"><span class="comment"># Number of committed transactions to trigger a snapshot to disk.</span></span><br><span class="line"><span class="attr">snapshot-count:</span> <span class="number">10000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) of a heartbeat interval.</span></span><br><span class="line"><span class="attr">heartbeat-interval:</span> <span class="number">100</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for an election to timeout.</span></span><br><span class="line"><span class="attr">election-timeout:</span> <span class="number">1000</span></span><br><span class="line"><span class="comment"># Raise alarms when backend size exceeds the given quota. 0 means use the</span></span><br><span class="line"><span class="comment"># default quota.</span></span><br><span class="line"><span class="attr">quota-backend-bytes:</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># List of comma separated URLs to listen on for peer traffic.</span></span><br><span class="line"><span class="attr">listen-peer-urls:</span> <span class="string">'https://172.16.80.202:2380'</span></span><br><span class="line"><span class="comment"># List of comma separated URLs to listen on for client traffic.</span></span><br><span class="line"><span class="attr">listen-client-urls:</span> <span class="string">'https://172.16.80.202:2379,http://127.0.0.1:2379'</span></span><br><span class="line"><span class="comment"># Maximum number of snapshot files to retain (0 is unlimited).</span></span><br><span class="line"><span class="attr">max-snapshots:</span> <span class="number">5</span></span><br><span class="line"><span class="comment"># Maximum number of wal files to retain (0 is unlimited).</span></span><br><span class="line"><span class="attr">max-wals:</span> <span class="number">5</span></span><br><span class="line"><span class="comment"># Comma-separated white list of origins for CORS (cross-origin resource sharing).</span></span><br><span class="line"><span class="attr">cors:</span></span><br><span class="line"><span class="comment"># List of this member's peer URLs to advertise to the rest of the cluster.</span></span><br><span class="line"><span class="comment"># The URLs needed to be a comma-separated list.</span></span><br><span class="line"><span class="attr">initial-advertise-peer-urls:</span> <span class="string">'https://172.16.80.202:2380'</span></span><br><span class="line"><span class="comment"># List of this member's client URLs to advertise to the public.</span></span><br><span class="line"><span class="comment"># The URLs needed to be a comma-separated list.</span></span><br><span class="line"><span class="attr">advertise-client-urls:</span> <span class="string">'https://172.16.80.202:2379'</span></span><br><span class="line"><span class="comment"># Discovery URL used to bootstrap the cluster.</span></span><br><span class="line"><span class="attr">discovery:</span></span><br><span class="line"><span class="comment"># Valid values include 'exit', 'proxy'</span></span><br><span class="line"><span class="attr">discovery-fallback:</span> <span class="string">'proxy'</span></span><br><span class="line"><span class="comment"># HTTP proxy to use for traffic to discovery service.</span></span><br><span class="line"><span class="attr">discovery-proxy:</span></span><br><span class="line"><span class="comment"># DNS domain used to bootstrap initial cluster.</span></span><br><span class="line"><span class="attr">discovery-srv:</span></span><br><span class="line"><span class="comment"># Initial cluster configuration for bootstrapping.</span></span><br><span class="line"><span class="attr">initial-cluster:</span> <span class="string">'etcd1=http://172.16.80.201:2380,etcd2=http://172.16.80.202:2380,etcd3=http://172.16.80.203:2380'</span></span><br><span class="line"><span class="comment"># Initial cluster token for the etcd cluster during bootstrap.</span></span><br><span class="line"><span class="attr">initial-cluster-token:</span> <span class="string">'etcd-cluster'</span></span><br><span class="line"><span class="comment"># Initial cluster state ('new' or 'existing').</span></span><br><span class="line"><span class="attr">initial-cluster-state:</span> <span class="string">'new'</span></span><br><span class="line"><span class="comment"># Reject reconfiguration requests that would cause quorum loss.</span></span><br><span class="line"><span class="attr">strict-reconfig-check:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># Accept etcd V2 client requests</span></span><br><span class="line"><span class="attr">enable-v2:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Enable runtime profiling data via HTTP server</span></span><br><span class="line"><span class="attr">enable-pprof:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Valid values include 'on', 'readonly', 'off'</span></span><br><span class="line"><span class="attr">proxy:</span> <span class="string">'off'</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) an endpoint will be held in a failed state.</span></span><br><span class="line"><span class="attr">proxy-failure-wait:</span> <span class="number">5000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) of the endpoints refresh interval.</span></span><br><span class="line"><span class="attr">proxy-refresh-interval:</span> <span class="number">30000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for a dial to timeout.</span></span><br><span class="line"><span class="attr">proxy-dial-timeout:</span> <span class="number">1000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for a write to timeout.</span></span><br><span class="line"><span class="attr">proxy-write-timeout:</span> <span class="number">5000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for a read to timeout.</span></span><br><span class="line"><span class="attr">proxy-read-timeout:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">client-transport-security:</span></span><br><span class="line">  <span class="comment"># Path to the client server TLS cert file.</span></span><br><span class="line"><span class="attr">  cert-file:</span></span><br><span class="line">  <span class="comment"># Path to the client server TLS key file.</span></span><br><span class="line"><span class="attr">  key-file:</span></span><br><span class="line">  <span class="comment"># Enable client cert authentication.</span></span><br><span class="line"><span class="attr">  client-cert-auth:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Path to the client server TLS trusted CA cert file.</span></span><br><span class="line"><span class="attr">  trusted-ca-file:</span></span><br><span class="line">  <span class="comment"># Client TLS using generated certificates</span></span><br><span class="line"><span class="attr">  auto-tls:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">peer-transport-security:</span></span><br><span class="line">  <span class="comment"># Path to the peer server TLS cert file.</span></span><br><span class="line"><span class="attr">  cert-file:</span></span><br><span class="line">  <span class="comment"># Path to the peer server TLS key file.</span></span><br><span class="line"><span class="attr">  key-file:</span></span><br><span class="line">  <span class="comment"># Enable peer client cert authentication.</span></span><br><span class="line"><span class="attr">  client-cert-auth:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Path to the peer server TLS trusted CA cert file.</span></span><br><span class="line"><span class="attr">  trusted-ca-file:</span></span><br><span class="line">  <span class="comment"># Peer TLS using generated certificates.</span></span><br><span class="line"><span class="attr">  auto-tls:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># Enable debug-level logging for etcd.</span></span><br><span class="line"><span class="attr">debug:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">logger:</span> <span class="string">zap</span></span><br><span class="line"><span class="comment"># Specify 'stdout' or 'stderr' to skip journald logging even when running under systemd.</span></span><br><span class="line"><span class="attr">log-outputs:</span> <span class="string">[stderr]</span></span><br><span class="line"><span class="comment"># Force to create a new one member cluster.</span></span><br><span class="line"><span class="attr">force-new-cluster:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">auto-compaction-mode:</span> <span class="string">periodic</span></span><br><span class="line"><span class="attr">auto-compaction-retention:</span> <span class="string">"1"</span></span><br></pre></td></tr></table></figure><h4 id="etcd3"><a href="#etcd3" class="headerlink" title="etcd3"></a>etcd3</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># This is the configuration file for the etcd server.</span></span><br><span class="line"><span class="comment"># Human-readable name for this member.</span></span><br><span class="line"><span class="attr">name:</span> <span class="string">'etcd3'</span></span><br><span class="line"><span class="comment"># Path to the data directory.</span></span><br><span class="line"><span class="attr">data-dir:</span> <span class="string">/var/lib/etcd/etcd3.etcd</span></span><br><span class="line"><span class="comment"># Path to the dedicated wal directory.</span></span><br><span class="line"><span class="attr">wal-dir:</span> <span class="string">/var/lib/etcd/wal</span></span><br><span class="line"><span class="comment"># Number of committed transactions to trigger a snapshot to disk.</span></span><br><span class="line"><span class="attr">snapshot-count:</span> <span class="number">10000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) of a heartbeat interval.</span></span><br><span class="line"><span class="attr">heartbeat-interval:</span> <span class="number">100</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for an election to timeout.</span></span><br><span class="line"><span class="attr">election-timeout:</span> <span class="number">1000</span></span><br><span class="line"><span class="comment"># Raise alarms when backend size exceeds the given quota. 0 means use the</span></span><br><span class="line"><span class="comment"># default quota.</span></span><br><span class="line"><span class="attr">quota-backend-bytes:</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># List of comma separated URLs to listen on for peer traffic.</span></span><br><span class="line"><span class="attr">listen-peer-urls:</span> <span class="string">'https://172.16.80.203:2380'</span></span><br><span class="line"><span class="comment"># List of comma separated URLs to listen on for client traffic.</span></span><br><span class="line"><span class="attr">listen-client-urls:</span> <span class="string">'https://172.16.80.203:2379,http://127.0.0.1:2379'</span></span><br><span class="line"><span class="comment"># Maximum number of snapshot files to retain (0 is unlimited).</span></span><br><span class="line"><span class="attr">max-snapshots:</span> <span class="number">5</span></span><br><span class="line"><span class="comment"># Maximum number of wal files to retain (0 is unlimited).</span></span><br><span class="line"><span class="attr">max-wals:</span> <span class="number">5</span></span><br><span class="line"><span class="comment"># Comma-separated white list of origins for CORS (cross-origin resource sharing).</span></span><br><span class="line"><span class="attr">cors:</span></span><br><span class="line"><span class="comment"># List of this member's peer URLs to advertise to the rest of the cluster.</span></span><br><span class="line"><span class="comment"># The URLs needed to be a comma-separated list.</span></span><br><span class="line"><span class="attr">initial-advertise-peer-urls:</span> <span class="string">'https://172.16.80.203:2380'</span></span><br><span class="line"><span class="comment"># List of this member's client URLs to advertise to the public.</span></span><br><span class="line"><span class="comment"># The URLs needed to be a comma-separated list.</span></span><br><span class="line"><span class="attr">advertise-client-urls:</span> <span class="string">'https://172.16.80.203:2379'</span></span><br><span class="line"><span class="comment"># Discovery URL used to bootstrap the cluster.</span></span><br><span class="line"><span class="attr">discovery:</span></span><br><span class="line"><span class="comment"># Valid values include 'exit', 'proxy'</span></span><br><span class="line"><span class="attr">discovery-fallback:</span> <span class="string">'proxy'</span></span><br><span class="line"><span class="comment"># HTTP proxy to use for traffic to discovery service.</span></span><br><span class="line"><span class="attr">discovery-proxy:</span></span><br><span class="line"><span class="comment"># DNS domain used to bootstrap initial cluster.</span></span><br><span class="line"><span class="attr">discovery-srv:</span></span><br><span class="line"><span class="comment"># Initial cluster configuration for bootstrapping.</span></span><br><span class="line"><span class="attr">initial-cluster:</span> <span class="string">'etcd1=http://172.16.80.201:2380,etcd2=http://172.16.80.202:2380,etcd3=http://172.16.80.203:2380'</span></span><br><span class="line"><span class="comment"># Initial cluster token for the etcd cluster during bootstrap.</span></span><br><span class="line"><span class="attr">initial-cluster-token:</span> <span class="string">'etcd-cluster'</span></span><br><span class="line"><span class="comment"># Initial cluster state ('new' or 'existing').</span></span><br><span class="line"><span class="attr">initial-cluster-state:</span> <span class="string">'new'</span></span><br><span class="line"><span class="comment"># Reject reconfiguration requests that would cause quorum loss.</span></span><br><span class="line"><span class="attr">strict-reconfig-check:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># Accept etcd V2 client requests</span></span><br><span class="line"><span class="attr">enable-v2:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Enable runtime profiling data via HTTP server</span></span><br><span class="line"><span class="attr">enable-pprof:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># Valid values include 'on', 'readonly', 'off'</span></span><br><span class="line"><span class="attr">proxy:</span> <span class="string">'off'</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) an endpoint will be held in a failed state.</span></span><br><span class="line"><span class="attr">proxy-failure-wait:</span> <span class="number">5000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) of the endpoints refresh interval.</span></span><br><span class="line"><span class="attr">proxy-refresh-interval:</span> <span class="number">30000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for a dial to timeout.</span></span><br><span class="line"><span class="attr">proxy-dial-timeout:</span> <span class="number">1000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for a write to timeout.</span></span><br><span class="line"><span class="attr">proxy-write-timeout:</span> <span class="number">5000</span></span><br><span class="line"><span class="comment"># Time (in milliseconds) for a read to timeout.</span></span><br><span class="line"><span class="attr">proxy-read-timeout:</span> <span class="number">0</span></span><br><span class="line"><span class="attr">client-transport-security:</span></span><br><span class="line">  <span class="comment"># Path to the client server TLS cert file.</span></span><br><span class="line"><span class="attr">  cert-file:</span></span><br><span class="line">  <span class="comment"># Path to the client server TLS key file.</span></span><br><span class="line"><span class="attr">  key-file:</span></span><br><span class="line">  <span class="comment"># Enable client cert authentication.</span></span><br><span class="line"><span class="attr">  client-cert-auth:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Path to the client server TLS trusted CA cert file.</span></span><br><span class="line"><span class="attr">  trusted-ca-file:</span></span><br><span class="line">  <span class="comment"># Client TLS using generated certificates</span></span><br><span class="line"><span class="attr">  auto-tls:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">peer-transport-security:</span></span><br><span class="line">  <span class="comment"># Path to the peer server TLS cert file.</span></span><br><span class="line"><span class="attr">  cert-file:</span></span><br><span class="line">  <span class="comment"># Path to the peer server TLS key file.</span></span><br><span class="line"><span class="attr">  key-file:</span></span><br><span class="line">  <span class="comment"># Enable peer client cert authentication.</span></span><br><span class="line"><span class="attr">  client-cert-auth:</span> <span class="literal">false</span></span><br><span class="line">  <span class="comment"># Path to the peer server TLS trusted CA cert file.</span></span><br><span class="line"><span class="attr">  trusted-ca-file:</span></span><br><span class="line">  <span class="comment"># Peer TLS using generated certificates.</span></span><br><span class="line"><span class="attr">  auto-tls:</span> <span class="literal">false</span></span><br><span class="line"><span class="comment"># Enable debug-level logging for etcd.</span></span><br><span class="line"><span class="attr">debug:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">logger:</span> <span class="string">zap</span></span><br><span class="line"><span class="comment"># Specify 'stdout' or 'stderr' to skip journald logging even when running under systemd.</span></span><br><span class="line"><span class="attr">log-outputs:</span> <span class="string">[stderr]</span></span><br><span class="line"><span class="comment"># Force to create a new one member cluster.</span></span><br><span class="line"><span class="attr">force-new-cluster:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">auto-compaction-mode:</span> <span class="string">periodic</span></span><br><span class="line"><span class="attr">auto-compaction-retention:</span> <span class="string">"1"</span></span><br></pre></td></tr></table></figure><h3 id="启动etcd集群"><a href="#启动etcd集群" class="headerlink" title="启动etcd集群"></a>启动etcd集群</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for NODE in 172.16.80.201 172.16.80.202 172.16.80.203;do</span><br><span class="line">ssh $NODE systemctl enable etcd</span><br><span class="line">ssh $NODE systemctl start etcd &amp;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="检查etcd集群"><a href="#检查etcd集群" class="headerlink" title="检查etcd集群"></a>检查etcd集群</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">export ETCDCTL_API=2</span><br><span class="line">etcdctl --endpoints 'http://172.16.80.201:2379,http://172.16.80.202:2379,http://172.16.80.202:2379' cluster-health</span><br><span class="line">member 222fd3b0bb4a5931 is healthy: got healthy result from http://172.16.80.203:2379</span><br><span class="line">member 8349ef180b115a83 is healthy: got healthy result from http://172.16.80.201:2379</span><br><span class="line">member f525d2d797a7c465 is healthy: got healthy result from http://172.16.80.202:2379</span><br><span class="line">cluster is healthy</span><br><span class="line"></span><br><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl --endpoints='http://172.16.80.201:2379,http://172.16.80.202:2379,http://172.16.80.202:2379' endpoint health</span><br><span class="line">http://172.16.80.201:2379 is healthy: successfully committed proposal: took = 2.879402ms</span><br><span class="line">http://172.16.80.203:2379 is healthy: successfully committed proposal: took = 6.708566ms</span><br><span class="line">http://172.16.80.202:2379 is healthy: successfully committed proposal: took = 7.187607ms</span><br></pre></td></tr></table></figure><h1 id="SSL-TLS加密"><a href="#SSL-TLS加密" class="headerlink" title="SSL/TLS加密"></a>SSL/TLS加密</h1><p>此段翻译自<a href="https://coreos.com/etcd/docs/latest/op-guide/security.html" target="_blank" rel="noopener">官方文档</a></p><p>etcd支持自动TLS、客户端证书身份认证、客户端到服务器端以及对等集群的加密通信</p><h2 id="生成证书"><a href="#生成证书" class="headerlink" title="生成证书"></a>生成证书</h2><p>为方便起见，这里使用<code>CFSSL</code>工具生成证书</p><h3 id="下载CFSSL"><a href="#下载CFSSL" class="headerlink" title="下载CFSSL"></a>下载CFSSL</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">mkdir ~/bin</span><br><span class="line">curl -s -L -o ~/bin/cfssl https://pkg.cfssl.org/R1.2/cfssl_linux-amd64</span><br><span class="line">curl -s -L -o ~/bin/cfssljson https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64</span><br><span class="line">chmod +x ~/bin/&#123;cfssl,cfssljson&#125;</span><br><span class="line">export PATH=$PATH:~/bin</span><br></pre></td></tr></table></figure><h3 id="创建工作目录"><a href="#创建工作目录" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir ~/cfssl</span><br><span class="line">cd ~/cfssl</span><br></pre></td></tr></table></figure><h3 id="创建默认配置文件"><a href="#创建默认配置文件" class="headerlink" title="创建默认配置文件"></a>创建默认配置文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cfssl print-defaults config &gt; ca-config.json</span><br><span class="line">cfssl print-defaults csr &gt; ca-csr.json</span><br></pre></td></tr></table></figure><h3 id="证书类型介绍"><a href="#证书类型介绍" class="headerlink" title="证书类型介绍"></a>证书类型介绍</h3><ul><li><strong>客户端证书</strong>用于服务器验证客户端身份</li><li><strong>服务器端证书</strong>用于客户端验证服务器端身份</li><li><strong>对等证书</strong>由etcd集群成员使用，同时使用<strong>客户端认证</strong>和<strong>服务器端认证</strong></li></ul><h3 id="配置CA"><a href="#配置CA" class="headerlink" title="配置CA"></a>配置CA</h3><p>修改<code>ca-config.json</code></p><p><strong>说明</strong></p><ul><li><code>expiry</code>定义过期时间，这里的43800h为5年</li><li><code>usages</code>字段定义用途<ul><li><code>signing</code>代表可以用于签发其他证书</li><li><code>key encipherment</code>代表将密钥加密</li><li><code>server auth</code></li><li><code>client auth</code></li></ul></li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"signing"</span>: &#123;</span><br><span class="line">        <span class="attr">"default"</span>: &#123;</span><br><span class="line">            <span class="attr">"expiry"</span>: <span class="string">"43800h"</span></span><br><span class="line">        &#125;,</span><br><span class="line">        <span class="attr">"profiles"</span>: &#123;</span><br><span class="line">            <span class="attr">"server"</span>: &#123;</span><br><span class="line">                <span class="attr">"expiry"</span>: <span class="string">"43800h"</span>,</span><br><span class="line">                <span class="attr">"usages"</span>: [</span><br><span class="line">                    <span class="string">"signing"</span>,</span><br><span class="line">                    <span class="string">"key encipherment"</span>,</span><br><span class="line">                    <span class="string">"server auth"</span></span><br><span class="line">                ]</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"client"</span>: &#123;</span><br><span class="line">                <span class="attr">"expiry"</span>: <span class="string">"43800h"</span>,</span><br><span class="line">                <span class="attr">"usages"</span>: [</span><br><span class="line">                    <span class="string">"signing"</span>,</span><br><span class="line">                    <span class="string">"key encipherment"</span>,</span><br><span class="line">                    <span class="string">"client auth"</span></span><br><span class="line">                ]</span><br><span class="line">            &#125;,</span><br><span class="line">            <span class="attr">"peer"</span>: &#123;</span><br><span class="line">                <span class="attr">"expiry"</span>: <span class="string">"43800h"</span>,</span><br><span class="line">                <span class="attr">"usages"</span>: [</span><br><span class="line">                    <span class="string">"signing"</span>,</span><br><span class="line">                    <span class="string">"key encipherment"</span>,</span><br><span class="line">                    <span class="string">"server auth"</span>,</span><br><span class="line">                    <span class="string">"client auth"</span></span><br><span class="line">                ]</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="配置证书请求"><a href="#配置证书请求" class="headerlink" title="配置证书请求"></a>配置证书请求</h3><p>修改<code>ca-csr.json</code>，可以根据自己的需求修改对应字段</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"CN"</span>: <span class="string">"My own CA"</span>,</span><br><span class="line">    <span class="attr">"key"</span>: &#123;</span><br><span class="line">        <span class="attr">"algo"</span>: <span class="string">"rsa"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">2048</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"names"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"C"</span>: <span class="string">"US"</span>,</span><br><span class="line">            <span class="attr">"L"</span>: <span class="string">"CA"</span>,</span><br><span class="line">            <span class="attr">"O"</span>: <span class="string">"My Company Name"</span>,</span><br><span class="line">            <span class="attr">"ST"</span>: <span class="string">"San Francisco"</span>,</span><br><span class="line">            <span class="attr">"OU"</span>: <span class="string">"Org Unit 1"</span>,</span><br><span class="line">            <span class="attr">"OU"</span>: <span class="string">"Org Unit 2"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="生成CA证书"><a href="#生成CA证书" class="headerlink" title="生成CA证书"></a>生成CA证书</h3><p>运行以下命令生成CA证书</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare ca -</span><br></pre></td></tr></table></figure><p>生成以下文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ca-key.pem</span><br><span class="line">ca.csr</span><br><span class="line">ca.pem</span><br></pre></td></tr></table></figure><ul><li>ca-key.pem为CA的私钥，请妥善保管</li><li>csr文件为证书请求文件，可以删除</li></ul><h3 id="生成服务器端证书"><a href="#生成服务器端证书" class="headerlink" title="生成服务器端证书"></a>生成服务器端证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl print-defaults csr &gt; server.json</span><br></pre></td></tr></table></figure><p>修改<code>server.json</code>的<strong>CN</strong>和<strong>hosts</strong>字段，<code>names</code>字段按需修改</p><p><strong>说明</strong></p><ul><li><strong>hosts</strong>字段为列表，服务器端需要将自己作为客户端访问集群，可以使用<code>hostname</code>或者<code>IP地址</code>的形式定义hosts</li></ul><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"CN"</span>: <span class="string">"example.net"</span>,</span><br><span class="line">    <span class="attr">"hosts"</span>: [</span><br><span class="line">        <span class="string">"127.0.0.1"</span>,</span><br><span class="line">        <span class="string">"192.168.1.1"</span>,</span><br><span class="line">        <span class="string">"ext.example.com"</span>,</span><br><span class="line">        <span class="string">"coreos1.local"</span>,</span><br><span class="line">        <span class="string">"coreos1"</span></span><br><span class="line">    ],</span><br><span class="line">    <span class="attr">"key"</span>: &#123;</span><br><span class="line">        <span class="attr">"algo"</span>: <span class="string">"ecdsa"</span>,</span><br><span class="line">        <span class="attr">"size"</span>: <span class="number">256</span></span><br><span class="line">    &#125;,</span><br><span class="line">    <span class="attr">"names"</span>: [</span><br><span class="line">        &#123;</span><br><span class="line">            <span class="attr">"C"</span>: <span class="string">"US"</span>,</span><br><span class="line">            <span class="attr">"L"</span>: <span class="string">"CA"</span>,</span><br><span class="line">            <span class="attr">"ST"</span>: <span class="string">"San Francisco"</span></span><br><span class="line">        &#125;</span><br><span class="line">    ]</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>创建服务器端证书和私钥</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=server server.json | cfssljson -bare server</span><br></pre></td></tr></table></figure><p>生成以下文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">server-key.pem</span><br><span class="line">server.csr</span><br><span class="line">server.pem</span><br></pre></td></tr></table></figure><h3 id="生成客户端证书"><a href="#生成客户端证书" class="headerlink" title="生成客户端证书"></a>生成客户端证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl print-defaults csr &gt; client.json</span><br></pre></td></tr></table></figure><p>修改<code>client.json</code>，客户端证书不需要hosts字段，只需要CN字段设置为<code>client</code></p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">    "CN": "client",</span><br><span class="line">    "hosts": [""],</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>创建客户端证书和私钥</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=client client.json | cfssljson -bare client</span><br></pre></td></tr></table></figure><p>生成以下文件</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">client-key.pem</span><br><span class="line">client.csr</span><br><span class="line">client.pem</span><br></pre></td></tr></table></figure><h3 id="生成对等证书"><a href="#生成对等证书" class="headerlink" title="生成对等证书"></a>生成对等证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl print-defaults csr &gt; member1.json</span><br></pre></td></tr></table></figure><p>修改<code>member1.json</code>的<strong>CN</strong>字段和<strong>hosts</strong>字段</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">    "CN": "member1",</span><br><span class="line">    "hosts": [</span><br><span class="line">        "192.168.122.101",</span><br><span class="line">        "ext.example.com",</span><br><span class="line">        "member1.local",</span><br><span class="line">        <span class="string">"member1"</span></span><br><span class="line">    ],</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>创建<code>member1</code>的证书和密钥</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cfssl gencert -ca=ca.pem -ca-key=ca-key.pem -config=ca-config.json -profile=peer member1.json | cfssljson -bare member1</span><br></pre></td></tr></table></figure><p>生成以下文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">member1-key.pem</span><br><span class="line">member1.csr</span><br><span class="line">member1.pem</span><br></pre></td></tr></table></figure><p>对于多个member需要重复此操作，用于生成相对应的对等证书</p><h3 id="验证证书"><a href="#验证证书" class="headerlink" title="验证证书"></a>验证证书</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">openssl x509 -in ca.pem -text -noout</span><br><span class="line">openssl x509 -in server.pem -text -noout</span><br><span class="line">openssl x509 -in client.pem -text -noout</span><br><span class="line">openssl x509 -in member1.pem -text -noout</span><br></pre></td></tr></table></figure><h2 id="示例1、客户端使用HTTPS传输数据给服务器端"><a href="#示例1、客户端使用HTTPS传输数据给服务器端" class="headerlink" title="示例1、客户端使用HTTPS传输数据给服务器端"></a>示例1、客户端使用HTTPS传输数据给服务器端</h2><p>准备CA证书<code>ca.pem</code>，密钥对<code>server.pem</code> <code>server-key.pem</code></p><h3 id="启动服务器端"><a href="#启动服务器端" class="headerlink" title="启动服务器端"></a>启动服务器端</h3><p>启动参数如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">etcd --name infra0 \</span><br><span class="line">--data-dir /var/lib/etcd/infra0 \</span><br><span class="line">--cert-file=/path/to/server.pem \</span><br><span class="line">--key-file=/path/to/server-key.pem \</span><br><span class="line">--advertise-client-urls=https://127.0.0.1:2379 \</span><br><span class="line">--listen-client-urls=https://127.0.0.1:2379</span><br></pre></td></tr></table></figure><h3 id="客户端使用HTTPS访问服务器端"><a href="#客户端使用HTTPS访问服务器端" class="headerlink" title="客户端使用HTTPS访问服务器端"></a>客户端使用HTTPS访问服务器端</h3><p>使用<code>curl</code>加载CA证书测试HTTPS连接</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">curl --cacert /path/to/ca.pem \</span><br><span class="line">https://127.0.0.1:2379/v2/keys/foo \</span><br><span class="line">-X PUT \</span><br><span class="line">-d value=bar \</span><br><span class="line">-v</span><br></pre></td></tr></table></figure><h2 id="示例2、客户端使用客户端证书作为身份验证访问服务器端"><a href="#示例2、客户端使用客户端证书作为身份验证访问服务器端" class="headerlink" title="示例2、客户端使用客户端证书作为身份验证访问服务器端"></a>示例2、客户端使用客户端证书作为身份验证访问服务器端</h2><p>在示例1的基础上，需要客户端证书<code>client.pem</code>和<code>client-key.pem</code></p><h3 id="启动服务器端-1"><a href="#启动服务器端-1" class="headerlink" title="启动服务器端"></a>启动服务器端</h3><p>启动参数如下，这里比示例1多了<code>client-cert-auth</code>和<code>truested-ca-file</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">etcd --name infra0 \</span><br><span class="line">--data-dir /var/lib/etcd/infra0 \</span><br><span class="line">--cert-file=/path/to/server.pem \</span><br><span class="line">--key-file=/path/to/server-key.pem \</span><br><span class="line">--advertise-client-urls=https://127.0.0.1:2379 \</span><br><span class="line">--listen-client-urls=https://127.0.0.1:2379 \</span><br><span class="line">--client-cert-auth \</span><br><span class="line">--trusted-ca-file=/path/to/ca.crt</span><br></pre></td></tr></table></figure><p>重复示例1的访问</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl --cacert /path/to/ca.crt https://127.0.0.1:2379/v2/keys/foo -XPUT -d value=bar -v</span><br></pre></td></tr></table></figure><p>此命令结果会提示被服务器端拒绝</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">routines:SSL3_READ_BYTES:sslv3 alert bad certificate</span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>使用客户端证书访问服务器端</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">curl --cacert /path/to/ca.pem \</span><br><span class="line">--cert /path/to/client.pem \</span><br><span class="line">--key /path/to/client-key.pem \</span><br><span class="line">-L https://127.0.0.1:2379/v2/keys/foo \</span><br><span class="line">-X PUT \</span><br><span class="line">-d value=bar \</span><br><span class="line">-v</span><br></pre></td></tr></table></figure><p>命令结果包含以下信息</p><ul><li>身份认证成功</li></ul><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line">SSLv3, TLS handshake, CERT verify (15):</span><br><span class="line">...</span><br><span class="line">TLS handshake, Finished (20)</span><br></pre></td></tr></table></figure><h2 id="示例3、在集群中传输安全和客户端证书"><a href="#示例3、在集群中传输安全和客户端证书" class="headerlink" title="示例3、在集群中传输安全和客户端证书"></a>示例3、在集群中传输安全和客户端证书</h2><p>这里需要为每个member配备对应的member证书，操作步骤见生成证书部分</p><p>假设有2个member，这两个member都已生成对应的证书(<code>member1.pem</code>、<code>member1-key.pem</code>、<code>member2.pem</code>、<code>member2-key.pem</code>)</p><p>etcd 成员将组成一个集群，集群中成员之间的所有通信将使用客户端证书进行加密和验证。</p><p>etcd的输出将显示其连接的地址使用HTTPS。</p><h3 id="启动服务器端-2"><a href="#启动服务器端-2" class="headerlink" title="启动服务器端"></a>启动服务器端</h3><p>从<a href="https://discovery.etcd.io/new获取discovery_url作为启动集群的发现服务" target="_blank" rel="noopener">https://discovery.etcd.io/new获取discovery_url作为启动集群的发现服务</a></p><p>发现服务可以在内网环境搭建，详见<a href="https://github.com/coreos/discovery.etcd.io" target="_blank" rel="noopener">github地址</a></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DISCOVERY_URL=$(curl https://discovery.etcd.io/new)</span><br></pre></td></tr></table></figure><h4 id="member1"><a href="#member1" class="headerlink" title="member1"></a>member1</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">etcd --name infra1 \</span><br><span class="line">--data-dir /var/lib/etcd/infra1 \</span><br><span class="line">--peer-client-cert-auth \</span><br><span class="line">--peer-trusted-ca-file=/path/to/ca.pem \</span><br><span class="line">--peer-cert-file=/path/to/member1.pem \</span><br><span class="line">--peer-key-file=/path/to/member1-key.pem \</span><br><span class="line">--initial-advertise-peer-urls=https://10.0.1.11:2380 \</span><br><span class="line">--listen-peer-urls=https://10.0.1.11:2380 \</span><br><span class="line">--discovery $&#123;DISCOVERY_URL&#125;</span><br></pre></td></tr></table></figure><h4 id="member2"><a href="#member2" class="headerlink" title="member2"></a>member2</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">etcd --name infra2 \</span><br><span class="line">--data-dir /var/lib/etcd/infra2 \</span><br><span class="line">--peer-client-cert-auth \</span><br><span class="line">--peer-trusted-ca-file=/path/to/ca.pem \</span><br><span class="line">--peer-cert-file=/path/to/member2.pem \</span><br><span class="line">--peer-key-file=/path/to/member2-key.pem \</span><br><span class="line">--initial-advertise-peer-urls=https://10.0.1.12:2380 \</span><br><span class="line">--listen-peer-urls=https://10.0.1.12:2380 \</span><br><span class="line">--discovery $&#123;DISCOVERY_URL&#125;</span><br></pre></td></tr></table></figure><h2 id="示例4、自动自签名"><a href="#示例4、自动自签名" class="headerlink" title="示例4、自动自签名"></a>示例4、自动自签名</h2><p>对于只需要加密传输数据而不需要身份验证的场景，etcd支持使用自动生成的自签名证书加密传输数据</p><h3 id="启动服务器端-3"><a href="#启动服务器端-3" class="headerlink" title="启动服务器端"></a>启动服务器端</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">DISCOVERY_URL=$(curl https://discovery.etcd.io/new)</span><br></pre></td></tr></table></figure><h4 id="member1-1"><a href="#member1-1" class="headerlink" title="member1"></a>member1</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">etcd --name infra1 \</span><br><span class="line">--data-dir /var/lib/etcd/infra1 \</span><br><span class="line">--auto-tls \</span><br><span class="line">--peer-auto-tls \</span><br><span class="line">--initial-advertise-peer-urls=https://10.0.1.11:2380 \</span><br><span class="line">--listen-peer-urls=https://10.0.1.11:2380 \</span><br><span class="line">--discovery $&#123;DISCOVERY_URL&#125;</span><br></pre></td></tr></table></figure><h4 id="member2-1"><a href="#member2-1" class="headerlink" title="member2"></a>member2</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">etcd --name infra2 \</span><br><span class="line">--data-dir /var/lib/etcd/infra2 \</span><br><span class="line">--auto-tls \</span><br><span class="line">--peer-auto-tls \</span><br><span class="line">--initial-advertise-peer-urls=https://10.0.1.12:2380 \</span><br><span class="line">--listen-peer-urls=https://10.0.1.12:2380 \</span><br><span class="line">--discovery $&#123;DISCOVERY_URL&#125;</span><br></pre></td></tr></table></figure><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a>注意</h3><p>由于自签名证书不会进行身份认证，因此curl会返回错误，因此需要添加<code>-k</code>参数禁用证书链检查</p><h1 id="etcd维护操作"><a href="#etcd维护操作" class="headerlink" title="etcd维护操作"></a>etcd维护操作</h1><h2 id="快照条目数量调整"><a href="#快照条目数量调整" class="headerlink" title="快照条目数量调整"></a>快照条目数量调整</h2><p><code>--snapshot-count</code>：指定有多少事务（transaction）被提交时，触发截取快照保存到磁盘。从v3.2开始，<code>--snapshot-count</code>的默认值已从10000更改为100000。</p><blockquote><p><strong>注意</strong></p><p>此参数具体数值可以通过根据实际情况调整</p><p>过低会带来频繁的IO压力，影响集群可用性和写入吞吐量。</p><p>过高则导致内存占用过高以及会让etcd的GC变慢</p></blockquote><h2 id="历史数据压缩（针对v3的API）"><a href="#历史数据压缩（针对v3的API）" class="headerlink" title="历史数据压缩（针对v3的API）"></a>历史数据压缩（针对v3的API）</h2><p>由于etcd保存了key的历史记录，因此能通过MVCC机制获取多版本的数据，需要定期压缩历史记录避免性能下降和空间耗尽。</p><p>到达上限阈值时，集群将处于只读和只能删除key的状态，无法写操作。</p><p>历史数据压缩只是针对数据的历史版本进行清理，清理之后只能读取到清理点之后的历史版本</p><h3 id="手动压缩"><a href="#手动压缩" class="headerlink" title="手动压缩"></a>手动压缩</h3><p>清理revision为3之前的历史数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl compact 3</span><br></pre></td></tr></table></figure><p>清理之后，访问revision3之前的数据会提示不存在</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl get KEY_NAME --rev=2</span><br><span class="line">Error:  etcdserver: mvcc: required revision has been compacted</span><br></pre></td></tr></table></figure><h3 id="自动压缩"><a href="#自动压缩" class="headerlink" title="自动压缩"></a>自动压缩</h3><p>启动参数中添加<code>--auto-compaction-retention=1</code>即为每小时压缩一次</p><h2 id="碎片整理-针对v3的API"><a href="#碎片整理-针对v3的API" class="headerlink" title="碎片整理(针对v3的API)"></a>碎片整理(针对v3的API)</h2><p>在数据压缩操作之后，旧的revision被压缩，会产生内部碎片，这些内部碎片可以被etcd使用，但是仍消耗磁盘空间。</p><p>碎片整理就是将这部分空间释放出来。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl defrag</span><br></pre></td></tr></table></figure><h2 id="空间配额"><a href="#空间配额" class="headerlink" title="空间配额"></a>空间配额</h2><p>etcd通过<code>--quota-backend-bytes</code>参数来限制etcd数据库的大小，以字节为单位。</p><p>默认是<code>2147483648</code>即2GB，最大值为<code>8589934592</code>即8GB。</p><p>容量限制见<a href="https://coreos.com/etcd/docs/latest/dev-guide/limit.html" target="_blank" rel="noopener">官方文档</a></p><h2 id="数据备份-针对v3的API"><a href="#数据备份-针对v3的API" class="headerlink" title="数据备份(针对v3的API)"></a>数据备份(针对v3的API)</h2><h3 id="快照备份"><a href="#快照备份" class="headerlink" title="快照备份"></a>快照备份</h3><p>通过快照etcd集群可以作备份数据的用途。</p><p>可以通过快照备份的数据，将etcd集群恢复到快照的时间点。</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl snapshot save /path/to/snapshot.db</span><br></pre></td></tr></table></figure><p>检查快照状态</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">etcd --write-out=table snapshot status /path/to/snapshot.db</span><br><span class="line">+----------+----------+------------+------------+</span><br><span class="line">|   HASH   | REVISION | TOTAL KEYS | TOTAL SIZE |</span><br><span class="line">+----------+----------+------------+------------+</span><br><span class="line">| dd97719a |    24276 |       1113 |     3.0 MB |</span><br><span class="line">+----------+----------+------------+------------+</span><br></pre></td></tr></table></figure><h3 id="基于快照的定期备份脚本"><a href="#基于快照的定期备份脚本" class="headerlink" title="基于快照的定期备份脚本"></a>基于快照的定期备份脚本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span>!/bin/sh</span><br><span class="line">TIME=$(date +%Y%m%d)</span><br><span class="line">HOUR=$(date +%H)</span><br><span class="line">BACKUP_DIR="/data/etcd_backup/$&#123;TIME&#125;"</span><br><span class="line">mkdir -p $BACKUP_DIR</span><br><span class="line">export ETCDCTL_API=3</span><br><span class="line">/usr/local/bin/etcdctl --cacert=/etc/etcd/ssl/etcd-ca.pem \</span><br><span class="line">                       --cert=/etc/etcd/ssl/etcd-client.pem \</span><br><span class="line">                       --key=/etc/etcd/ssl/etcd-client-key.pem \</span><br><span class="line">                       --endpoints=https://member1:2379,https://member2:2379,https://member3:2379 \</span><br><span class="line">                       snapshot save $BACKUP_DIR/snapshot-$&#123;HOUR&#125;.db</span><br><span class="line"><span class="meta">#</span> 清理2天前的etcd备份</span><br><span class="line">find /data/etcd_backup -type d -mtime +2 -exec rm -rf &#123;&#125; \;</span><br></pre></td></tr></table></figure><h2 id="etcd镜像集群-针对v3的API"><a href="#etcd镜像集群-针对v3的API" class="headerlink" title="etcd镜像集群(针对v3的API)"></a>etcd镜像集群(针对v3的API)</h2><p>通过mirror-maker实时做镜像的方式同步数据，如果出现主机房服务挂了可以通过切换域名的形式切换到灾备机房；这个过程中数据是可以保持一致的。</p><p>提前部署好两套etcd集群之后，可以在主集群上面运行以下命令</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">export ETCDCTL_API=3</span><br><span class="line">etcdctl make-mirror --no-dest-prefix=true http://mirror1:2379,http://mirror2:2379,http://mirror3:2379</span><br><span class="line"><span class="meta">#</span> 输出示例</span><br><span class="line">488</span><br><span class="line">546</span><br><span class="line">604</span><br><span class="line">662</span><br><span class="line">720</span><br><span class="line">778</span><br><span class="line">836</span><br><span class="line">894</span><br><span class="line">950</span><br><span class="line">1009</span><br><span class="line">1067</span><br><span class="line">1125</span><br><span class="line">1183</span><br><span class="line">1241</span><br></pre></td></tr></table></figure><blockquote><p>make-mirror的输出为30s一次，程序为前台运行，可以通过nohup &gt;/path/to/log 2&gt;&amp;1 &amp;的方式扔到后台运行</p></blockquote><h1 id="etcd监控"><a href="#etcd监控" class="headerlink" title="etcd监控"></a>etcd监控</h1><h2 id="debug-endpoint"><a href="#debug-endpoint" class="headerlink" title="debug endpoint"></a>debug endpoint</h2><p>启动参数中添加<code>--debug</code>即可打开debug模式，etcd会在<code>http://x.x.x.x:2379/debug</code>路径下输出debug信息。</p><p>由于debug信息很多，会导致性能下降。</p><p><code>/debug/pprof</code>为go语言runtime的endpoint，可以用于分析CPU、heap、mutex和goroutine利用率。</p><p>这里示例为使用go命令获取etcd最耗时的</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">go tool pprof http://127.0.0.1:2379/debug/pprof/profile</span><br><span class="line">Fetching profile over HTTP from http://127.0.0.1:2379/debug/pprof/profile</span><br><span class="line">Saved profile in /root/pprof/pprof.etcd-3.2.24.samples.cpu.001.pb.gz</span><br><span class="line">File: etcd-3.2.24</span><br><span class="line">Type: cpu</span><br><span class="line">Time: Feb 10, 2019 at 9:57pm (CST)</span><br><span class="line">Duration: 30s, Total samples = 60ms (  0.2%)</span><br><span class="line">Entering interactive mode (type "help" for commands, "o" for options)</span><br><span class="line">(pprof) </span><br><span class="line">(pprof) </span><br><span class="line">(pprof) top10</span><br><span class="line">Showing nodes accounting for 60ms, 100% of 60ms total</span><br><span class="line">Showing top 10 nodes out of 25</span><br><span class="line">      flat  flat%   sum%        cum   cum%</span><br><span class="line">      60ms   100%   100%       60ms   100%  runtime.futex</span><br><span class="line">         0     0%   100%       10ms 16.67%  github.com/coreos/etcd/cmd/vendor/github.com/coreos/etcd/etcdserver.(*raftNode).start.func1</span><br><span class="line">         0     0%   100%       10ms 16.67%  github.com/coreos/etcd/cmd/vendor/github.com/coreos/etcd/etcdserver.(*raftNode).tick</span><br><span class="line">         0     0%   100%       10ms 16.67%  github.com/coreos/etcd/cmd/vendor/github.com/coreos/etcd/raft.(*node).Tick</span><br><span class="line">         0     0%   100%       20ms 33.33%  runtime.chansend</span><br><span class="line">         0     0%   100%       30ms 50.00%  runtime.exitsyscall</span><br><span class="line">         0     0%   100%       30ms 50.00%  runtime.exitsyscallfast</span><br><span class="line">         0     0%   100%       30ms 50.00%  runtime.exitsyscallfast.func1</span><br><span class="line">         0     0%   100%       30ms 50.00%  runtime.exitsyscallfast_pidle</span><br><span class="line">         0     0%   100%       60ms   100%  runtime.futexwakeup</span><br><span class="line">(pprof) exit</span><br></pre></td></tr></table></figure><h2 id="metrics-endpoint"><a href="#metrics-endpoint" class="headerlink" title="metrics endpoint"></a>metrics endpoint</h2><p>每个etcd节点都会在<code>/metrics</code>路径下输出监控信息，监控软件可以通过此路径获取指标信息</p><p>具体的metrics信息可以参看<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/metrics.md" target="_blank" rel="noopener">官方文档</a></p><ul><li><code>--listen-metrics-urls</code>定义metrics的location。</li><li><code>--metrics</code>可以定义<code>basic</code>和<code>extensive</code></li></ul><p>这里通过<code>curl</code>命令来获取metrics信息</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://127.0.0.1:2379/metrics</span><br></pre></td></tr></table></figure><h2 id="health-check"><a href="#health-check" class="headerlink" title="health check"></a>health check</h2><p>这里通过<code>curl</code>命令来获取health信息，返回结果为json</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl http://127.0.0.1:2379/health</span><br></pre></td></tr></table></figure><p>返回结果如下</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  <span class="attr">"health"</span>: <span class="string">"true"</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="对接Prometheus"><a href="#对接Prometheus" class="headerlink" title="对接Prometheus"></a>对接Prometheus</h2><h3 id="配置文件-1"><a href="#配置文件-1" class="headerlink" title="配置文件"></a>配置文件</h3><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">global:</span></span><br><span class="line"><span class="attr">  scrape_interval:</span> <span class="number">10</span><span class="string">s</span></span><br><span class="line"><span class="attr">scrape_configs:</span></span><br><span class="line"><span class="attr">  - job_name:</span> <span class="string">etcd-cluster-monitoring</span></span><br><span class="line"><span class="attr">    static_configs:</span></span><br><span class="line"><span class="attr">    - targets:</span> <span class="string">['10.240.0.32:2379','10.240.0.33:2379','10.240.0.34:2379']</span></span><br></pre></td></tr></table></figure><h3 id="监控告警"><a href="#监控告警" class="headerlink" title="监控告警"></a>监控告警</h3><p>使用Alertmanager进行监控告警</p><p><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/etcd3_alert.rules" target="_blank" rel="noopener">Prometheus 1.x 范例</a></p><p><a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/etcd3_alert.rules.yml" target="_blank" rel="noopener">Prometheus 2.x 范例</a></p><h3 id="监控指标展示"><a href="#监控指标展示" class="headerlink" title="监控指标展示"></a>监控指标展示</h3><p>使用Grafana读取Prometheus的数据展示监控数据，<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/grafana.json" target="_blank" rel="noopener">Dashboard模板</a></p><p><img src="https://github.com/etcd-io/etcd/raw/master/Documentation/op-guide/etcd-sample-grafana.png" alt="img"></p><h1 id="etcd故障处理"><a href="#etcd故障处理" class="headerlink" title="etcd故障处理"></a>etcd故障处理</h1><h2 id="leader节点故障"><a href="#leader节点故障" class="headerlink" title="leader节点故障"></a>leader节点故障</h2><blockquote><ul><li>leader节点故障，etcd集群会自动选举出新的leader。</li><li>故障检测模型是基于超时的，因此选举新的leader节点不会在旧的leader节点故障之后立刻发生。</li><li>选举leader期间，集群不会处理写入操作。选举期间的写入请求会进入队列等待处理，直至选出新的leader节点。</li><li>已经发送给故障leader但尚未提交的数据可能会丢失。这是因为新的leader节点有权对旧leader节点的数据进行修改</li><li>客户端会发现一些写入请求可能会超时，没有提交的数据会丢失。</li></ul></blockquote><h2 id="follower节点故障"><a href="#follower节点故障" class="headerlink" title="follower节点故障"></a>follower节点故障</h2><blockquote><ul><li>follower故障节点数量少于集群节点的一半时，etcd集群是可以正常工作的。<ul><li>例如3个节点故障了1个，5个节点故障了2个</li></ul></li><li>follower节点故障后，客户端的etcd库应该自动连接到etcd集群的其他成员。</li></ul></blockquote><h2 id="超过半数节点故障"><a href="#超过半数节点故障" class="headerlink" title="超过半数节点故障"></a>超过半数节点故障</h2><blockquote><ul><li>由于Raft算法的原理所限，超过半数的集群节点故障会导致etcd集群进入不可写入的状态。</li><li>只要正常工作的节点超过集群节点的一半，那么etcd集群会自动选举leader节点并且自动恢复到健康状态</li><li>如果无法修复多数节点，那么就需要走灾难恢复的操作流程</li></ul></blockquote><h2 id="网络分区"><a href="#网络分区" class="headerlink" title="网络分区"></a>网络分区</h2><blockquote><ul><li>由于网络故障，导致etcd集群被切分成两个或者更多的部分。</li><li>那么占有多数节点的一方会成为可用集群，少数节点的一方不可写入。</li><li>如果对等切分了集群，那么每个部分都不可用。</li><li>这是因为Raft一致性算法保证了etcd是不存在<strong>脑裂</strong>现象。</li><li>只要网络分区的故障解除，少数节点的一方会自动从多数节点一方识别出leader节点，然后恢复状态。</li></ul></blockquote><h2 id="集群启动失败"><a href="#集群启动失败" class="headerlink" title="集群启动失败"></a>集群启动失败</h2><p>只有超过半数成员启动完成之后，集群的bootstrap才会成功。</p><p>Raft一致性算法保证了集群节点的数据一致性和稳定性，因此对于节点的恢复，更多的是恢复etcd节点服务，然后恢复数据</p><h3 id="新的集群"><a href="#新的集群" class="headerlink" title="新的集群"></a>新的集群</h3><p>可以删除所有成员的数据目录，然后重新走创建集群的步骤</p><h3 id="已有集群"><a href="#已有集群" class="headerlink" title="已有集群"></a>已有集群</h3><p>这个就要看无法启动的节点是数据文件损坏，还是其他原因导致的。</p><p>这里以数据文件损坏为例。</p><ul><li>寻找正常的节点，使用<code>etcdctl snapshot save</code>命令保存出快照文件</li><li>将故障节点的数据目录清空，使用<code>etcdctl snapshot restore</code>命令将数据恢复到数据目录</li><li>使用<code>etcdctl member list</code>确认故障节点的信息</li><li>使用<code>etcdctl member remove</code>删除故障节点</li><li>使用<code>etcdctl member add MEMBER_NAME --peer-urls=http://member:2379</code>重新添加成员</li><li>修改etcd启动参数<code>--initial-cluster-state=existing</code>启动故障节点的etcd服务</li></ul><h1 id="etcd灾难恢复"><a href="#etcd灾难恢复" class="headerlink" title="etcd灾难恢复"></a>etcd灾难恢复</h1><p>这里的灾难恢复，只能恢复v2或者v3的数据，不能同时恢复v2和v3。</p><p>两套API是相互隔离的。</p><h2 id="针对v3的API"><a href="#针对v3的API" class="headerlink" title="针对v3的API"></a>针对v3的API</h2><p>etcd v3的API提供了快照和恢复功能，可以在不损失快照点数据的情况下重建集群</p><h3 id="快照备份数据"><a href="#快照备份数据" class="headerlink" title="快照备份数据"></a>快照备份数据</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ETCDCTL_API=3 etcdctl --endpoints http://member1:2379,http://member2:2379,http://member3:2379 snapshot save /path/to/snapshot.db</span><br></pre></td></tr></table></figure><h3 id="恢复集群"><a href="#恢复集群" class="headerlink" title="恢复集群"></a>恢复集群</h3><blockquote><ul><li>恢复etcd集群，只需要快照文件<code>db</code>即可。</li><li>使用<code>etcdctl snapshot restore</code>命令还原数据时会自动创建新的etcd数据目录。</li><li>恢复过程会覆盖快照文件里面的一些metadata（特别是member id和cluster id），该member会失去之前的id。覆盖metadata可以防止新成员无意中加入现有集群。</li><li>从快照中恢复集群，必须以新集群启动。</li><li>恢复时可以选择验证快照完整性hash。<ul><li>使用<code>etcdctl snapshot save</code>生成的快照，则具有完整性hash</li><li>如果是直接从数据目录拷贝数据快照，则没有完整性hash，需要使用<code>--skip-hash-check</code>跳过检查</li></ul></li></ul></blockquote><h4 id="恢复节点数据"><a href="#恢复节点数据" class="headerlink" title="恢复节点数据"></a>恢复节点数据</h4><blockquote><ul><li>这里假定原有的集群节点为member1、member2、member3</li></ul></blockquote><p>在member1、member2、member3上分别恢复快照数据</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \</span><br><span class="line">  --name member1 \</span><br><span class="line">  --initial-cluster member1=http://member1:2380,member2=http://member2:2380,member3=http://member3:2380 \</span><br><span class="line">  --initial-cluster-token etcd-cluster-1 \</span><br><span class="line">  --initial-advertise-peer-urls http://member1:2380</span><br><span class="line"><span class="meta">$</span> ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \</span><br><span class="line">  --name member2 \</span><br><span class="line">  --initial-cluster member1=http://member1:2380,member2=http://member2:2380,member3=http://member3:2380 \</span><br><span class="line">  --initial-cluster-token etcd-cluster-1 \</span><br><span class="line">  --initial-advertise-peer-urls http://member2:2380</span><br><span class="line"><span class="meta">$</span> ETCDCTL_API=3 etcdctl snapshot restore snapshot.db \</span><br><span class="line">  --name member3 \</span><br><span class="line">  --initial-cluster member1=http://member1:2380,member2=http://member2:2380,member3=http://member3:2380 \</span><br><span class="line">  --initial-cluster-token etcd-cluster-1 \</span><br><span class="line">  --initial-advertise-peer-urls http://member3:2380</span><br></pre></td></tr></table></figure><h4 id="启动etcd集群-1"><a href="#启动etcd集群-1" class="headerlink" title="启动etcd集群"></a>启动etcd集群</h4><p>在member1、member2、member3上分别启动集群</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span> etcd \</span><br><span class="line">  --name member1 \</span><br><span class="line">  --listen-client-urls http://member1:2379 \</span><br><span class="line">  --advertise-client-urls http://member1:2379 \</span><br><span class="line">  --listen-peer-urls http://member1:2380 &amp;</span><br><span class="line"><span class="meta">$</span> etcd \</span><br><span class="line">  --name member2 \</span><br><span class="line">  --listen-client-urls http://member2:2379 \</span><br><span class="line">  --advertise-client-urls http://member2:2379 \</span><br><span class="line">  --listen-peer-urls http://member2:2380 &amp;</span><br><span class="line"><span class="meta">$</span> etcd \</span><br><span class="line">  --name member3 \</span><br><span class="line">  --listen-client-urls http://member3:2379 \</span><br><span class="line">  --advertise-client-urls http://member3:2379 \</span><br><span class="line">  --listen-peer-urls http://member3:2380 &amp;</span><br></pre></td></tr></table></figure><h2 id="针对v2的API"><a href="#针对v2的API" class="headerlink" title="针对v2的API"></a>针对v2的API</h2><h3 id="备份数据"><a href="#备份数据" class="headerlink" title="备份数据"></a>备份数据</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ETCDCTL_API=3</span><br><span class="line">etcdctl backup \</span><br><span class="line">        --data-dir /path/to/data-dir \</span><br><span class="line">        --wal-dir /path/to/wal_dir \</span><br><span class="line">        --backup-dir /path/to/backup_data_dir \</span><br><span class="line">        --backup-wal-dir /path/to/backup_wal_dir</span><br></pre></td></tr></table></figure><h3 id="清理数据目录"><a href="#清理数据目录" class="headerlink" title="清理数据目录"></a>清理数据目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">rm -rf /path/to/data-dir</span><br><span class="line">rm -rf /path/to/wal-dir</span><br></pre></td></tr></table></figure><h3 id="恢复数据"><a href="#恢复数据" class="headerlink" title="恢复数据"></a>恢复数据</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mv /path/to/backup_data_dir /path/to/data-dir</span><br><span class="line">mv /path/to/backup_wal_dir /path/to/wal_dir</span><br></pre></td></tr></table></figure><h3 id="启动etcd集群-2"><a href="#启动etcd集群-2" class="headerlink" title="启动etcd集群"></a>启动etcd集群</h3><p>启动参数需要添加<code>--force-new-cluster</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">etcd --data-dir /path/to/data-dir \</span><br><span class="line">     --wal-dir /path/to/wal_dir \</span><br><span class="line">     --force-new-cluster</span><br></pre></td></tr></table></figure><h1 id="etcd版本升级"><a href="#etcd版本升级" class="headerlink" title="etcd版本升级"></a>etcd版本升级</h1><p>这里可以参考<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/upgrades/upgrading-etcd.md" target="_blank" rel="noopener">etcd的升级文档</a></p><h1 id="etcd的FAQ"><a href="#etcd的FAQ" class="headerlink" title="etcd的FAQ"></a>etcd的FAQ</h1><p>摘自<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/faq.md" target="_blank" rel="noopener">Frequently Asked Questions (FAQ)</a></p><h2 id="客户端是否需要向etcd集群的leader节点发送请求"><a href="#客户端是否需要向etcd集群的leader节点发送请求" class="headerlink" title="客户端是否需要向etcd集群的leader节点发送请求"></a>客户端是否需要向etcd集群的leader节点发送请求</h2><blockquote><ul><li>leader节点负责处理所有需要集群共识的请求（例如写请求）。</li><li>客户端不需要知道哪个节点是leader，follower节点会将所有需要集群共识的请求转发给leader节点。</li><li>所有节点都可以处理不需要集群共识的请求（例如序列化读取）。</li></ul></blockquote><h2 id="listen-client-urls、listen-peer-urls、advertise-client-urls、initial-advertise-peer-urls的区别"><a href="#listen-client-urls、listen-peer-urls、advertise-client-urls、initial-advertise-peer-urls的区别" class="headerlink" title="listen-client-urls、listen-peer-urls、advertise-client-urls、initial-advertise-peer-urls的区别"></a>listen-client-urls、listen-peer-urls、advertise-client-urls、initial-advertise-peer-urls的区别</h2><blockquote><ul><li><code>listen-client-urls</code>和<code>listen-peer-urls</code>指定etcd服务端用于接收传入连接的本地地址，要监听所有地址，请指定0.0.0.0作为监听地址。</li><li><code>advertise-client-urls</code> 和<code>initial-advertise-peer-urls</code>指定etcd的客户端及集群其他成员访问etcd服务的地址，此地址必须要被外部访问，因此不能设置127.0.0.1或者0.0.0.0等地址。</li></ul></blockquote><h2 id="为什么不能通过更改listen-peer-urls或者initial-advertise-peer-urls来更新etcdctl-member-list中列出的advertise-peer-urls"><a href="#为什么不能通过更改listen-peer-urls或者initial-advertise-peer-urls来更新etcdctl-member-list中列出的advertise-peer-urls" class="headerlink" title="为什么不能通过更改listen-peer-urls或者initial-advertise-peer-urls来更新etcdctl member list中列出的advertise peer urls"></a>为什么不能通过更改listen-peer-urls或者initial-advertise-peer-urls来更新etcdctl member list中列出的advertise peer urls</h2><blockquote><ul><li>每个member的advertise-peer-urls来自初始化集群时的<code>initial-advertise-peer-urls</code>参数</li><li>在member启动完成后修改listen-peer-urls或者initial-advertise-peer-urls参数不会影响现有的advertise-peer-urls，因为修改此参数需要通过集群仲裁以避免出现脑裂</li><li>修改<code>advertise-peer-url</code>请使用<code>etcd member update</code>命令操作</li></ul></blockquote><h2 id="系统要求"><a href="#系统要求" class="headerlink" title="系统要求"></a>系统要求</h2><blockquote><ul><li>etcd会将数据写入磁盘，因此高性能的磁盘会更好，推荐使用SSD</li><li>默认存储配额为2GB，最大值为8GB</li><li>为了避免使用swap或者内存不足，服务器内存至少要超过存储配额</li></ul></blockquote><h2 id="为什么etcd需要奇数个集群成员"><a href="#为什么etcd需要奇数个集群成员" class="headerlink" title="为什么etcd需要奇数个集群成员"></a>为什么etcd需要奇数个集群成员</h2><blockquote><ul><li>etcd集群需要通过大多数节点仲裁才能将集群状态更新到一致</li><li>仲裁为(n/2)+1</li><li>双数个集群成员并不比奇数个节点容错性强</li></ul></blockquote><h2 id="集群容错性列表"><a href="#集群容错性列表" class="headerlink" title="集群容错性列表"></a>集群容错性列表</h2><table><thead><tr><th>Cluster Size</th><th>Majority</th><th>Failure Tolerance</th></tr></thead><tbody><tr><td>1</td><td>1</td><td>0</td></tr><tr><td>2</td><td>2</td><td>0</td></tr><tr><td>3</td><td>2</td><td>1</td></tr><tr><td>4</td><td>3</td><td>1</td></tr><tr><td>5</td><td>3</td><td>2</td></tr><tr><td>6</td><td>4</td><td>2</td></tr><tr><td>7</td><td>4</td><td>3</td></tr><tr><td>8</td><td>5</td><td>3</td></tr><tr><td>9</td><td>5</td><td>4</td></tr></tbody></table><h2 id="集群最大节点数量"><a href="#集群最大节点数量" class="headerlink" title="集群最大节点数量"></a>集群最大节点数量</h2><blockquote><ul><li>理论上没有硬性限制，一般不超过7个节点</li><li>建议5个节点，5个节点可以容忍2个节点故障下线，在大多数情况下已经足够</li><li>更多的节点可以提供更好的可用性，但是写入性能会有影响</li></ul></blockquote><h2 id="部署跨数据中心的etcd集群是否合适"><a href="#部署跨数据中心的etcd集群是否合适" class="headerlink" title="部署跨数据中心的etcd集群是否合适"></a>部署跨数据中心的etcd集群是否合适</h2><blockquote><ul><li>跨数据中心的etcd集群可以提高可用性</li><li>数据中心之间的网络延迟可能会影响节点的election</li><li>默认的etcd配置可能会因为网络延迟频繁选举或者心跳超时，需要调整对应的<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/tuning.md" target="_blank" rel="noopener">参数</a></li></ul></blockquote><h2 id="为什么etcd会因为磁盘IO延迟而重新选举"><a href="#为什么etcd会因为磁盘IO延迟而重新选举" class="headerlink" title="为什么etcd会因为磁盘IO延迟而重新选举"></a>为什么etcd会因为磁盘IO延迟而重新选举</h2><blockquote><ul><li>这是故意设计的</li><li>磁盘IO延迟是leader节点存活指标的一部分</li><li>磁盘IO延迟很高导致选举超时，即使leader节点在选举间隔内能处理网络信息（例如发送心跳），但它实际上是不可用的，因为它无法及时提交新的提议</li><li>如果经常出现因磁盘IO延迟而重新选举，请关注一下磁盘或者修改etcd时间<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/tuning.md" target="_blank" rel="noopener">参数</a></li></ul></blockquote><h1 id="etcd性能压测"><a href="#etcd性能压测" class="headerlink" title="etcd性能压测"></a>etcd性能压测</h1><p>这里参考<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/performance.md" target="_blank" rel="noopener">官方文档</a></p><h2 id="性能指标"><a href="#性能指标" class="headerlink" title="性能指标"></a>性能指标</h2><blockquote><ul><li>延迟<ul><li>完成操作所需的时间</li></ul></li><li>吞吐量<ul><li>一段时间内完成的总操作数量</li></ul></li></ul></blockquote><p>通常情况下，平均延迟会随着吞吐量的增加而增加。</p><p>etcd使用Raft一致性算法完成成员之间的数据同步并达成集群共识。</p><p>集群的共识性能，尤其是提交延迟，主要受到两个方面限制。</p><blockquote><ul><li>网络IO延迟</li><li>磁盘IO延迟</li></ul></blockquote><h3 id="提交延迟的构成"><a href="#提交延迟的构成" class="headerlink" title="提交延迟的构成"></a>提交延迟的构成</h3><blockquote><ul><li>成员之间的网络往返时间RTT<ul><li>同一个数据中心内部的RTT是ms级别</li><li>跨数据中心的RTT就需要考虑物理限制和网络质量</li></ul></li><li><code>fdatasync</code>数据落盘时间<ul><li>机械硬盘<code>fdatasync</code>延迟通常在10ms左右</li><li>固态硬盘则低于1ms</li></ul></li></ul></blockquote><h3 id="其他延迟构成"><a href="#其他延迟构成" class="headerlink" title="其他延迟构成"></a>其他延迟构成</h3><blockquote><ul><li>序列化etcd请求需要通过etcd后端boltdb的MVVC机制来完成，通常会在10ms完成。</li><li>etcd定期将最近提交的请求快照，然后跟磁盘上的快照合并，这个操作过程会导致延迟出现峰值。</li><li>正在进行的数据压缩也会影响到延迟，所以要跟业务错开</li></ul></blockquote><h2 id="benchmark跑分"><a href="#benchmark跑分" class="headerlink" title="benchmark跑分"></a>benchmark跑分</h2><p>etcd自带的<a href="https://github.com/coreos/etcd/tree/master/tools/benchmark" target="_blank" rel="noopener">benchmark</a>命令行工具可以用来测试etcd性能</p><h3 id="写入请求"><a href="#写入请求" class="headerlink" title="写入请求"></a>写入请求</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 假定 HOST_1 是 leader, 写入请求发到 leader</span></span><br><span class="line">benchmark --endpoints=<span class="variable">$&#123;HOST_1&#125;</span> \</span><br><span class="line">          --conns=1 \</span><br><span class="line">          --clients=1 \</span><br><span class="line">          put --key-size=8 \</span><br><span class="line">          --sequential-keys \</span><br><span class="line">          --total=10000 \</span><br><span class="line">          --val-size=256</span><br><span class="line">benchmark --endpoints=<span class="variable">$&#123;HOST_1&#125;</span> \</span><br><span class="line">          --conns=100 \</span><br><span class="line">          --clients=1000 \</span><br><span class="line">          put --key-size=8 \</span><br><span class="line">          --sequential-keys \</span><br><span class="line">          --total=100000 \</span><br><span class="line">          --val-size=256</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 写入发到所有成员</span></span><br><span class="line">benchmark --endpoints=<span class="variable">$&#123;HOST_1&#125;</span>,<span class="variable">$&#123;HOST_2&#125;</span>,<span class="variable">$&#123;HOST_3&#125;</span> \</span><br><span class="line">          --conns=100 \</span><br><span class="line">          --clients=1000 \</span><br><span class="line">          put --key-size=8 \</span><br><span class="line">          --sequential-keys \</span><br><span class="line">          --total=100000 \</span><br><span class="line">          --val-size=256</span><br></pre></td></tr></table></figure><h3 id="序列化读取"><a href="#序列化读取" class="headerlink" title="序列化读取"></a>序列化读取</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Single connection read requests</span></span><br><span class="line">benchmark --endpoints=<span class="variable">$&#123;HOST_1&#125;</span>,<span class="variable">$&#123;HOST_2&#125;</span>,<span class="variable">$&#123;HOST_3&#125;</span> \</span><br><span class="line">          --conns=1 \</span><br><span class="line">          --clients=1 \</span><br><span class="line">          range YOUR_KEY \</span><br><span class="line">          --consistency=l \</span><br><span class="line">          --total=10000</span><br><span class="line">benchmark --endpoints=<span class="variable">$&#123;HOST_1&#125;</span>,<span class="variable">$&#123;HOST_2&#125;</span>,<span class="variable">$&#123;HOST_3&#125;</span> \</span><br><span class="line">          --conns=1 \</span><br><span class="line">          --clients=1 \</span><br><span class="line">          range YOUR_KEY \</span><br><span class="line">          --consistency=s \</span><br><span class="line">          --total=10000</span><br><span class="line"></span><br><span class="line"><span class="comment"># Many concurrent read requests</span></span><br><span class="line">benchmark --endpoints=<span class="variable">$&#123;HOST_1&#125;</span>,<span class="variable">$&#123;HOST_2&#125;</span>,<span class="variable">$&#123;HOST_3&#125;</span> \</span><br><span class="line">          --conns=100 \</span><br><span class="line">          --clients=1000 \</span><br><span class="line">          range YOUR_KEY \</span><br><span class="line">          --consistency=l \</span><br><span class="line">          --total=100000</span><br><span class="line">benchmark --endpoints=<span class="variable">$&#123;HOST_1&#125;</span>,<span class="variable">$&#123;HOST_2&#125;</span>,<span class="variable">$&#123;HOST_3&#125;</span> \</span><br><span class="line">          --conns=100 \</span><br><span class="line">          --clients=1000 \</span><br><span class="line">          range YOUR_KEY \</span><br><span class="line">          --consistency=s \</span><br><span class="line">          --total=100000</span><br></pre></td></tr></table></figure><h1 id="etcd性能调优"><a href="#etcd性能调优" class="headerlink" title="etcd性能调优"></a>etcd性能调优</h1><p>参考<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/tuning.md" target="_blank" rel="noopener">官方文档</a></p><p>etcd默认配置是基于同一个数据中心，网络延迟较低的情况。</p><p>对于网络延迟较高，那么就需要优化心跳间隔和选举超时时间</p><h2 id="时间参数（time-parameter）"><a href="#时间参数（time-parameter）" class="headerlink" title="时间参数（time parameter）"></a>时间参数（time parameter）</h2><p>延迟不止有网络延迟，还可能受到节点磁盘IO影响。</p><p>每一次超时设置应该包括请求发出到响应成功的时间。</p><h3 id="心跳间隔（heartbeat-interval）"><a href="#心跳间隔（heartbeat-interval）" class="headerlink" title="心跳间隔（heartbeat interval）"></a>心跳间隔（heartbeat interval）</h3><p>leader节点通知各follower节点自己的存活信息。</p><p>最佳实践是通过ping命令获取RTT最大值，然后设置为RTT的0.5~1.5倍。</p><p>默认是100ms。</p><h3 id="选举超时（election-timeout）"><a href="#选举超时（election-timeout）" class="headerlink" title="选举超时（election timeout）"></a>选举超时（election timeout）</h3><p>follower节点在多久之后没收到leader节点的心跳信息，就开始选举新leader节点。</p><p>默认是1000ms。选举超时应该设置为至少是RTT的10倍，以避免网络出现波动导致重新选举。</p><h2 id="快照（snapshot）"><a href="#快照（snapshot）" class="headerlink" title="快照（snapshot）"></a>快照（snapshot）</h2><p>etcd会将所有变更的key追加写入到wal日志文件中。</p><p>一行记录一个key的变更，因此日志会不断增长。</p><p>为避免日志过大，etcd会定期做快照。</p><p>快照操作会保存当前系统状态并移除旧的日志。</p><p><code>snapshot-count</code>参数控制快照的频率，默认是10000，即每10000次变更会触发一次快照操作。</p><p>如果内存使用率高并且磁盘使用率高，可以尝试调低这个参数。</p><h2 id="磁盘"><a href="#磁盘" class="headerlink" title="磁盘"></a>磁盘</h2><p>etcd集群对磁盘IO延迟非常的敏感。</p><p>etcd需要存储变更日志、快照等操作，可能会导致磁盘IO出现很高的<code>fsync</code>延迟。</p><p>磁盘IO延迟高会导致leader节点心跳信息超时、请求超时、重新选举等。</p><blockquote><ul><li><p>etcd所使用的磁盘与系统盘分开</p></li><li><p>data目录和wal目录分开</p></li><li><p>有条件推荐使用SSD固态硬盘</p></li><li><p>使用<code>ionice</code>调高etcd进程的IO优先级（这个针对etcd数据目录在系统盘的情况）</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&gt;    ionice -c2 -n0 -p `pgrep etcd`</span><br><span class="line">&gt;</span><br></pre></td></tr></table></figure></li></ul></blockquote><blockquote></blockquote><h2 id="网络"><a href="#网络" class="headerlink" title="网络"></a>网络</h2><p>如果leader节点接收来自客户端的大量请求，无法及时处理follower的请求，那么follower节点处理的请求也会因此出现延迟。</p><p>具体表现为follower会提示sending bufer is full。</p><p>可以通过调高leader的网络优先级或者通过流量管控机制来提高对follower的请求响应。</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;说明&quot;&gt;&lt;a href=&quot;#说明&quot; class=&quot;headerlink&quot; title=&quot;说明&quot;&gt;&lt;/a&gt;说明&lt;/h1&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Etcd 是 CoreOS 推出的分布式一致性键值存储，用于共享配置和服务发现&lt;/li&gt;
&lt;li&gt;Et
      
    
    </summary>
    
    
      <category term="kubernetes" scheme="https://luanlengli.github.io/tags/kubernetes/"/>
    
      <category term="etcd" scheme="https://luanlengli.github.io/tags/etcd/"/>
    
  </entry>
  
  <entry>
    <title>CentOS7使用社区YUM源安装Mariadb Galera集群</title>
    <link href="https://luanlengli.github.io/2018/12/11/CentOS7%E4%BD%BF%E7%94%A8%E7%A4%BE%E5%8C%BAYUM%E6%BA%90%E5%AE%89%E8%A3%85Mariadb-Galera%E9%9B%86%E7%BE%A4.html"/>
    <id>https://luanlengli.github.io/2018/12/11/CentOS7使用社区YUM源安装Mariadb-Galera集群.html</id>
    <published>2018-12-10T16:07:07.000Z</published>
    <updated>2018-12-10T16:34:31.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><blockquote><ul><li>本文以MariaDB官方文档为基础，记录操作步骤</li></ul></blockquote><h1 id="安装Mariadb数据库前的准备工作"><a href="#安装Mariadb数据库前的准备工作" class="headerlink" title="安装Mariadb数据库前的准备工作"></a>安装Mariadb数据库前的准备工作</h1><h2 id="准备虚拟机三台"><a href="#准备虚拟机三台" class="headerlink" title="准备虚拟机三台"></a>准备虚拟机三台</h2><table><thead><tr><th style="text-align:center">IP地址</th><th style="text-align:center">主机名</th><th style="text-align:center">CPU</th><th style="text-align:center">内存</th></tr></thead><tbody><tr><td style="text-align:center">172.16.10.101</td><td style="text-align:center">db1</td><td style="text-align:center">2</td><td style="text-align:center">3G</td></tr><tr><td style="text-align:center">172.16.10.102</td><td style="text-align:center">db2</td><td style="text-align:center">2</td><td style="text-align:center">3G</td></tr><tr><td style="text-align:center">172.16.10.103</td><td style="text-align:center">db3</td><td style="text-align:center">2</td><td style="text-align:center">3G</td></tr></tbody></table><h2 id="添加Mariadb官方YUM源，下面以Mariadb-10-1为例"><a href="#添加Mariadb官方YUM源，下面以Mariadb-10-1为例" class="headerlink" title="添加Mariadb官方YUM源，下面以Mariadb 10.1为例"></a>添加Mariadb官方YUM源，下面以Mariadb 10.1为例</h2><p><a href="https://downloads.mariadb.org/mariadb/repositories/#mirror=neusoft&amp;distro=CentOS&amp;distro_release=centos7-amd64--centos7&amp;version=10.1" target="_blank" rel="noopener">官方YUM源编辑器</a></p><p>使用以下命令快速添加YUM源</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tee /etc/yum.repos.d/mariadb.repo &lt;&lt;-'EOF'</span><br><span class="line">[mariadb]</span><br><span class="line">name = MariaDB</span><br><span class="line">baseurl = https://mirrors.ustc.edu.cn/mariadb/yum/10.1/centos7-amd64</span><br><span class="line">gpgkey=https://mirrors.ustc.edu.cn/mariadb/yum/RPM-GPG-KEY-MariaDB</span><br><span class="line">gpgcheck=1 </span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="刷新YUM缓存"><a href="#刷新YUM缓存" class="headerlink" title="刷新YUM缓存"></a>刷新YUM缓存</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum makecache</span><br></pre></td></tr></table></figure><h2 id="查看Mariadb相关的安装包，注意软件包版本和对应的YUM源名字"><a href="#查看Mariadb相关的安装包，注意软件包版本和对应的YUM源名字" class="headerlink" title="查看Mariadb相关的安装包，注意软件包版本和对应的YUM源名字"></a>查看Mariadb相关的安装包，注意软件包版本和对应的YUM源名字</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum list MariaDB* galera</span><br></pre></td></tr></table></figure><h2 id="关闭firewalld防火墙"><a href="#关闭firewalld防火墙" class="headerlink" title="关闭firewalld防火墙"></a>关闭firewalld防火墙</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl disable firewalld --now</span><br></pre></td></tr></table></figure><h2 id="设置主机名（设置三台虚拟机主机名分别为db1，db2，db3）"><a href="#设置主机名（设置三台虚拟机主机名分别为db1，db2，db3）" class="headerlink" title="设置主机名（设置三台虚拟机主机名分别为db1，db2，db3）"></a>设置主机名（设置三台虚拟机主机名分别为db1，db2，db3）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hostnamectl set-hostname db1</span><br><span class="line">hostnamectl set-hostname db2</span><br><span class="line">hostnamectl set-hostname db3</span><br></pre></td></tr></table></figure><h2 id="编辑-etc-hosts文件"><a href="#编辑-etc-hosts文件" class="headerlink" title="编辑/etc/hosts文件"></a>编辑/etc/hosts文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/hosts &lt;&lt;EOF</span><br><span class="line">172.16.10.101 db1</span><br><span class="line">172.16.10.102 db2</span><br><span class="line">172.16.10.103 db3</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="关闭SELINUX"><a href="#关闭SELINUX" class="headerlink" title="关闭SELINUX"></a>关闭SELINUX</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0 </span><br><span class="line"></span><br><span class="line">sed -i 's,^SELINUX=enforcing,SELINUX=disabled,g' /etc/selinux/config</span><br></pre></td></tr></table></figure><h1 id="部署MariaDB-Galera集群"><a href="#部署MariaDB-Galera集群" class="headerlink" title="部署MariaDB Galera集群"></a>部署MariaDB Galera集群</h1><h2 id="安装相关软件包"><a href="#安装相关软件包" class="headerlink" title="安装相关软件包"></a>安装相关软件包</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install MariaDB-server MariaDB-client MariaDB-client</span><br></pre></td></tr></table></figure><h2 id="启用xtrabackup-v2功能"><a href="#启用xtrabackup-v2功能" class="headerlink" title="启用xtrabackup-v2功能"></a>启用xtrabackup-v2功能</h2><blockquote><ul><li>需要额外安装percona提供的软件包</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.4.10/binary/redhat/7/x86_64/percona-xtrabackup-24-2.4.10-1.el7.x86_64.rpm</span><br></pre></td></tr></table></figure><h2 id="启动MariaDB数据库"><a href="#启动MariaDB数据库" class="headerlink" title="启动MariaDB数据库"></a>启动MariaDB数据库</h2><blockquote><ul><li>在db1上启动MariaDB数据库，设置galera集群同步账号,进行安全初始化</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">systemctl start mariadb.service</span><br><span class="line">mysql -uroot -e "grant all privileges on *.* to 'sst'@'localhost' identified by 'password';" </span><br><span class="line">mysql_secure_installation  </span><br><span class="line">systemctl stop mariadb.service</span><br></pre></td></tr></table></figure><h2 id="编辑MariaDB配置文件"><a href="#编辑MariaDB配置文件" class="headerlink" title="编辑MariaDB配置文件"></a>编辑MariaDB配置文件</h2><blockquote><ul><li>在三个节点上编辑MariaDB配置文件，以开启galera集群功能</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/my.cnf.d/galera.cnf</span><br><span class="line">[server]</span><br><span class="line">[mysqld]</span><br><span class="line"><span class="meta">#</span> 监听哪个地址，这里每个节点填对应的ip地址</span><br><span class="line">bind-address=172.16.10.101 </span><br><span class="line"><span class="meta">#</span> 监听哪个端口</span><br><span class="line">port = 3306 </span><br><span class="line"><span class="meta">#</span> 设置默认字符编码集</span><br><span class="line">collation-server = utf8_general_ci</span><br><span class="line">init-connect = SET NAMES utf8</span><br><span class="line">character-set-server = utf8</span><br><span class="line"><span class="meta">#</span> 设置日志路径</span><br><span class="line">log-error = /var/log/mariadb/mariadb.log</span><br><span class="line"><span class="meta">#</span> 设置binlog</span><br><span class="line">log-bin = mysql-bin</span><br><span class="line">binlog_format=ROW</span><br><span class="line"><span class="meta">#</span> 设置默认数据目录</span><br><span class="line">datadir = /var/lib/mysql/ </span><br><span class="line"><span class="meta">#</span> 设置默认存储引擎</span><br><span class="line">default-storage-engine=innodb</span><br><span class="line">innodb_autoinc_lock_mode=2 </span><br><span class="line">[galera]</span><br><span class="line">wsrep_on=ON</span><br><span class="line">wsrep_provider=/usr/lib64/galera/libgalera_smm.so</span><br><span class="line"><span class="meta">#</span> galera集群名字</span><br><span class="line">wsrep_cluster_name="galera_cluster" </span><br><span class="line"><span class="meta">#</span> 本节点的主机名，这里每个节点填对应的ip地址</span><br><span class="line">wsrep_node_name="db1" </span><br><span class="line">wsrep_cluster_address = "gcomm://172.16.10.101:4567,172.16.10.102:4567,172.16.10.103:4567"</span><br><span class="line">wsrep_provider_options = "gmcast.listen_addr=tcp://172.16.10.101:4567;ist.recv_addr=172.16.10.101:4568" </span><br><span class="line">wsrep_node_address="172.16.10.101:4567" </span><br><span class="line"><span class="meta">#</span> 设置galera集群同步的方法和用户名密码</span><br><span class="line">wsrep_sst_auth=sst:password</span><br><span class="line">wsrep_sst_method=xtrabackup-v2</span><br><span class="line">max_connections = 10000 </span><br><span class="line">key_buffer_size = 64M</span><br><span class="line">max_heap_table_size = 64M</span><br><span class="line">tmp_table_size = 64M</span><br><span class="line">innodb_buffer_pool_size = 128M</span><br><span class="line">[embedded]</span><br><span class="line">[mariadb]</span><br><span class="line">[mariadb-10.1]</span><br></pre></td></tr></table></figure><h1 id="启动galera集群"><a href="#启动galera集群" class="headerlink" title="启动galera集群"></a>启动galera集群</h1><h2 id="创建集群"><a href="#创建集群" class="headerlink" title="创建集群"></a>创建集群</h2><blockquote><ul><li>在db1上运行galera_new_cluster命令</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">galera_new_cluster</span><br></pre></td></tr></table></figure><h2 id="查看集群状态"><a href="#查看集群状态" class="headerlink" title="查看集群状态"></a>查看集群状态</h2><blockquote><ul><li>在db1上查看集群状态</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> mysql -uroot -p -e "show status like 'wsrep_cluster_size';"</span><br><span class="line">+--------------------------+--------------------------------------+</span><br><span class="line">| Variable_name            | Value                                |</span><br><span class="line">+--------------------------+--------------------------------------+</span><br><span class="line">| wsrep_cluster_size       | 1                                    |</span><br><span class="line">+--------------------------+--------------------------------------+</span><br></pre></td></tr></table></figure><h2 id="监控MariaDB日志"><a href="#监控MariaDB日志" class="headerlink" title="监控MariaDB日志"></a>监控MariaDB日志</h2><blockquote><ul><li>监控db1上的MariaDB日志</li><li>在启动其他节点的时候，能看到其他节点加入到galera集群</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tail -f /var/log/mariadb/mariadb.log</span><br></pre></td></tr></table></figure><h2 id="启动其他节点数据库"><a href="#启动其他节点数据库" class="headerlink" title="启动其他节点数据库"></a>启动其他节点数据库</h2><blockquote><ul><li>在db2和db3上运行MariaDB数据库</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start mariadb</span><br></pre></td></tr></table></figure><h2 id="检查集群状态"><a href="#检查集群状态" class="headerlink" title="检查集群状态"></a>检查集群状态</h2><blockquote><ul><li>在db1上检查集群状态</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -p -e "show status like 'wsrep_cluster_size';"</span><br><span class="line">+--------------------------+--------------------------------------+</span><br><span class="line">| Variable_name            | Value                                |</span><br><span class="line">+--------------------------+--------------------------------------+</span><br><span class="line">| wsrep_cluster_size       | 3                                    |</span><br><span class="line">+--------------------------+--------------------------------------+</span><br></pre></td></tr></table></figure><h1 id="验证MariaDB-galera集群的同步功能是否正常"><a href="#验证MariaDB-galera集群的同步功能是否正常" class="headerlink" title="验证MariaDB galera集群的同步功能是否正常"></a>验证MariaDB galera集群的同步功能是否正常</h1><h2 id="在db1上创建用户、数据库"><a href="#在db1上创建用户、数据库" class="headerlink" title="在db1上创建用户、数据库"></a>在db1上创建用户、数据库</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -p -e "user add testuser;"</span><br><span class="line">mysql -uroot -p -e "create database testdb;"</span><br><span class="line">mysql -uroot -p -e "grant all privileges on testdb.* to 'testuser'@'localhost' identified by 'password';"</span><br></pre></td></tr></table></figure><h2 id="在db2上检查用户、数据库是否存在"><a href="#在db2上检查用户、数据库是否存在" class="headerlink" title="在db2上检查用户、数据库是否存在"></a>在db2上检查用户、数据库是否存在</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -p -e "select user,host from mysql.user;"</span><br><span class="line">mysql -uroot -p -e "show databases;"</span><br></pre></td></tr></table></figure><h2 id="在db3上删除用户和数据库"><a href="#在db3上删除用户和数据库" class="headerlink" title="在db3上删除用户和数据库"></a>在db3上删除用户和数据库</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -p -e "delete user 'testuser'"</span><br><span class="line">mysql -uroot -p -e "drop database testdb"</span><br></pre></td></tr></table></figure><h2 id="在db1上检查用户和数据库是否还在"><a href="#在db1上检查用户和数据库是否还在" class="headerlink" title="在db1上检查用户和数据库是否还在"></a>在db1上检查用户和数据库是否还在</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mysql -uroot -p -e "select user,host from mysql.user;"</span><br><span class="line">mysql -uroot -p -e "show databases;"</span><br></pre></td></tr></table></figure><h1 id="至此，MariaDB-galera集群已经部署完成"><a href="#至此，MariaDB-galera集群已经部署完成" class="headerlink" title="至此，MariaDB galera集群已经部署完成"></a>至此，MariaDB galera集群已经部署完成</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;本文以MariaDB官方文档为基础，记录操作步骤&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;
      
    
    </summary>
    
    
      <category term="Mariadb/MySQL" scheme="https://luanlengli.github.io/tags/Mariadb-MySQL/"/>
    
      <category term="Linux" scheme="https://luanlengli.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>使用Docker打包shadowsocks-libev镜像</title>
    <link href="https://luanlengli.github.io/2018/12/11/%E4%BD%BF%E7%94%A8Docker%E6%89%93%E5%8C%85shadowsocks-libev%E9%95%9C%E5%83%8F.html"/>
    <id>https://luanlengli.github.io/2018/12/11/使用Docker打包shadowsocks-libev镜像.html</id>
    <published>2018-12-10T16:03:06.000Z</published>
    <updated>2018-12-10T16:31:12.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>记录一下使用Dockerfile制作shadowsocks-libev镜像的过程</p><blockquote><ul><li>基于Alpine-3.8和shadowsocks-libev-v3.2.3制作</li><li>参考shadowsocks-libev项目上面的<a href="https://raw.githubusercontent.com/shadowsocks/shadowsocks-libev/v3.2.3/docker/alpine/Dockerfile" target="_blank" rel="noopener">Dockerfile</a></li></ul></blockquote><h1 id="以下是Dockerfile内容"><a href="#以下是Dockerfile内容" class="headerlink" title="以下是Dockerfile内容"></a>以下是Dockerfile内容</h1><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># README</span></span><br><span class="line"><span class="comment"># /*  BUILD IMAGE  */</span></span><br><span class="line"><span class="comment"># dokcer image build -t shadowsocks-libev:v3.2.3 .</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># /*  RUN CONATIANER  */</span></span><br><span class="line"><span class="comment"># docker container run -d -e SERVER_PORT=111 -e PASSWORD='password' -e METHOD='aes-256-gcm' --net host --name ss-libev-port111 shadowsocks-libev:v3.2-alpine3.8</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># /*  SS-SERVER HELP  */</span></span><br><span class="line"><span class="comment"># shadowsocks-libev 3.2.3</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#   maintained by Max Lv &lt;max.c.lv@gmail.com&gt; and Linus Yang &lt;laokongzi@gmail.com&gt;</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#   usage:</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#     ss-server</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#        -s &lt;server_host&gt;           Host name or IP address of your remote server.</span></span><br><span class="line"><span class="comment">#        -p &lt;server_port&gt;           Port number of your remote server.</span></span><br><span class="line"><span class="comment">#        -l &lt;local_port&gt;            Port number of your local server.</span></span><br><span class="line"><span class="comment">#        -k &lt;password&gt;              Password of your remote server.</span></span><br><span class="line"><span class="comment">#        -m &lt;encrypt_method&gt;        Encrypt method: rc4-md5, </span></span><br><span class="line"><span class="comment">#                                   aes-128-gcm, aes-192-gcm, aes-256-gcm,</span></span><br><span class="line"><span class="comment">#                                   aes-128-cfb, aes-192-cfb, aes-256-cfb,</span></span><br><span class="line"><span class="comment">#                                   aes-128-ctr, aes-192-ctr, aes-256-ctr,</span></span><br><span class="line"><span class="comment">#                                   camellia-128-cfb, camellia-192-cfb,</span></span><br><span class="line"><span class="comment">#                                   camellia-256-cfb, bf-cfb,</span></span><br><span class="line"><span class="comment">#                                   chacha20-ietf-poly1305,</span></span><br><span class="line"><span class="comment">#                                   xchacha20-ietf-poly1305,</span></span><br><span class="line"><span class="comment">#                                   salsa20, chacha20 and chacha20-ietf.</span></span><br><span class="line"><span class="comment">#                                   The default cipher is chacha20-ietf-poly1305.</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#        [-a &lt;user&gt;]                Run as another user.</span></span><br><span class="line"><span class="comment">#        [-f &lt;pid_file&gt;]            The file path to store pid.</span></span><br><span class="line"><span class="comment">#        [-t &lt;timeout&gt;]             Socket timeout in seconds.</span></span><br><span class="line"><span class="comment">#        [-c &lt;config_file&gt;]         The path to config file.</span></span><br><span class="line"><span class="comment">#        [-n &lt;number&gt;]              Max number of open files.</span></span><br><span class="line"><span class="comment">#        [-i &lt;interface&gt;]           Network interface to bind.</span></span><br><span class="line"><span class="comment">#        [-b &lt;local_address&gt;]       Local address to bind.</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#        [-u]                       Enable UDP relay.</span></span><br><span class="line"><span class="comment">#        [-U]                       Enable UDP relay and disable TCP relay.</span></span><br><span class="line"><span class="comment">#        [-6]                       Resovle hostname to IPv6 address first.</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#        [-d &lt;addr&gt;]                Name servers for internal DNS resolver.</span></span><br><span class="line"><span class="comment">#        [--reuse-port]             Enable port reuse.</span></span><br><span class="line"><span class="comment">#        [--fast-open]              Enable TCP fast open.</span></span><br><span class="line"><span class="comment">#                                   with Linux kernel &gt; 3.7.0.</span></span><br><span class="line"><span class="comment">#        [--acl &lt;acl_file&gt;]         Path to ACL (Access Control List).</span></span><br><span class="line"><span class="comment">#        [--manager-address &lt;addr&gt;] UNIX domain socket address.</span></span><br><span class="line"><span class="comment">#        [--mtu &lt;MTU&gt;]              MTU of your network interface.</span></span><br><span class="line"><span class="comment">#        [--mptcp]                  Enable Multipath TCP on MPTCP Kernel.</span></span><br><span class="line"><span class="comment">#        [--no-delay]               Enable TCP_NODELAY.</span></span><br><span class="line"><span class="comment">#        [--key &lt;key_in_base64&gt;]    Key of your remote server.</span></span><br><span class="line"><span class="comment">#        [--plugin &lt;name&gt;]          Enable SIP003 plugin. (Experimental)</span></span><br><span class="line"><span class="comment">#        [--plugin-opts &lt;options&gt;]  Set SIP003 plugin options. (Experimental)</span></span><br><span class="line"><span class="comment"># </span></span><br><span class="line"><span class="comment">#        [-v]                       Verbose mode.</span></span><br><span class="line"><span class="comment">#        [-h, --help]               Print this message.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">FROM</span> alpine:<span class="number">3.8</span></span><br><span class="line"><span class="keyword">ENV</span> TZ <span class="string">'Asia/Shanghai'</span></span><br><span class="line"><span class="keyword">ENV</span> SS_VERSION <span class="number">3.2</span>.<span class="number">3</span></span><br><span class="line"><span class="keyword">ENV</span> SS_DOWNLOAD_URL https://github.com/shadowsocks/shadowsocks-libev/releases/download/v$&#123;SS_VERSION&#125;/shadowsocks-libev-$&#123;SS_VERSION&#125;.tar.gz</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apk upgrade \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk add bash tzdata libsodium rng-tools \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk add --virtual .build-deps \</span></span><br><span class="line"><span class="bash">    autoconf \</span></span><br><span class="line"><span class="bash">    automake \</span></span><br><span class="line"><span class="bash">    xmlto \</span></span><br><span class="line"><span class="bash">    build-base \</span></span><br><span class="line"><span class="bash">    curl \</span></span><br><span class="line"><span class="bash">    c-ares-dev \</span></span><br><span class="line"><span class="bash">    libev-dev \</span></span><br><span class="line"><span class="bash">    libtool \</span></span><br><span class="line"><span class="bash">    linux-headers \</span></span><br><span class="line"><span class="bash">    udns-dev \</span></span><br><span class="line"><span class="bash">    libsodium-dev \</span></span><br><span class="line"><span class="bash">    mbedtls-dev \</span></span><br><span class="line"><span class="bash">    pcre-dev \</span></span><br><span class="line"><span class="bash">    udns-dev \</span></span><br><span class="line"><span class="bash">    tar \</span></span><br><span class="line"><span class="bash">    git \</span></span><br><span class="line"><span class="bash">    &amp;&amp; wget -q -O - <span class="variable">$SS_DOWNLOAD_URL</span> | tar xz  \</span></span><br><span class="line"><span class="bash">    &amp;&amp; (<span class="built_in">cd</span> shadowsocks-libev-<span class="variable">$&#123;SS_VERSION&#125;</span> \</span></span><br><span class="line"><span class="bash">    &amp;&amp; ./configure --prefix=/usr --<span class="built_in">disable</span>-documentation \</span></span><br><span class="line"><span class="bash">    &amp;&amp; make install) \</span></span><br><span class="line"><span class="bash">    &amp;&amp; ln -sf /usr/share/zoneinfo/<span class="variable">$TZ</span> /etc/localtime \</span></span><br><span class="line"><span class="bash">    &amp;&amp; <span class="built_in">echo</span> <span class="variable">$TZ</span> &gt; /etc/timezone \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk del .build-deps \</span></span><br><span class="line"><span class="bash">    &amp;&amp; rm -rf shadowsocks-libev-<span class="variable">$&#123;SS_VERSION&#125;</span> \</span></span><br><span class="line"><span class="bash">    /var/cache/apk/* \</span></span><br><span class="line"><span class="bash">    &amp;&amp; apk add --no-cache \</span></span><br><span class="line"><span class="bash">    rng-tools \</span></span><br><span class="line"><span class="bash">    $(scanelf --needed --nobanner /usr/bin/ss-* \</span></span><br><span class="line"><span class="bash">    | awk <span class="string">'&#123; gsub(/,/, "\nso:", $2); print "so:" $2 &#125;'</span> \</span></span><br><span class="line"><span class="bash">    | sort -u)</span></span><br><span class="line"><span class="bash">    </span></span><br><span class="line"><span class="bash">CMD [<span class="string">"/usr/bin/ss-server"</span>]</span></span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;介绍&quot;&gt;&lt;a href=&quot;#介绍&quot; class=&quot;headerlink&quot; title=&quot;介绍&quot;&gt;&lt;/a&gt;介绍&lt;/h1&gt;&lt;p&gt;记录一下使用Dockerfile制作shadowsocks-libev镜像的过程&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;基于A
      
    
    </summary>
    
    
      <category term="docker" scheme="https://luanlengli.github.io/tags/docker/"/>
    
  </entry>
  
  <entry>
    <title>【不定时更新】二进制部署 kubernetes v1.11.x 高可用集群</title>
    <link href="https://luanlengli.github.io/2018/12/08/%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%83%A8%E7%BD%B2%20kubernetes%20v1.11.x%20%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4.html"/>
    <id>https://luanlengli.github.io/2018/12/08/二进制部署 kubernetes v1.11.x 高可用集群.html</id>
    <published>2018-12-08T03:34:08.000Z</published>
    <updated>2019-02-10T14:20:35.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="更新记录"><a href="#更新记录" class="headerlink" title="更新记录"></a>更新记录</h1><blockquote><ul><li>2019年1月7日添加基于ingress-nginx使用域名+HTTPS的方式访问kubernetes-Dashboard</li><li>2019年1月2日添加RBAC规则，修复kube-apiserver无法访问kubelet的问题</li><li>2019年1月1日调整master节点和worker节点的操作步骤，添加CoreDNS的configmap中的hosts静态解析</li><li>2018年12月28日修改kube-prometheus部分，修复Prometheus的Targets无法发现的问题</li><li>2018年12月26日修改kubernetes-dashboard链接指向</li><li>2018年12月25日修改kubele.config.file路径问题</li><li>2018年12月18日修改kubelet和kube-proxy启动时加载config file</li><li>2018年12月17日添加EFK部署内容</li><li>2018年12月16日添加prometheus-operator部署内容</li><li>2018年12月14日添加helm部署内容，拆分etcd的server证书和client证书</li><li>2018年12月13日添加rook-ceph部署内容</li><li>2018年12月12日添加Metrics-Server内容</li><li>2018年12月11日添加Dashboard、Ingress内容</li><li>2018年12月10日添加kube-flannel、calico、CoreDNS内容</li><li>2018年12月9日分拆master节点和work节点的内容</li><li>2018年12月8日初稿</li></ul></blockquote><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>本次部署方式为二进制可执行文件的方式部署</p><blockquote><ul><li>注意<font color="red">请根据自己的实际情况调整</font></li><li>对于生产环境部署，请注意某些参数的选择</li></ul></blockquote><p>如无特殊说明，均在<font color="red">k8s-m1</font>节点上执行</p><h2 id="参考博文"><a href="#参考博文" class="headerlink" title="参考博文"></a>参考博文</h2><p>感谢两位大佬的文章，这里整合一下两位大佬的内容，结合自己的理解整理本文</p><blockquote><ul><li><a href="https://mritd.me/2018/04/19/set-up-kubernetes-1.10.1-cluster-by-hyperkube/" target="_blank" rel="noopener">【漠然】Kubernetes 1.10.1 集群搭建</a></li><li><a href="https://mritd.me/2018/08/28/kubernetes-tls-bootstrapping-with-bootstrap-token/" target="_blank" rel="noopener">【漠然】使用 Bootstrap Token 完成 TLS Bootstrapping</a></li><li><a href="https://zhangguanzhang.github.io/2018/09/18/kubernetes-1-11-x-bin/" target="_blank" rel="noopener">【张馆长】二进制部署Kubernetes v1.11.x(1.12.x) HA可选</a></li></ul></blockquote><h2 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h2><blockquote><ul><li><a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.11.md" target="_blank" rel="noopener">kubernetes v1.11.5</a> <font color="red">【下载链接需要爬墙，自行解决】</font>&gt;</li><li><a href="https://docs.docker.com/install/linux/docker-ce/" target="_blank" rel="noopener">docker-ce 18.03</a></li><li><a href="https://github.com/containernetworking/plugins/releases" target="_blank" rel="noopener">cni-plugin v0.7.4</a></li><li><a href="https://github.com/etcd-io/etcd/releases" target="_blank" rel="noopener">etcd v3.3.10</a></li></ul></blockquote><h2 id="网络信息"><a href="#网络信息" class="headerlink" title="网络信息"></a>网络信息</h2><blockquote><ul><li>基于CNI的模式实现容器网络</li><li>Cluster IP CIDR: <code>10.244.0.0/16</code></li><li>Service Cluster IP CIDR: <code>10.96.0.0/12</code></li><li>Service DNS IP: <code>10.96.0.10</code></li><li>Kubernetes API VIP: <code>172.16.80.200</code></li></ul></blockquote><h2 id="节点信息"><a href="#节点信息" class="headerlink" title="节点信息"></a>节点信息</h2><blockquote><ul><li>操作系统可采用 <code>Ubuntu Server 16.04+</code> 和 <code>CentOS 7.4+</code>，本文使用CentOS 7.6 (1810) Minimal</li><li>由<code>keepalived</code>提供VIP</li><li>由<code>haproxy</code>提供kube-apiserver四层负载均衡</li><li>由于实验环境受限，以3台服务器同时作为master和worker节点运行</li><li>服务器配置请根据实际情况适当调整</li></ul></blockquote><table><thead><tr><th style="text-align:center">IP地址</th><th style="text-align:center">主机名</th><th style="text-align:center">角色</th><th style="text-align:center">CPU</th><th style="text-align:center">内存</th></tr></thead><tbody><tr><td style="text-align:center">172.16.80.201</td><td style="text-align:center">k8s-m1</td><td style="text-align:center">master+worker</td><td style="text-align:center">4</td><td style="text-align:center">8G</td></tr><tr><td style="text-align:center">172.16.80.202</td><td style="text-align:center">k8s-m2</td><td style="text-align:center">master+worker</td><td style="text-align:center">4</td><td style="text-align:center">8G</td></tr><tr><td style="text-align:center">172.16.80.203</td><td style="text-align:center">k8s-m3</td><td style="text-align:center">master+worker</td><td style="text-align:center">4</td><td style="text-align:center">8G</td></tr></tbody></table><h2 id="目录说明"><a href="#目录说明" class="headerlink" title="目录说明"></a>目录说明</h2><blockquote><ul><li>/usr/local/bin/：存放kubernetes和etcd二进制文件</li><li>/opt/cni/bin/： 存放cni-plugin二进制文件</li><li>/etc/etcd/：存放etcd配置文件和SSL证书</li><li>/etc/kubernetes/：存放kubernetes配置和SSL证书</li><li>/etc/cni/net.d/：安装CNI插件后会在这里生成配置文件</li><li>$HOME/.kube/：kubectl命令会在家目录下建立此目录，用于保存访问kubernetes集群的配置和缓存</li><li>$HOME/.helm/：helm命令会建立此目录，用于保存helm缓存和repository信息</li></ul></blockquote><h1 id="事前准备"><a href="#事前准备" class="headerlink" title="事前准备"></a>事前准备</h1><blockquote><p>事情准备在所有服务器上都需要完成</p><p>部署过程以<code>root用户</code>完成</p></blockquote><ul><li>所有服务器<code>网络互通</code>，<code>k8s-m1</code>可以通过SSH证书免密登录到其他master节点，用于分发文件</li><li>编辑<code>/etc/hosts</code></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/hosts &lt;&lt;EOF</span><br><span class="line">127.0.0.1 localhost</span><br><span class="line">172.16.80.200 k8s-vip</span><br><span class="line">172.16.80.201 k8s-m1</span><br><span class="line">172.16.80.202 k8s-m2</span><br><span class="line">172.16.80.203 k8s-m3</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>时间同步服务</li></ul><p>集群系统需要各节点时间同步</p><p>参考链接：<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/system_administrators_guide/sect-using_chrony" target="_blank" rel="noopener">RHEL7官方文档</a></p><p>这里使用公网对时，如果需要内网对时，请自行配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y chrony</span><br><span class="line">systemctl enable chronyd</span><br><span class="line">systemctl start chronyd</span><br></pre></td></tr></table></figure><ul><li>关闭firewalld和SELINUX（可根据实际情况自行决定关闭不需要的服务）</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line">systemctl mask firewalld</span><br><span class="line"><span class="meta">#</span><span class="bash"> 清空iptables规则</span></span><br><span class="line">iptables -Z</span><br><span class="line">iptables -P INPUT ACCEPT</span><br><span class="line">iptables -P FORWARD ACCEPT</span><br><span class="line">iptables -P OUTPUT ACCEPT</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -ri '/^[^#]*SELINUX=/s#=.+$#=disabled#' /etc/selinux/config</span><br></pre></td></tr></table></figure><ul><li>禁用swap</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line">sed -ri '/^[^#]*swap/s@^@#@' /etc/fstab</span><br></pre></td></tr></table></figure><ul><li>添加<code>sysctl</code>参数</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/sysctl.d/centos.conf &lt;&lt;EOF </span><br><span class="line"><span class="meta">#</span><span class="bash"> 最大文件句柄数</span></span><br><span class="line">fs.file-max=1024000</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在CentOS7.4引入了一个新的参数来控制内核的行为。 </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> /proc/sys/fs/may_detach_mounts 默认设置为0</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 当系统有容器运行的时候，需要将该值设置为1。</span></span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 最大文件打开数</span></span><br><span class="line">fs.nr_open=1024000</span><br><span class="line"><span class="meta">#</span><span class="bash"> 二层的网桥在转发包时也会被iptables的FORWARD规则所过滤</span></span><br><span class="line">net.bridge.bridge-nf-call-arptables=1</span><br><span class="line">net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables=1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 关闭严格校验数据包的反向路径</span></span><br><span class="line">net.ipv4.conf.default.rp_filter=0</span><br><span class="line">net.ipv4.conf.all.rp_filter=0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 打开ipv4数据包转发</span></span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 允许应用程序能够绑定到不属于本地网卡的地址</span></span><br><span class="line">net.ipv4.ip_nonlocal_bind=1 </span><br><span class="line"><span class="meta">#</span><span class="bash"> 表示最大限度使用物理内存，然后才是swap空间</span></span><br><span class="line">vm.swappiness = 0 </span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置系统TCP连接keepalive的持续时间，默认7200</span></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_intvl = 30</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 10</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 让sysctl参数生效</span></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure><ul><li>确保操作系统已经最新</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum update -y</span><br></pre></td></tr></table></figure><ul><li>安装软件包</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum groups install base -y</span><br><span class="line">yum install epel-release bash-completion-extras -y</span><br><span class="line">yum install git vim ipvsadm tree dstat iotop htop socat ipset conntrack -y</span><br></pre></td></tr></table></figure><ul><li>加载ipvs模块</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 开机自动加载ipvs模块</span></span><br><span class="line">cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">ipvs_modules="ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack_ipv4"</span><br><span class="line">for kernel_module in \$&#123;ipvs_modules&#125;; do</span><br><span class="line">    /sbin/modinfo -F filename \$&#123;kernel_module&#125; &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">    if [ $? -eq 0 ]; then</span><br><span class="line">        /sbin/modprobe \$&#123;kernel_module&#125;</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep ip_vs</span><br></pre></td></tr></table></figure><ul><li>安装docker-ce 18.03</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-selinux docker-engine-selinux docker-engine -y</span><br><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2 -y</span><br><span class="line">yum-config-manager --add-repo http://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">sed -e 's,download.docker.com,mirrors.aliyun.com/docker-ce,g' -i /etc/yum.repos.d/docker-ce.repo</span><br><span class="line">yum install docker-ce-18.03.1.ce -y</span><br></pre></td></tr></table></figure><ul><li>创建docker配置文件</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /etc/docker</span><br><span class="line"><span class="meta">cat&gt;</span><span class="bash">/etc/docker/daemon.json&lt;&lt;EOF</span></span><br><span class="line">&#123;</span><br><span class="line">    "registry-mirrors": ["https://registry.docker-cn.com"],</span><br><span class="line">    "insecure-registries": [],</span><br><span class="line">    "log-driver": "json-file",</span><br><span class="line">    "log-opts": &#123;</span><br><span class="line">        "max-size": "100m",</span><br><span class="line">        "max-file": "3"</span><br><span class="line">    &#125;,</span><br><span class="line">    "max-concurrent-downloads": 10</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>配置docker命令补全</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp /usr/share/bash-completion/completions/docker /etc/bash_completion.d/</span><br><span class="line">source /etc/bash_completion.d/docker</span><br></pre></td></tr></table></figure><ul><li>配置docker服务开机自启动</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable docker.service</span><br><span class="line">systemctl start docker.service</span><br></pre></td></tr></table></figure><ul><li>查看docker信息</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker info</span><br></pre></td></tr></table></figure><ul><li>禁用docker源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 为避免yum update时更新docker，将docker源禁用</span></span><br><span class="line">sed -e 's,enabled=1,enabled=0,g' -i /etc/yum.repos.d/docker-ce.repo</span><br></pre></td></tr></table></figure><ul><li>确保以最新的内核启动系统</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure><h1 id="定义集群变量"><a href="#定义集群变量" class="headerlink" title="定义集群变量"></a><strong><font color="red">定义集群变量</font></strong></h1><blockquote><font color="red"><strong>注意</strong></font><ul><li>这里的变量只对当前会话生效，如果会话断开或者重启服务器，都需要重新定义变量</li><li><code>HostArray</code>定义集群中所有节点的主机名和IP</li><li><code>MasterArray</code>定义master节点的主机名和IP</li><li><code>WorkerArray</code>定义worker节点的主机名和IP，这里master和worker都在一起，所以MasterArray和WorkerArray一样</li><li><code>VIP_IFACE</code>定义keepalived的VIP绑定在哪一个网卡</li><li><code>ETCD_SERVERS</code>以MasterArray的信息生成etcd集群服务器列表</li><li><code>ETCD_INITIAL_CLUSTER</code>以MasterArray信息生成etcd集群初始化列表</li><li><code>POD_DNS_SERVER_IP</code>定义Pod的DNS服务器IP地址</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">declare -A HostArray MasterArray WorkerArray</span><br><span class="line"><span class="meta">#</span><span class="bash"> 声明所有节点的信息</span></span><br><span class="line">HostArray=(['k8s-m1']=172.16.80.201 ['k8s-m2']=172.16.80.202 ['k8s-m3']=172.16.80.203)</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果节点多，可以按照下面的方式声明Array</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> HostArray=([<span class="string">'k8s-m1'</span>]=172.16.80.201 [<span class="string">'k8s-m2'</span>]=172.16.80.202 [<span class="string">'k8s-m3'</span>]=172.16.80.203 [<span class="string">'k8s-n1'</span>]=172.16.80.204 [<span class="string">'k8s-n2'</span>]=172.16.80.205)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 声明master节点信息</span></span><br><span class="line">MasterArray=(['k8s-m1']=172.16.80.201 ['k8s-m2']=172.16.80.202 ['k8s-m3']=172.16.80.203)</span><br><span class="line"><span class="meta">#</span><span class="bash"> 声明worker节点信息</span></span><br><span class="line">WorkerArray=(['k8s-m1']=172.16.80.201 ['k8s-m2']=172.16.80.202 ['k8s-m3']=172.16.80.203)</span><br><span class="line"><span class="meta">#</span><span class="bash"> </span></span><br><span class="line">VIP="172.16.80.200"</span><br><span class="line">KUBE_APISERVER="https://172.16.80.200:8443"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> etcd版本号</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubeadm-v1.11.5里面使用的是v3.2.18，这里直接上到最新的v3.3.10</span></span><br><span class="line">ETCD_VERSION="v3.3.10"</span><br><span class="line"><span class="meta">#</span><span class="bash"> kubernetes版本号</span></span><br><span class="line">KUBERNETES_VERSION="v1.11.5"</span><br><span class="line"><span class="meta">#</span><span class="bash"> cni-plugin版本号</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubernetes YUM源里用的还是v0.6.0版，这里上到最新的v0.7.4</span></span><br><span class="line">CNI_PLUGIN_VERSION="v0.7.4"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 声明VIP所在的网卡名称，以ens33为例</span></span><br><span class="line">VIP_IFACE="ens33"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 声明etcd_server</span></span><br><span class="line">ETCD_SERVERS=$( xargs -n1&lt;&lt;&lt;$&#123;MasterArray[@]&#125; | sort | sed 's#^#https://#;s#$#:2379#;$s#\n##' | paste -d, -s - )</span><br><span class="line">ETCD_INITIAL_CLUSTER=$( for i in $&#123;!MasterArray[@]&#125;;do  echo $i=https://$&#123;MasterArray[$i]&#125;:2380; done | sort | paste -d, -s - )</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 定义POD_CLUSTER_CIDR</span></span><br><span class="line">POD_NET_CIDR="10.244.0.0/16"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 定义SVC_CLUSTER_CIDR</span></span><br><span class="line">SVC_CLUSTER_CIDR="10.96.0.0/12"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 定义POD_DNS_SERVER_IP</span></span><br><span class="line">POD_DNS_SERVER_IP="10.96.0.10"</span><br></pre></td></tr></table></figure><h1 id="下载所需软件包"><a href="#下载所需软件包" class="headerlink" title="下载所需软件包"></a>下载所需软件包</h1><blockquote><ul><li>创建工作目录</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/software</span><br><span class="line">cd /root/software</span><br></pre></td></tr></table></figure><blockquote><ul><li>二进制文件需要分发到master和worker节点</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载kubernetes二进制包</span></span><br><span class="line">echo "--- 下载kubernetes $&#123;KUBERNETES_VERSION&#125; 二进制包 ---"</span><br><span class="line">wget https://dl.k8s.io/$&#123;KUBERNETES_VERSION&#125;/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">tar xzf kubernetes-server-linux-amd64.tar.gz \</span><br><span class="line">        kubernetes/server/bin/hyperkube \</span><br><span class="line">        kubernetes/server/bin/kube-controller-manager \</span><br><span class="line">        kubernetes/server/bin/kubectl \</span><br><span class="line">        kubernetes/server/bin/apiextensions-apiserver \</span><br><span class="line">        kubernetes/server/bin/kube-proxy \</span><br><span class="line">        kubernetes/server/bin/kube-apiserver \</span><br><span class="line">        kubernetes/server/bin/kubelet \</span><br><span class="line">        kubernetes/server/bin/kubeadm \</span><br><span class="line">        kubernetes/server/bin/kube-aggregator \</span><br><span class="line">        kubernetes/server/bin/kube-scheduler \</span><br><span class="line">        kubernetes/server/bin/cloud-controller-manager \</span><br><span class="line">        kubernetes/server/bin/mounter</span><br><span class="line">chown -R root:root kubernetes/server/bin/*</span><br><span class="line">chmod 0755 kubernetes/server/bin/*</span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里需要先拷贝kubectl到/usr/<span class="built_in">local</span>/bin目录下，用于生成kubeconfig文件</span></span><br><span class="line">rsync -avpt kubernetes/server/bin/kubectl /usr/local/bin/kubectl</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 下载etcd二进制包</span></span><br><span class="line">echo "--- 下载etcd $&#123;ETCD_VERSION&#125; 二进制包 ---"</span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/$&#123;ETCD_VERSION&#125;/etcd-$&#123;ETCD_VERSION&#125;-linux-amd64.tar.gz</span><br><span class="line">tar xzf etcd-$&#123;ETCD_VERSION&#125;-linux-amd64.tar.gz \</span><br><span class="line">        etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcdctl \</span><br><span class="line">        etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcd</span><br><span class="line">chown root:root etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcdctl etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcd</span><br><span class="line">chmod 0755 etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcdctl etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcd</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 下载CNI-plugin</span></span><br><span class="line">echo "--- 下载cni-plugins $&#123;CNI_PLUGIN_VERSION&#125; 二进制包 ---"</span><br><span class="line">wget https://github.com/containernetworking/plugins/releases/download/$&#123;CNI_PLUGIN_VERSION&#125;/cni-plugins-amd64-$&#123;CNI_PLUGIN_VERSION&#125;.tgz</span><br><span class="line">mkdir /root/software/cni-plugins</span><br><span class="line">tar xzf cni-plugins-amd64-$&#123;CNI_PLUGIN_VERSION&#125;.tgz -C /root/software/cni-plugins/</span><br></pre></td></tr></table></figure><h1 id="生成集群Key和Certificates"><a href="#生成集群Key和Certificates" class="headerlink" title="生成集群Key和Certificates"></a>生成集群Key和Certificates</h1><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>本次部署，需要为<code>etcd-server</code>、<code>etcd-client</code>、<code>kube-apiserver</code>、<code>kube-controller-manager</code>、<code>kube-scheduler</code>、<code>kube-proxy</code>生成证书。另外还需要生成<code>sa</code>、<code>front-proxy-ca</code>、<code>front-proxy-client</code>证书用于集群的其他功能。</p><blockquote><ul><li>要注意CA JSON文件的<code>CN(Common Name)</code>与<code>O(Organization)</code>等内容是会影响Kubernetes组件认证的。<ul><li><code>CN</code> Common Name，kube-apiserver会从证书中提取该字段作为请求的用户名（User Name）</li><li><code>O</code> Oragnization，kube-apiserver会从证书中提取该字段作为请求用户的所属组（Group）</li></ul></li><li>CA是自签名根证书，用来给后续各种证书签名</li><li>kubernetes集群的所有状态信息都保存在etcd中，kubernetes组件会通过kube-apiserver读写etcd里面的信息</li><li>etcd如果暴露在公网且没做SSL/TLS验证，那么任何人都能读写数据，那么很可能会无端端在kubernetes集群里面多了挖坑Pod或者肉鸡Pod</li><li>本文使用<code>CFSSL</code>创建证书，证书有效期10年</li><li>建立证书过程在<font color="red" size="3">k8s-m1</font>上完成</li></ul></blockquote><h2 id="下载CFSSL工具"><a href="#下载CFSSL工具" class="headerlink" title="下载CFSSL工具"></a>下载CFSSL工具</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -O /usr/local/bin/cfssl-certinfo</span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -O /usr/local/bin/cfssl</span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -O /usr/local/bin/cfssljson</span><br><span class="line">chmod 755 /usr/local/bin/cfssl-certinfo \</span><br><span class="line">          /usr/local/bin/cfssl \</span><br><span class="line">          /usr/local/bin/cfssljson</span><br></pre></td></tr></table></figure><h2 id="创建工作目录"><a href="#创建工作目录" class="headerlink" title="创建工作目录"></a>创建工作目录</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/pki /root/master /root/worker</span><br><span class="line">cd /root/pki</span><br></pre></td></tr></table></figure><h2 id="创建用于生成证书的json文件"><a href="#创建用于生成证书的json文件" class="headerlink" title="创建用于生成证书的json文件"></a>创建用于生成证书的json文件</h2><h3 id="ca-config-json"><a href="#ca-config-json" class="headerlink" title="ca-config.json"></a>ca-config.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; ca-config.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "signing": &#123;</span><br><span class="line">    "default": &#123;</span><br><span class="line">      "expiry": "87600h"</span><br><span class="line">    &#125;,</span><br><span class="line">    "profiles": &#123;</span><br><span class="line">      "kubernetes": &#123;</span><br><span class="line">        "usages": [</span><br><span class="line">            "signing",</span><br><span class="line">            "key encipherment",</span><br><span class="line">            "server auth",</span><br><span class="line">            "client auth"</span><br><span class="line">        ],</span><br><span class="line">        "expiry": "87600h"</span><br><span class="line">      &#125;,</span><br><span class="line">      "etcd-server": &#123;</span><br><span class="line">        "usages": [</span><br><span class="line">            "signing",</span><br><span class="line">            "key encipherment",</span><br><span class="line">            "server auth",</span><br><span class="line">            "client auth"</span><br><span class="line">        ],</span><br><span class="line">        "expiry": "87600h"</span><br><span class="line">      &#125;,</span><br><span class="line">      "etcd-client": &#123;</span><br><span class="line">          "usages": [</span><br><span class="line">              "signing",</span><br><span class="line">              "key encipherment",</span><br><span class="line">              "client auth"</span><br><span class="line">          ],</span><br><span class="line">          "expiry": "87600h"</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="ca-csr-json"><a href="#ca-csr-json" class="headerlink" title="ca-csr.json"></a>ca-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; ca-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "kubernetes",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "Kubernetes",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="etcd-ca-csr-json"><a href="#etcd-ca-csr-json" class="headerlink" title="etcd-ca-csr.json"></a>etcd-ca-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd-ca-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "etcd",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "etcd",</span><br><span class="line">      "OU": "Etcd Security"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="etcd-server-csr-json"><a href="#etcd-server-csr-json" class="headerlink" title="etcd-server-csr.json"></a>etcd-server-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd-server-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "etcd-server",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "etcd",</span><br><span class="line">      "OU": "Etcd Security"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="etcd-client-csr-json"><a href="#etcd-client-csr-json" class="headerlink" title="etcd-client-csr.json"></a>etcd-client-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd-client-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "etcd-client",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "hosts": [</span><br><span class="line">    ""</span><br><span class="line">  ],</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "etcd",</span><br><span class="line">      "OU": "Etcd Security"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-apiserver-csr-json"><a href="#kube-apiserver-csr-json" class="headerlink" title="kube-apiserver-csr.json"></a>kube-apiserver-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-apiserver-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "kube-apiserver",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "Kubernetes",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-manager-csr-json"><a href="#kube-manager-csr-json" class="headerlink" title="kube-manager-csr.json"></a>kube-manager-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-manager-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "system:kube-controller-manager",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "system:kube-controller-manager",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-scheduler-csr-json"><a href="#kube-scheduler-csr-json" class="headerlink" title="kube-scheduler-csr.json"></a>kube-scheduler-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-scheduler-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "system:kube-scheduler",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "system:kube-scheduler",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-proxy-csr-json"><a href="#kube-proxy-csr-json" class="headerlink" title="kube-proxy-csr.json"></a>kube-proxy-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-proxy-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "system:kube-proxy",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "system:kube-proxy",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-admin-csr-json"><a href="#kube-admin-csr-json" class="headerlink" title="kube-admin-csr.json"></a>kube-admin-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-admin-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "admin",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "system:masters",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="front-proxy-ca-csr-json"><a href="#front-proxy-ca-csr-json" class="headerlink" title="front-proxy-ca-csr.json"></a>front-proxy-ca-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; front-proxy-ca-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "kubernetes",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="front-proxy-client-csr-json"><a href="#front-proxy-client-csr-json" class="headerlink" title="front-proxy-client-csr.json"></a>front-proxy-client-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; front-proxy-client-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "front-proxy-client",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="sa-csr-json"><a href="#sa-csr-json" class="headerlink" title="sa-csr.json"></a>sa-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; sa-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "service-accounts",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "Kubernetes",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="创建etcd证书"><a href="#创建etcd证书" class="headerlink" title="创建etcd证书"></a>创建etcd证书</h2><h3 id="etcd-ca证书"><a href="#etcd-ca证书" class="headerlink" title="etcd-ca证书"></a>etcd-ca证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建etcd-ca证书 ---'</span><br><span class="line">cfssl gencert -initca etcd-ca-csr.json | cfssljson -bare etcd-ca</span><br></pre></td></tr></table></figure><h3 id="etcd-server证书"><a href="#etcd-server证书" class="headerlink" title="etcd-server证书"></a>etcd-server证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建etcd-server证书 ---'</span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=etcd-ca.pem \</span><br><span class="line">      -ca-key=etcd-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -hostname=127.0.0.1,$(xargs -n1&lt;&lt;&lt;$&#123;MasterArray[@]&#125; | sort  | paste -d, -s -) \</span><br><span class="line">      -profile=etcd-server etcd-server-csr.json | cfssljson -bare etcd-server</span><br></pre></td></tr></table></figure><h3 id="etcd-client证书"><a href="#etcd-client证书" class="headerlink" title="etcd-client证书"></a>etcd-client证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建etcd-client证书 ---'</span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=etcd-ca.pem \</span><br><span class="line">      -ca-key=etcd-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=etcd-client etcd-client-csr.json | cfssljson -bare etcd-client</span><br></pre></td></tr></table></figure><h2 id="创建kubernetes证书"><a href="#创建kubernetes证书" class="headerlink" title="创建kubernetes证书"></a>创建kubernetes证书</h2><h3 id="kubernetes-CA-证书"><a href="#kubernetes-CA-证书" class="headerlink" title="kubernetes-CA 证书"></a>kubernetes-CA 证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建kubernetes-ca证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建kubernetes-ca证书</span></span><br><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare kube-ca</span><br></pre></td></tr></table></figure><h3 id="kube-apiserver证书"><a href="#kube-apiserver证书" class="headerlink" title="kube-apiserver证书"></a>kube-apiserver证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建kube-apiserver证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建kube-apiserver证书</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里的hostname字段中的10.96.0.1要跟上文提到的service cluster ip cidr对应</span></span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=kube-ca.pem \</span><br><span class="line">      -ca-key=kube-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -hostname=10.96.0.1,127.0.0.1,localhost,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.default.svc.cluster.local,$&#123;VIP&#125;,$(xargs -n1&lt;&lt;&lt;$&#123;MasterArray[@]&#125; | sort  | paste -d, -s -) \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      kube-apiserver-csr.json | cfssljson -bare kube-apiserver</span><br></pre></td></tr></table></figure><h3 id="kube-controller-manager证书"><a href="#kube-controller-manager证书" class="headerlink" title="kube-controller-manager证书"></a>kube-controller-manager证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建kube-controller-manager证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建kube-controller-manager证书</span></span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=kube-ca.pem \</span><br><span class="line">      -ca-key=kube-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      kube-manager-csr.json | cfssljson -bare kube-controller-manager</span><br></pre></td></tr></table></figure><h3 id="kube-scheduler证书"><a href="#kube-scheduler证书" class="headerlink" title="kube-scheduler证书"></a>kube-scheduler证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建kube-scheduler证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建kube-scheduler证书</span></span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=kube-ca.pem \</span><br><span class="line">      -ca-key=kube-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      kube-scheduler-csr.json | cfssljson -bare kube-scheduler</span><br></pre></td></tr></table></figure><h3 id="kube-proxy证书"><a href="#kube-proxy证书" class="headerlink" title="kube-proxy证书"></a>kube-proxy证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建kube-proxy证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建kube-proxy证书</span></span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=kube-ca.pem \</span><br><span class="line">      -ca-key=kube-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      kube-proxy-csr.json | cfssljson -bare kube-proxy</span><br></pre></td></tr></table></figure><h3 id="kube-admin证书"><a href="#kube-admin证书" class="headerlink" title="kube-admin证书"></a>kube-admin证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建kube-admin证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建kube-admin证书</span></span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=kube-ca.pem \</span><br><span class="line">      -ca-key=kube-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      kube-admin-csr.json | cfssljson -bare kube-admin</span><br></pre></td></tr></table></figure><h3 id="Front-Proxy证书"><a href="#Front-Proxy证书" class="headerlink" title="Front Proxy证书"></a>Front Proxy证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建Front Proxy Certificate证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建Front Proxy Certificate证书</span></span><br><span class="line">cfssl gencert -initca front-proxy-ca-csr.json | cfssljson -bare front-proxy-ca</span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=front-proxy-ca.pem \</span><br><span class="line">      -ca-key=front-proxy-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      front-proxy-client-csr.json | cfssljson -bare front-proxy-client</span><br></pre></td></tr></table></figure><h3 id="Service-Account证书"><a href="#Service-Account证书" class="headerlink" title="Service Account证书"></a>Service Account证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建service account证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建创建service account证书</span></span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=kube-ca.pem \</span><br><span class="line">      -ca-key=kube-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      sa-csr.json | cfssljson -bare sa</span><br></pre></td></tr></table></figure><h3 id="bootstrap-token"><a href="#bootstrap-token" class="headerlink" title="bootstrap-token"></a>bootstrap-token</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BOOTSTRAP_TOKEN=$(dd if=/dev/urandom bs=128 count=1 2&gt;/dev/null | base64 | tr -d "=+/[:space:]" | dd bs=32 count=1 2&gt;/dev/null)</span><br><span class="line">echo "BOOTSTRAP_TOKEN: $&#123;BOOTSTRAP_TOKEN&#125;"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建token.csv文件</span></span><br><span class="line">cat &gt; token.csv &lt;&lt;EOF</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;BOOTSTRAP_TOKEN&#125;,kubelet-bootstrap,10001,<span class="string">"system:bootstrappers"</span></span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="encryption-yaml"><a href="#encryption-yaml" class="headerlink" title="encryption.yaml"></a>encryption.yaml</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ENCRYPTION_TOKEN=$(head -c 32 /dev/urandom | base64)</span><br><span class="line">echo "ENCRYPTION_TOKEN: $&#123;ENCRYPTION_TOKEN&#125;"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建encryption.yaml文件</span></span><br><span class="line">cat &gt; encryption.yaml &lt;&lt;EOF</span><br><span class="line">kind: EncryptionConfig</span><br><span class="line">apiVersion: v1</span><br><span class="line">resources:</span><br><span class="line">  - resources:</span><br><span class="line">      - secrets</span><br><span class="line">    providers:</span><br><span class="line">      - aescbc:</span><br><span class="line">          keys:</span><br><span class="line">            - name: key1</span><br><span class="line">              secret: $&#123;ENCRYPTION_TOKEN&#125;</span><br><span class="line">      - identity: &#123;&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="audit-policy-yaml"><a href="#audit-policy-yaml" class="headerlink" title="audit-policy.yaml"></a>audit-policy.yaml</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建创建高级审计配置 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建高级审计配置</span></span><br><span class="line">cat &gt;&gt; audit-policy.yaml &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> Log all requests at the Metadata level.</span></span><br><span class="line">apiVersion: audit.k8s.io/v1beta1</span><br><span class="line">kind: Policy</span><br><span class="line">rules:</span><br><span class="line">- level: Metadata</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="创建kubeconfig文件"><a href="#创建kubeconfig文件" class="headerlink" title="创建kubeconfig文件"></a>创建kubeconfig文件</h2><h3 id="说明-1"><a href="#说明-1" class="headerlink" title="说明"></a>说明</h3><blockquote><ul><li>kubeconfig 文件用于组织关于集群、用户、命名空间和认证机制的信息。</li><li>命令行工具 <code>kubectl</code> 从 kubeconfig 文件中得到它要选择的集群以及跟集群 API server 交互的信息。</li><li>默认情况下，<code>kubectl</code> 会从 <code>$HOME/.kube</code> 目录下查找文件名为 <code>config</code> 的文件。</li></ul></blockquote><blockquote><p><strong>注意：</strong> 用于配置集群访问信息的文件叫作 <code>kubeconfig文件</code>，这是一种引用配置文件的通用方式，并不是说它的文件名就是 <code>kubeconfig</code>。</p></blockquote><h3 id="kube-controller-manager-kubeconfig"><a href="#kube-controller-manager-kubeconfig" class="headerlink" title="kube-controller-manager.kubeconfig"></a>kube-controller-manager.kubeconfig</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">echo "Create kube-controller-manager kubeconfig..."</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=kube-ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-controller-manager.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials system:kube-controller-manager \</span><br><span class="line">  --client-certificate=kube-controller-manager.pem \</span><br><span class="line">  --client-key=kube-controller-manager-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-controller-manager.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=system:kube-controller-manager \</span><br><span class="line">  --kubeconfig=kube-controller-manager.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line">kubectl config use-context default --kubeconfig=kube-controller-manager.kubeconfig</span><br></pre></td></tr></table></figure><h3 id="kube-scheduler-kubeconfig"><a href="#kube-scheduler-kubeconfig" class="headerlink" title="kube-scheduler.kubeconfig"></a>kube-scheduler.kubeconfig</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">echo "Create kube-scheduler kubeconfig..."</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=kube-ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-scheduler.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials system:kube-scheduler \</span><br><span class="line">  --client-certificate=kube-scheduler.pem \</span><br><span class="line">  --client-key=kube-scheduler-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-scheduler.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=system:kube-scheduler \</span><br><span class="line">  --kubeconfig=kube-scheduler.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line">kubectl config use-context default --kubeconfig=kube-scheduler.kubeconfig</span><br></pre></td></tr></table></figure><h3 id="kube-proxy-kubeconfig"><a href="#kube-proxy-kubeconfig" class="headerlink" title="kube-proxy.kubeconfig"></a>kube-proxy.kubeconfig</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">echo "Create kube-proxy kubeconfig..."</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=kube-ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials system:kube-proxy \</span><br><span class="line">  --client-certificate=kube-proxy.pem \</span><br><span class="line">  --client-key=kube-proxy-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=system:kube-proxy \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line">kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure><h3 id="kube-admin-kubeconfig"><a href="#kube-admin-kubeconfig" class="headerlink" title="kube-admin.kubeconfig"></a>kube-admin.kubeconfig</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">echo "Create kube-admin kubeconfig..."</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=kube-ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-admin.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials kubernetes-admin \</span><br><span class="line">  --client-certificate=kube-admin.pem \</span><br><span class="line">  --client-key=kube-admin-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-admin.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kubernetes-admin \</span><br><span class="line">  --kubeconfig=kube-admin.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line">kubectl config use-context default --kubeconfig=kube-admin.kubeconfig</span><br></pre></td></tr></table></figure><h3 id="bootstrap-kubeconfig"><a href="#bootstrap-kubeconfig" class="headerlink" title="bootstrap.kubeconfig"></a>bootstrap.kubeconfig</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">echo "Create kubelet bootstrapping kubeconfig..."</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=kube-ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials kubelet-bootstrap \</span><br><span class="line">  --token=$&#123;BOOTSTRAP_TOKEN&#125; \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kubelet-bootstrap \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line">kubectl config use-context default --kubeconfig=bootstrap.kubeconfig</span><br></pre></td></tr></table></figure><h3 id="清理证书CSR文件"><a href="#清理证书CSR文件" class="headerlink" title="清理证书CSR文件"></a>清理证书CSR文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 删除*.csr文件 ---'</span><br><span class="line">rm -rf *csr</span><br></pre></td></tr></table></figure><h2 id="修改文件权限"><a href="#修改文件权限" class="headerlink" title="修改文件权限"></a>修改文件权限</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chown root:root *pem *kubeconfig *yaml *csv</span><br><span class="line">chmod 0444 *pem *kubeconfig *yaml *csv</span><br><span class="line">chmod 0400 *key.pem</span><br></pre></td></tr></table></figure><h2 id="检查生成的文件"><a href="#检查生成的文件" class="headerlink" title="检查生成的文件"></a>检查生成的文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">ls -l | grep -v json</span><br><span class="line">-r--r--r-- 1 root root  113 Dec  6 15:36 audit-policy.yaml</span><br><span class="line">-r--r--r-- 1 root root 2207 Dec  6 15:36 bootstrap.kubeconfig</span><br><span class="line">-r--r--r-- 1 root root  240 Dec  6 15:36 encryption.yaml</span><br><span class="line">-r-------- 1 root root 1675 Dec  6 15:36 etcd-ca-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1375 Dec  6 15:36 etcd-ca.pem</span><br><span class="line">-r-------- 1 root root 1679 Dec  6 15:36 etcd-client-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1424 Dec  6 15:36 etcd-client.pem</span><br><span class="line">-r-------- 1 root root 1679 Dec  6 15:36 etcd-server-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1468 Dec  6 15:36 etcd-server.pem</span><br><span class="line">-r-------- 1 root root 1679 Dec  6 15:36 front-proxy-ca-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1143 Dec  6 15:36 front-proxy-ca.pem</span><br><span class="line">-r-------- 1 root root 1675 Dec  6 15:36 front-proxy-client-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1188 Dec  6 15:36 front-proxy-client.pem</span><br><span class="line">-r-------- 1 root root 1679 Dec  6 15:36 kube-admin-key.pem</span><br><span class="line">-r--r--r-- 1 root root 6345 Dec  6 15:36 kube-admin.kubeconfig</span><br><span class="line">-r--r--r-- 1 root root 1419 Dec  6 15:36 kube-admin.pem</span><br><span class="line">-r-------- 1 root root 1675 Dec  6 15:36 kube-apiserver-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1688 Dec  6 15:36 kube-apiserver.pem</span><br><span class="line">-r-------- 1 root root 1679 Dec  6 15:36 kube-ca-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1387 Dec  6 15:36 kube-ca.pem</span><br><span class="line">-r-------- 1 root root 1679 Dec  6 15:36 kube-controller-manager-key.pem</span><br><span class="line">-r--r--r-- 1 root root 6449 Dec  6 15:36 kube-controller-manager.kubeconfig</span><br><span class="line">-r--r--r-- 1 root root 1476 Dec  6 15:36 kube-controller-manager.pem</span><br><span class="line">-r-------- 1 root root 1675 Dec  6 15:36 kube-proxy-key.pem</span><br><span class="line">-r--r--r-- 1 root root 6371 Dec  6 15:36 kube-proxy.kubeconfig</span><br><span class="line">-r--r--r-- 1 root root 1440 Dec  6 15:36 kube-proxy.pem</span><br><span class="line">-r-------- 1 root root 1675 Dec  6 15:36 kube-scheduler-key.pem</span><br><span class="line">-r--r--r-- 1 root root 6395 Dec  6 15:36 kube-scheduler.kubeconfig</span><br><span class="line">-r--r--r-- 1 root root 1452 Dec  6 15:36 kube-scheduler.pem</span><br><span class="line">-r-------- 1 root root 1675 Dec  6 15:36 sa-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1432 Dec  6 15:36 sa.pem</span><br><span class="line">-r--r--r-- 1 root root   80 Dec  6 15:36 token.csv</span><br></pre></td></tr></table></figure><h1 id="kubernetes-master节点"><a href="#kubernetes-master节点" class="headerlink" title="kubernetes-master节点"></a>kubernetes-master节点</h1><p>本节介绍如何部署kubernetes master节点</p><h2 id="master节点说明"><a href="#master节点说明" class="headerlink" title="master节点说明"></a><strong>master节点说明</strong></h2><blockquote><ul><li>原则上，master节点不应该运行业务Pod，且不应该暴露到公网环境！！</li><li>边界节点，应该交由<code>worker</code>节点或者运行<code>Ingress</code>的节点来承担</li><li>以<code>kubeadm</code>部署为例，部署完成后，会给master节点添加<code>node-role.kubernetes.io/master=&#39;&#39;</code>标签（Labels）并且会对带有此标签的节点添加<code>node-role.kubernetes.io/master:NoSchedule</code>污点（taints），这样不能容忍此污点的Pod无法调度到master节点</li><li>本文中，在kubelet启动参数里，默认添加<code>node-role.kubernetes.io/node=&#39;&#39;</code>标签（Labels），且没有对master节点添加<code>node-role.kubernetes.io/master:NoSchedule</code>污点（taints）</li><li>生产环境中最好参照kubeadm，对master节点添加<code>node-role.kubernetes.io/master=&#39;&#39;</code>标签（Labels）和<code>node-role.kubernetes.io/master:NoSchedule</code>污点（taints）</li></ul></blockquote><p><strong>kube-apiserver</strong></p><blockquote><ul><li>以 REST APIs 提供 Kubernetes 资源的 CRUD,如授权、认证、存取控制与 API 注册等机制。</li><li>关闭默认非安全端口8080,在安全端口 6443 接收 https 请求</li><li>严格的认证和授权策略 (x509、token、RBAC)</li><li>开启 bootstrap token 认证，支持 kubelet TLS bootstrapping</li><li>使用 https 访问 kubelet、etcd，加密通信</li></ul></blockquote><p><strong>kube-controller-manager</strong></p><blockquote><ul><li>通过核心控制循环(Core Control Loop)监听 Kubernetes API<br>的资源来维护集群的状态，这些资源会被不同的控制器所管理，如 Replication Controller、Namespace<br>Controller 等等。而这些控制器会处理着自动扩展、滚动更新等等功能。</li><li>关闭非安全端口，在安全端口 10252 接收 https 请求</li><li>使用 kubeconfig 访问 kube-apiserver 的安全端口</li></ul></blockquote><p><strong>kube-scheduler</strong></p><blockquote><ul><li>负责将一个(或多个)容器依据调度策略分配到对应节点上让容器引擎(如 Docker)执行。</li><li>调度受到 QoS 要求、软硬性约束、亲和性(Affinity)等等因素影响。</li></ul></blockquote><p><strong>HAProxy</strong></p><blockquote><ul><li>提供多个 API Server 的负载均衡(Load Balance)</li><li>监听VIP的<code>8443</code>端口负载均衡到三台master节点的<code>6443</code>端口</li></ul></blockquote><p><strong>Keepalived</strong></p><blockquote><ul><li>提供虚拟IP位址(VIP),来让vip落在可用的master主机上供所有组件访问master节点</li><li>提供健康检查脚本用于切换VIP</li></ul></blockquote><h2 id="添加用户"><a href="#添加用户" class="headerlink" title="添加用户"></a>添加用户</h2><blockquote><ul><li>这里强迫症发作，指定了<code>UID</code>和<code>GID</code></li><li>不指定<code>UID</code>和<code>GID</code>也可以</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo '--- master节点添加用户 ---'</span><br><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    ssh $&#123;NODE&#125; /usr/sbin/groupadd -r -g 10000 kube</span><br><span class="line">    ssh $&#123;NODE&#125; /usr/sbin/groupadd -r -g 10001 etcd</span><br><span class="line">    ssh $&#123;NODE&#125; /usr/sbin/useradd -r -g kube -u 10000 -s /bin/false kube</span><br><span class="line">    ssh $&#123;NODE&#125; /usr/sbin/useradd -r -g etcd -u 10001 -s /bin/false etcd</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">echo '--- master节点创建目录 ---'</span><br><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    echo "--- 创建目录 ---"</span><br><span class="line">    ssh $&#123;NODE&#125; /usr/bin/mkdir -p /etc/etcd/ssl \</span><br><span class="line">                                  /etc/kubernetes/pki \</span><br><span class="line">                                  /etc/kubernetes/manifests \</span><br><span class="line">                                  /var/lib/etcd \</span><br><span class="line">                                  /var/lib/kubelet \</span><br><span class="line">                                  /var/run/kubernetes \</span><br><span class="line">                                  /var/log/kube-audit \</span><br><span class="line">                                  /etc/cni/net.d \</span><br><span class="line">                                  /opt/cni/bin </span><br><span class="line">    echo "--- 修改目录权限 ---"</span><br><span class="line">    ssh $&#123;NODE&#125; /usr/bin/chmod 0755 /etc/etcd \</span><br><span class="line">                                    /etc/etcd/ssl \</span><br><span class="line">                                    /etc/kubernetes \</span><br><span class="line">                                    /etc/kubernetes/pki \</span><br><span class="line">                                    /var/lib/etcd \</span><br><span class="line">                                    /var/lib/kubelet \</span><br><span class="line">                                    /var/log/kube-audit \</span><br><span class="line">                                    /var/run/kubernetes \</span><br><span class="line">                                    /etc/cni/net.d \</span><br><span class="line">                                    /opt/cni/bin </span><br><span class="line">    echo "--- 修改目录属组 ---"</span><br><span class="line">    ssh $&#123;NODE&#125; chown -R etcd:etcd /etc/etcd/ /var/lib/etcd</span><br><span class="line">    ssh $&#123;NODE&#125; chown -R kube:kube /etc/kubernetes \</span><br><span class="line">                                   /var/lib/kubelet \</span><br><span class="line">                                   /var/log/kube-audit \</span><br><span class="line">                                   /var/run/kubernetes</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="分发证书文件和kubeconfig到master节点"><a href="#分发证书文件和kubeconfig到master节点" class="headerlink" title="分发证书文件和kubeconfig到master节点"></a>分发证书文件和kubeconfig到master节点</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "---- $NODE ----"</span><br><span class="line">    echo '---- 分发etcd证书 ----'</span><br><span class="line">    rsync -avpt /root/pki/etcd-ca-key.pem \</span><br><span class="line">                /root/pki/etcd-ca.pem \</span><br><span class="line">                /root/pki/etcd-client-key.pem \</span><br><span class="line">                /root/pki/etcd-client.pem \</span><br><span class="line">                /root/pki/etcd-server-key.pem \</span><br><span class="line">                /root/pki/etcd-server.pem \</span><br><span class="line">                $NODE:/etc/etcd/ssl/</span><br><span class="line">    echo '---- 分发kubeconfig文件 yaml文件 token.csv ----'</span><br><span class="line">    rsync -avpt /root/pki/kube-admin.kubeconfig \</span><br><span class="line">                /root/pki/kube-controller-manager.kubeconfig \</span><br><span class="line">                /root/pki/kube-scheduler.kubeconfig \</span><br><span class="line">                /root/pki/audit-policy.yaml \</span><br><span class="line">                /root/pki/encryption.yaml \</span><br><span class="line">                /root/pki/token.csv \</span><br><span class="line">                $NODE:/etc/kubernetes/</span><br><span class="line">    echo '---- 分发sa证书 kube证书 front-proxy证书 ----'</span><br><span class="line">    rsync -avpt /root/pki/etcd-ca.pem \</span><br><span class="line">                /root/pki/etcd-client-key.pem \</span><br><span class="line">                /root/pki/etcd-client.pem \</span><br><span class="line">                /root/pki/front-proxy-ca.pem \</span><br><span class="line">                /root/pki/front-proxy-client-key.pem \</span><br><span class="line">                /root/pki/front-proxy-client.pem \</span><br><span class="line">                /root/pki/kube-apiserver-key.pem \</span><br><span class="line">                /root/pki/kube-apiserver.pem \</span><br><span class="line">                /root/pki/kube-ca.pem \</span><br><span class="line">                /root/pki/kube-ca-key.pem \</span><br><span class="line">                /root/pki/sa-key.pem \</span><br><span class="line">                /root/pki/sa.pem \</span><br><span class="line">                $NODE:/etc/kubernetes/pki/</span><br><span class="line">    ssh $NODE chown -R etcd:etcd /etc/etcd</span><br><span class="line">    ssh $NODE chown -R kube:kube /etc/kubernetes</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="分发二进制文件"><a href="#分发二进制文件" class="headerlink" title="分发二进制文件"></a>分发二进制文件</h2><blockquote><ul><li>在<font color="red" size="3">k8s-m1</font>上操作</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 分发kubernetes和etcd二进制文件 ---'</span><br><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    rsync -avpt /root/software/kubernetes/server/bin/hyperkube \</span><br><span class="line">                /root/software/kubernetes/server/bin/kube-controller-manager \</span><br><span class="line">                /root/software/kubernetes/server/bin/kubectl \</span><br><span class="line">                /root/software/kubernetes/server/bin/apiextensions-apiserver \</span><br><span class="line">                /root/software/kubernetes/server/bin/kube-apiserver \</span><br><span class="line">                /root/software/kubernetes/server/bin/kubeadm \</span><br><span class="line">                /root/software/kubernetes/server/bin/kube-aggregator \</span><br><span class="line">                /root/software/kubernetes/server/bin/kube-scheduler \</span><br><span class="line">                /root/software/kubernetes/server/bin/cloud-controller-manager \</span><br><span class="line">                /root/software/kubernetes/server/bin/mounter \</span><br><span class="line">                /root/software/etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcdctl \</span><br><span class="line">                /root/software/etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcd \</span><br><span class="line">                $NODE:/usr/local/bin/</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="部署配置Keepalived和HAProxy"><a href="#部署配置Keepalived和HAProxy" class="headerlink" title="部署配置Keepalived和HAProxy"></a>部署配置Keepalived和HAProxy</h2><blockquote><ul><li>在<font color="red" size="3">k8s-m1</font>上操作</li></ul></blockquote><h3 id="切换工作目录"><a href="#切换工作目录" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/master</span><br></pre></td></tr></table></figure><h3 id="安装Keepalived和HAProxy"><a href="#安装Keepalived和HAProxy" class="headerlink" title="安装Keepalived和HAProxy"></a>安装Keepalived和HAProxy</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "---- $NODE ----"</span><br><span class="line">    echo "---- 安装haproxy和keepalived ----"</span><br><span class="line">    ssh $NODE yum install keepalived haproxy -y</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="配置keepalived"><a href="#配置keepalived" class="headerlink" title="配置keepalived"></a>配置keepalived</h3><blockquote><ul><li>编辑<code>keepalived.conf</code>模板</li><li>替换<code>keepalived.conf</code>的字符串</li><li>编辑<code>check_haproxy.sh</code></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; keepalived.conf.example &lt;&lt;EOF</span><br><span class="line">vrrp_script haproxy-check &#123;</span><br><span class="line">    script "/bin/bash /etc/keepalived/check_haproxy.sh"</span><br><span class="line">    interval 3</span><br><span class="line">    weight -2</span><br><span class="line">    fall 10</span><br><span class="line">    rise 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance haproxy-vip &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    priority 101</span><br><span class="line">    interface &#123;&#123; VIP_IFACE &#125;&#125;</span><br><span class="line">    virtual_router_id 47</span><br><span class="line">    advert_int 3</span><br><span class="line"></span><br><span class="line">    unicast_peer &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        &#123;&#123; VIP &#125;&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    track_script &#123;</span><br><span class="line">        haproxy-check</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 替换字符</span></span><br><span class="line">sed -r -e "s#\&#123;\&#123; VIP \&#125;\&#125;#$&#123;VIP&#125;#" \</span><br><span class="line">       -e "s#\&#123;\&#123; VIP_IFACE \&#125;\&#125;#$&#123;VIP_IFACE&#125;#" \</span><br><span class="line">       -e '/unicast_peer/r '&lt;(xargs -n1&lt;&lt;&lt;$&#123;MasterArray[@]&#125; | sort | sed 's#^#\t#') \</span><br><span class="line">       keepalived.conf.example &gt; keepalived.conf</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; check_haproxy.sh &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">VIRTUAL_IP=$&#123;VIP&#125;</span><br><span class="line"></span><br><span class="line">errorExit() &#123;</span><br><span class="line">    echo "*** $*" 1&gt;&amp;2</span><br><span class="line">    exit 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if ip addr | grep -q \$VIRTUAL_IP ; then</span><br><span class="line">    curl -s --max-time 2 --insecure https://\$&#123;VIRTUAL_IP&#125;:8443/ -o /dev/null || errorExit "Error GET https://\$&#123;VIRTUAL_IP&#125;:8443/"</span><br><span class="line">fi</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="配置haproxy"><a href="#配置haproxy" class="headerlink" title="配置haproxy"></a>配置haproxy</h3><blockquote><ul><li>编辑<code>haproxy.cfg</code>模板</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; haproxy.cfg.example &lt;&lt;EOF</span><br><span class="line">global</span><br><span class="line">  maxconn  2000</span><br><span class="line">  ulimit-n  16384</span><br><span class="line">  log  127.0.0.1 local0 err</span><br><span class="line">  stats timeout 30s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">  log global</span><br><span class="line">  mode  http</span><br><span class="line">  option  httplog</span><br><span class="line">  timeout connect 5000</span><br><span class="line">  timeout client  50000</span><br><span class="line">  timeout server  50000</span><br><span class="line">  timeout http-request 15s</span><br><span class="line">  timeout http-keep-alive 15s</span><br><span class="line"></span><br><span class="line">frontend monitor-in</span><br><span class="line">  bind $&#123;VIP&#125;:33305</span><br><span class="line">  mode http</span><br><span class="line">  option httplog</span><br><span class="line">  monitor-uri /monitor</span><br><span class="line"></span><br><span class="line">listen stats</span><br><span class="line">  bind    $&#123;VIP&#125;:8006</span><br><span class="line">  mode    http</span><br><span class="line">  stats   enable</span><br><span class="line">  stats   hide-version</span><br><span class="line">  stats   uri       /stats</span><br><span class="line">  stats   refresh   30s</span><br><span class="line">  stats   realm     Haproxy\ Statistics</span><br><span class="line">  stats   auth      admin:admin</span><br><span class="line"></span><br><span class="line">frontend k8s-api</span><br><span class="line">  bind $&#123;VIP&#125;:8443</span><br><span class="line">  mode tcp</span><br><span class="line">  option tcplog</span><br><span class="line">  tcp-request inspect-delay 5s</span><br><span class="line">  default_backend k8s-api</span><br><span class="line"></span><br><span class="line">backend k8s-api</span><br><span class="line">  mode tcp</span><br><span class="line">  option tcplog</span><br><span class="line">  option tcp-check</span><br><span class="line">  balance roundrobin</span><br><span class="line">  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 替换字符</span></span><br><span class="line">sed -e '$r '&lt;(paste &lt;( seq -f'  server k8s-api-%g'  $&#123;#MasterArray[@]&#125; ) &lt;( xargs -n1&lt;&lt;&lt;$&#123;MasterArray[@]&#125; | sort | sed 's#$#:6443  check#')) haproxy.cfg.example &gt; haproxy.cfg</span><br></pre></td></tr></table></figure><h3 id="分发配置文件到master节点"><a href="#分发配置文件到master节点" class="headerlink" title="分发配置文件到master节点"></a>分发配置文件到master节点</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "---- $NODE ----"</span><br><span class="line">rsync -avpt haproxy.cfg $NODE:/etc/haproxy/</span><br><span class="line">rsync -avpt keepalived.conf \</span><br><span class="line">            check_haproxy.sh \</span><br><span class="line">            $NODE:/etc/keepalived/</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="启动keepalived和haproxy"><a href="#启动keepalived和haproxy" class="headerlink" title="启动keepalived和haproxy"></a>启动keepalived和haproxy</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "---- $NODE ----"</span><br><span class="line">ssh $NODE systemctl enable --now keepalived haproxy</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="验证VIP"><a href="#验证VIP" class="headerlink" title="验证VIP"></a>验证VIP</h3><blockquote><ul><li>需要大约十秒的时间等待keepalived和haproxy服务起来</li><li>这里由于后端的kube-apiserver服务还没启动，只测试是否能ping通VIP</li><li>如果VIP没起来，就要去确认一下各master节点的keepalived服务是否正常</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sleep 15</span><br><span class="line">ping -c 4 $VIP</span><br></pre></td></tr></table></figure><h2 id="部署etcd集群"><a href="#部署etcd集群" class="headerlink" title="部署etcd集群"></a>部署etcd集群</h2><blockquote><ul><li>每个etcd节点的配置都需要做对应更改</li><li>在<font color="red" size="3">k8s-m1</font>上操作</li></ul></blockquote><h3 id="配置etcd-service文件"><a href="#配置etcd-service文件" class="headerlink" title="配置etcd.service文件"></a>配置etcd.service文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Service</span><br><span class="line">Documentation=https://coreos.com/etcd/docs/latest/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=etcd</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/local/bin/etcd --config-file=/etc/etcd/etcd.config.yaml</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">Alias=etcd3.service</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="etcd-config-yaml模板"><a href="#etcd-config-yaml模板" class="headerlink" title="etcd.config.yaml模板"></a>etcd.config.yaml模板</h3><blockquote><ul><li>关于各个参数的说明可以看<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/configuration.md" target="_blank" rel="noopener">这里</a></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd.config.yaml.example &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> This is the configuration file <span class="keyword">for</span> the etcd server.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Human-readable name <span class="keyword">for</span> this member.</span></span><br><span class="line">name: '&#123;HOSTNAME&#125;'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Path to the data directory.</span></span><br><span class="line">data-dir: '/var/lib/etcd/&#123;HOSTNAME&#125;.data/'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Path to the dedicated wal directory.</span></span><br><span class="line">wal-dir: '/var/lib/etcd/&#123;HOSTNAME&#125;.wal/'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Number of committed transactions to trigger a snapshot to disk.</span></span><br><span class="line">snapshot-count: 5000</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) of a heartbeat interval.</span></span><br><span class="line">heartbeat-interval: 100</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) <span class="keyword">for</span> an election to timeout.</span></span><br><span class="line">election-timeout: 1000</span><br><span class="line"><span class="meta">#</span><span class="bash"> Raise alarms when backend size exceeds the given quota. 0 means use the</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> default quota.</span></span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line"><span class="meta">#</span><span class="bash"> List of comma separated URLs to listen on <span class="keyword">for</span> peer traffic.</span></span><br><span class="line">listen-peer-urls: 'https://&#123;PUBLIC_IP&#125;:2380'</span><br><span class="line"><span class="meta">#</span><span class="bash"> List of comma separated URLs to listen on <span class="keyword">for</span> client traffic.</span></span><br><span class="line">listen-client-urls: 'https://&#123;PUBLIC_IP&#125;:2379,http://127.0.0.1:2379'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Maximum number of snapshot files to retain (0 is unlimited).</span></span><br><span class="line">max-snapshots: 3</span><br><span class="line"><span class="meta">#</span><span class="bash"> Maximum number of wal files to retain (0 is unlimited).</span></span><br><span class="line">max-wals: 5</span><br><span class="line"><span class="meta">#</span><span class="bash"> Comma-separated white list of origins <span class="keyword">for</span> CORS (cross-origin resource sharing).</span></span><br><span class="line">cors:</span><br><span class="line"><span class="meta">#</span><span class="bash"> List of this member<span class="string">'s peer URLs to advertise to the rest of the cluster.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The URLs needed to be a comma-separated list.</span></span><br><span class="line">initial-advertise-peer-urls: 'https://&#123;PUBLIC_IP&#125;:2380'</span><br><span class="line"><span class="meta">#</span><span class="bash"> List of this member<span class="string">'s client URLs to advertise to the public.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The URLs needed to be a comma-separated list.</span></span><br><span class="line">advertise-client-urls: 'https://&#123;PUBLIC_IP&#125;:2379'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Discovery URL used to bootstrap the cluster.</span></span><br><span class="line">discovery:</span><br><span class="line"><span class="meta">#</span><span class="bash"> Valid values include <span class="string">'exit'</span>, <span class="string">'proxy'</span></span></span><br><span class="line">discovery-fallback: 'proxy'</span><br><span class="line"><span class="meta">#</span><span class="bash"> HTTP proxy to use <span class="keyword">for</span> traffic to discovery service.</span></span><br><span class="line">discovery-proxy:</span><br><span class="line"><span class="meta">#</span><span class="bash"> DNS domain used to bootstrap initial cluster.</span></span><br><span class="line">discovery-srv:</span><br><span class="line"><span class="meta">#</span><span class="bash"> Initial cluster configuration <span class="keyword">for</span> bootstrapping.</span></span><br><span class="line">initial-cluster: '$&#123;ETCD_INITIAL_CLUSTER&#125;'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Initial cluster token <span class="keyword">for</span> the etcd cluster during bootstrap.</span></span><br><span class="line">initial-cluster-token: 'etcd-k8s-cluster'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Initial cluster state (<span class="string">'new'</span> or <span class="string">'existing'</span>).</span></span><br><span class="line">initial-cluster-state: 'new'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Reject reconfiguration requests that would cause quorum loss.</span></span><br><span class="line">strict-reconfig-check: false</span><br><span class="line"><span class="meta">#</span><span class="bash"> Accept etcd V2 client requests</span></span><br><span class="line">enable-v2: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> Enable runtime profiling data via HTTP server</span></span><br><span class="line">enable-pprof: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> Valid values include <span class="string">'on'</span>, <span class="string">'readonly'</span>, <span class="string">'off'</span></span></span><br><span class="line">proxy: 'off'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) an endpoint will be held <span class="keyword">in</span> a failed state.</span></span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) of the endpoints refresh interval.</span></span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) <span class="keyword">for</span> a dial to timeout.</span></span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) <span class="keyword">for</span> a write to timeout.</span></span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) <span class="keyword">for</span> a <span class="built_in">read</span> to timeout.</span></span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Path to the client server TLS cert file.</span></span><br><span class="line">  cert-file: '/etc/etcd/ssl/etcd-server.pem'</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Path to the client server TLS key file.</span></span><br><span class="line">  key-file: '/etc/etcd/ssl/etcd-server-key.pem'</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Enable client cert authentication.</span></span><br><span class="line">  client-cert-auth: true</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Path to the client server TLS trusted CA cert file.</span></span><br><span class="line">  trusted-ca-file: '/etc/etcd/ssl/etcd-ca.pem'</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Client TLS using generated certificates</span></span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Path to the peer server TLS cert file.</span></span><br><span class="line">  cert-file: '/etc/etcd/ssl/etcd-server.pem'</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Path to the peer server TLS key file.</span></span><br><span class="line">  key-file: '/etc/etcd/ssl/etcd-server-key.pem'</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Enable peer client cert authentication.</span></span><br><span class="line">  client-cert-auth: true</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Path to the peer server TLS trusted CA cert file.</span></span><br><span class="line">  trusted-ca-file: '/etc/etcd/ssl/etcd-ca.pem'</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Peer TLS using generated certificates.</span></span><br><span class="line">  auto-tls: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> Enable debug-level logging <span class="keyword">for</span> etcd.</span></span><br><span class="line">debug: false</span><br><span class="line">logger: 'zap'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Specify <span class="string">'stdout'</span> or <span class="string">'stderr'</span> to skip journald logging even when running under systemd.</span></span><br><span class="line">log-outputs: [default]</span><br><span class="line"><span class="meta">#</span><span class="bash"> Force to create a new one member cluster.</span></span><br><span class="line">force-new-cluster: false</span><br><span class="line">auto-compaction-mode: 'periodic'</span><br><span class="line">auto-compaction-retention: '1'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Set level of detail <span class="keyword">for</span> exported metrics, specify <span class="string">'extensive'</span> to include histogram metrics.</span></span><br><span class="line">metrics: 'basic'</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="分发配置文件"><a href="#分发配置文件" class="headerlink" title="分发配置文件"></a>分发配置文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 根据节点信息替换文本，分发到各etcd节点</span></span><br><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE $&#123;MasterArray[$NODE]&#125; ---"</span><br><span class="line">    sed -e "s/&#123;HOSTNAME&#125;/$NODE/g" \</span><br><span class="line">        -e "s/&#123;PUBLIC_IP&#125;/$&#123;MasterArray[$NODE]&#125;/g" \</span><br><span class="line">        etcd.config.yaml.example &gt; etcd.config.yaml.$&#123;NODE&#125;</span><br><span class="line">    rsync -avpt etcd.config.yaml.$&#123;NODE&#125; $&#123;NODE&#125;:/etc/etcd/etcd.config.yaml</span><br><span class="line">    rsync -avpt etcd.service $&#123;NODE&#125;:/usr/lib/systemd/system/etcd.service</span><br><span class="line">    ssh $&#123;NODE&#125; systemctl daemon-reload</span><br><span class="line">    ssh $&#123;NODE&#125; chown -R etcd:etcd /etc/etcd</span><br><span class="line">    rm -rf etcd.config.yaml.$&#123;NODE&#125;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="启动etcd集群"><a href="#启动etcd集群" class="headerlink" title="启动etcd集群"></a>启动etcd集群</h3><blockquote><ul><li>etcd 进程首次启动时会等待其它节点的 etcd 加入集群，命令 systemctl start etcd 会卡住一段时间，为正常现象</li><li>启动之后可以通过<code>etcdctl</code>命令查看集群状态</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE $&#123;MasterArray[$NODE]&#125; ---"</span><br><span class="line">    ssh $NODE systemctl enable etcd</span><br><span class="line">    ssh $NODE systemctl start etcd &amp;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><blockquote><ul><li>为方便维护，可使用alias简化etcdctl命令</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /root/.bashrc &lt;&lt;EOF</span><br><span class="line">alias etcdctl2="export ETCDCTL_API=2;etcdctl --ca-file '/etc/etcd/ssl/etcd-ca.pem' --cert-file '/etc/etcd/ssl/etcd-client.pem' --key-file '/etc/etcd/ssl/etcd-client-key.pem' --endpoints $&#123;ETCD_SERVERS&#125;"</span><br><span class="line">alias etcdctl3="export ETCDCTL_API=3;etcdctl --cacert=/etc/etcd/ssl/etcd-ca.pem --cert=/etc/etcd/ssl/etcd-client.pem --key=/etc/etcd/ssl/etcd-client-key.pem --endpoints=$&#123;ETCD_SERVERS&#125;"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="验证etcd集群状态"><a href="#验证etcd集群状态" class="headerlink" title="验证etcd集群状态"></a>验证etcd集群状态</h3><blockquote><ul><li>etcd提供v2和v3两套API，kubernetes使用v3</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 应用上面定义的<span class="built_in">alias</span></span></span><br><span class="line">source /root/.bashrc</span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用v2 API访问etcd的集群状态</span></span><br><span class="line">etcdctl2 cluster-health</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">member 222fd3b0bb4a5931 is healthy: got healthy result from https://172.16.80.203:2379</span><br><span class="line">member 8349ef180b115a83 is healthy: got healthy result from https://172.16.80.201:2379</span><br><span class="line">member f525d2d797a7c465 is healthy: got healthy result from https://172.16.80.202:2379</span><br><span class="line">cluster is healthy</span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用v2 API访问etcd成员列表</span></span><br><span class="line">etcdctl2 member list</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">222fd3b0bb4a5931: name=k8s-m3 peerURLs=https://172.16.80.203:2380 clientURLs=https://172.16.80.203:2379 isLeader=false</span><br><span class="line">8349ef180b115a83: name=k8s-m1 peerURLs=https://172.16.80.201:2380 clientURLs=https://172.16.80.201:2379 isLeader=false</span><br><span class="line">f525d2d797a7c465: name=k8s-m2 peerURLs=https://172.16.80.202:2380 clientURLs=https://172.16.80.202:2379 isLeader=true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用v3 API访问etcd的endpoint状态</span></span><br><span class="line">etcdctl3 endpoint health</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">https://172.16.80.201:2379 is healthy: successfully committed proposal: took = 2.879402ms</span><br><span class="line">https://172.16.80.203:2379 is healthy: successfully committed proposal: took = 6.708566ms</span><br><span class="line">https://172.16.80.202:2379 is healthy: successfully committed proposal: took = 7.187607ms</span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用v3 API访问etcd成员列表</span></span><br><span class="line">etcdctl3 member list --write-out=table</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">+------------------+---------+--------+----------------------------+----------------------------+</span><br><span class="line">|        ID        | STATUS  |  NAME  |         PEER ADDRS         |        CLIENT ADDRS        |</span><br><span class="line">+------------------+---------+--------+----------------------------+----------------------------+</span><br><span class="line">| 222fd3b0bb4a5931 | started | k8s-m3 | https://172.16.80.203:2380 | https://172.16.80.203:2379 |</span><br><span class="line">| 8349ef180b115a83 | started | k8s-m1 | https://172.16.80.201:2380 | https://172.16.80.201:2379 |</span><br><span class="line">| f525d2d797a7c465 | started | k8s-m2 | https://172.16.80.202:2380 | https://172.16.80.202:2379 |</span><br><span class="line">+------------------+---------+--------+----------------------------+----------------------------+</span><br></pre></td></tr></table></figure><h2 id="Master组件服务"><a href="#Master组件服务" class="headerlink" title="Master组件服务"></a>Master组件服务</h2><h3 id="master组件配置模板"><a href="#master组件配置模板" class="headerlink" title="master组件配置模板"></a>master组件配置模板</h3><h4 id="kube-apiserver-conf"><a href="#kube-apiserver-conf" class="headerlink" title="kube-apiserver.conf"></a>kube-apiserver.conf</h4><blockquote><ul><li><p><code>--allow-privileged=true</code>启用容器特权模式</p></li><li><p><code>--apiserver-count=3</code>指定集群运行模式，其它节点处于阻塞状态</p></li><li><p><code>--audit-policy-file=/etc/kubernetes/audit-policy.yaml</code> 基于audit-policy.yaml文件定义的内容启动审计功能</p></li><li><p><code>--authorization-mode=Node,RBAC</code>开启 Node 和 RBAC 授权模式，拒绝未授权的请求</p></li><li><p><code>--disable-admission-plugins=</code>和<code>--enable-admission-plugins</code>禁用和启用准入控制插件。</p><p>准入控制插件会在请求通过认证和授权之后、对象被持久化之前拦截到达apiserver的请求。</p><p>准入控制插件依次执行，因此需要注意顺序。</p><p>如果插件序列中任何一个拒绝了请求，则整个请求将立刻被拒绝并返回错误给客户端。</p><p>关于admission-plugins官方文档里面有推荐配置，这里直接采用官方配置，注意针对不同kubernetes版本都会有不一样的配置，具体可以看<a href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#is-there-a-recommended-set-of-admission-controllers-to-use" target="_blank" rel="noopener">这里</a></p></li><li><p><code>--enable-bootstrap-token-auth=true</code>启用 kubelet bootstrap 的 token 认证</p></li><li><p><code>--experimental-encryption-provider-config=/etc/kubernetes/encryption.yaml</code>启用加密特性将Secret数据加密存储到etcd</p></li><li><p><code>--insecure-port=0</code>关闭监听非安全端口8080</p></li><li><p><code>--runtime-config=api/all=true</code>启用所有版本的 APIs</p></li><li><p><code>--service-cluster-ip-range=10.96.0.0/12</code>指定 Service Cluster IP 地址段</p></li><li><p><code>--service-node-port-range=30000-32767</code>指定 NodePort 的端口范围</p></li><li><p><code>--token-auth-file=/etc/kubernetes/token.csv</code>保存bootstrap的token信息</p></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-apiserver.conf.example &lt;&lt;EOF</span><br><span class="line">KUBE_APISERVER_ARGS=" \\</span><br><span class="line">--advertise-address=&#123;PUBLIC_IP&#125;  \\</span><br><span class="line">--allow-privileged=true  \\</span><br><span class="line">--apiserver-count=3 \\</span><br><span class="line">--audit-log-maxage=30  \\</span><br><span class="line">--audit-log-maxbackup=3  \\</span><br><span class="line">--audit-log-maxsize=100  \\</span><br><span class="line">--audit-log-path=/var/log/kube-audit/audit.log  \\</span><br><span class="line">--audit-policy-file=/etc/kubernetes/audit-policy.yaml  \\</span><br><span class="line">--authorization-mode=Node,RBAC  \\</span><br><span class="line">--bind-address=0.0.0.0 \\</span><br><span class="line">--client-ca-file=/etc/kubernetes/pki/kube-ca.pem  \\</span><br><span class="line">--disable-admission-plugins=PersistentVolumeLabel \\</span><br><span class="line">--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,PodPreset  \\</span><br><span class="line">--enable-bootstrap-token-auth=true  \\</span><br><span class="line">--etcd-cafile=/etc/kubernetes/pki/etcd-ca.pem  \\</span><br><span class="line">--etcd-certfile=/etc/kubernetes/pki/etcd-client.pem  \\</span><br><span class="line">--etcd-keyfile=/etc/kubernetes/pki/etcd-client-key.pem  \\</span><br><span class="line">--etcd-servers=$ETCD_SERVERS  \\</span><br><span class="line">--experimental-encryption-provider-config=/etc/kubernetes/encryption.yaml  \\</span><br><span class="line">--event-ttl=1h  \\</span><br><span class="line">--feature-gates=PodShareProcessNamespace=true,ExpandPersistentVolumes=true \\</span><br><span class="line">--insecure-port=0  \\</span><br><span class="line">--kubelet-client-certificate=/etc/kubernetes/pki/kube-apiserver.pem  \\</span><br><span class="line">--kubelet-client-key=/etc/kubernetes/pki/kube-apiserver-key.pem  \\</span><br><span class="line">--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \\</span><br><span class="line">--logtostderr=true  \\</span><br><span class="line">--proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \\</span><br><span class="line">--proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \\</span><br><span class="line">--requestheader-allowed-names=aggregator  \\</span><br><span class="line">--requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \\</span><br><span class="line">--requestheader-extra-headers-prefix=X-Remote-Extra-  \\</span><br><span class="line">--requestheader-group-headers=X-Remote-Group  \\</span><br><span class="line">--requestheader-username-headers=X-Remote-User  \\</span><br><span class="line">--runtime-config=api/all=true  \\</span><br><span class="line">--secure-port=6443  \\</span><br><span class="line">--service-account-key-file=/etc/kubernetes/pki/sa.pem  \\</span><br><span class="line">--service-cluster-ip-range=10.96.0.0/12  \\</span><br><span class="line">--service-node-port-range=30000-32767 \\</span><br><span class="line">--storage-backend=etcd3 \\</span><br><span class="line">--tls-cert-file=/etc/kubernetes/pki/kube-apiserver.pem  \\</span><br><span class="line">--tls-private-key-file=/etc/kubernetes/pki/kube-apiserver-key.pem  \\</span><br><span class="line">--token-auth-file=/etc/kubernetes/token.csv \\</span><br><span class="line">--v=2  \\</span><br><span class="line">"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="kube-controller-manager-conf"><a href="#kube-controller-manager-conf" class="headerlink" title="kube-controller-manager.conf"></a>kube-controller-manager.conf</h4><blockquote><ul><li><code>--allocate-node-cidrs=true</code>在cloud provider上分配和设置pod的CIDR</li><li><code>--cluster-cidr</code>集群内的pod的CIDR范围，需要 <code>--allocate-node-cidrs</code>设为true</li><li><code>--experimental-cluster-signing-duration=8670h0m0s</code>指定 TLS Bootstrap 证书的有效期</li><li><code>--feature-gates=RotateKubeletServerCertificate=true</code>开启 kublet server 证书的自动更新特性</li><li><code>--horizontal-pod-autoscaler-use-rest-clients=true</code>能够使用自定义资源（Custom Metrics）进行自动水平扩展</li><li><code>--leader-elect=true</code>集群运行模式，启用选举功能，被选为 leader 的节点负责处理工作，其它节点为阻塞状态</li><li><code>--node-cidr-mask-size=24</code>集群中node cidr的掩码</li><li><code>--service-cluster-ip-range=10.96.0.0/16</code>指定 Service Cluster IP 网段，必须和 kube-apiserver 中的同名参数一致</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-controller-manager.conf.example &lt;&lt;EOF</span><br><span class="line">KUBE_CONTROLLER_MANAGER_ARGS=" \\</span><br><span class="line">--address=0.0.0.0 \\</span><br><span class="line">--allocate-node-cidrs=true \\</span><br><span class="line">--cluster-cidr=$POD_NET_CIDR \\</span><br><span class="line">--cluster-signing-cert-file=/etc/kubernetes/pki/kube-ca.pem \\</span><br><span class="line">--cluster-signing-key-file=/etc/kubernetes/pki/kube-ca-key.pem \\</span><br><span class="line">--controllers=*,bootstrapsigner,tokencleaner \\</span><br><span class="line">--experimental-cluster-signing-duration=8670h0m0s \\</span><br><span class="line">--feature-gates=RotateKubeletServerCertificate=true,ExpandPersistentVolumes=true \\</span><br><span class="line">--horizontal-pod-autoscaler-sync-period=10s \\</span><br><span class="line">--horizontal-pod-autoscaler-use-rest-clients=true \\</span><br><span class="line">--kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\</span><br><span class="line">--leader-elect=true \\</span><br><span class="line">--logtostderr=true \\</span><br><span class="line">--node-cidr-mask-size=24 \\</span><br><span class="line">--node-monitor-grace-period=40s \\</span><br><span class="line">--node-monitor-period=5s \\</span><br><span class="line">--pod-eviction-timeout=2m0s \\</span><br><span class="line">--root-ca-file=/etc/kubernetes/pki/kube-ca.pem \\</span><br><span class="line">--service-account-private-key-file=/etc/kubernetes/pki/sa-key.pem \\</span><br><span class="line">--service-cluster-ip-range=$SVC_CLUSTER_CIDR \\</span><br><span class="line">--use-service-account-credentials=true \\</span><br><span class="line">--v=2 \\</span><br><span class="line">"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="kube-scheduler-conf"><a href="#kube-scheduler-conf" class="headerlink" title="kube-scheduler.conf"></a>kube-scheduler.conf</h4><blockquote><ul><li><code>--leader-elect=true</code>集群运行模式，启用选举功能，被选为 leader 的节点负责处理工作，其它节点为阻塞状态</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-scheduler.conf.example &lt;&lt;EOF</span><br><span class="line">KUBE_SCHEDULER_ARGS="\\</span><br><span class="line">--address=0.0.0.0 \\</span><br><span class="line">--algorithm-provider=DefaultProvider \\</span><br><span class="line">--kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \\</span><br><span class="line">--leader-elect=true \\</span><br><span class="line">--logtostderr=true \\</span><br><span class="line">--v=2 \\</span><br><span class="line">"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="systemd服务文件"><a href="#systemd服务文件" class="headerlink" title="systemd服务文件"></a>systemd服务文件</h3><h4 id="kube-apiserver-service"><a href="#kube-apiserver-service" class="headerlink" title="kube-apiserver.service"></a>kube-apiserver.service</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-apiserver.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line">After=etcd.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=kube</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-apiserver.conf</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \$KUBE_APISERVER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="kube-controller-manager-service"><a href="#kube-controller-manager-service" class="headerlink" title="kube-controller-manager.service"></a>kube-controller-manager.service</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-controller-manager.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=kube</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-controller-manager.conf</span><br><span class="line">ExecStart=/usr/local/bin/kube-controller-manager \$KUBE_CONTROLLER_MANAGER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="kube-scheduler-service"><a href="#kube-scheduler-service" class="headerlink" title="kube-scheduler.service"></a>kube-scheduler.service</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-scheduler.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler Plugin</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=kube</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-scheduler.conf</span><br><span class="line">ExecStart=/usr/local/bin/kube-scheduler \$KUBE_SCHEDULER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="分发配置文件到各master节点"><a href="#分发配置文件到各master节点" class="headerlink" title="分发配置文件到各master节点"></a>分发配置文件到各master节点</h3><blockquote><ul><li>根据master节点的信息替换配置文件里面的字段</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE $&#123;MasterArray[$NODE]&#125; ---"</span><br><span class="line">    rsync -avpt kube*service $NODE:/usr/lib/systemd/system/</span><br><span class="line">    sed -e "s/&#123;PUBLIC_IP&#125;/$&#123;MasterArray[$NODE]&#125;/g" kube-apiserver.conf.example &gt; kube-apiserver.conf.$&#123;NODE&#125;</span><br><span class="line">    rsync -avpt kube-apiserver.conf.$&#123;NODE&#125; $NODE:/etc/kubernetes/kube-apiserver.conf</span><br><span class="line">    rsync -avpt kube-controller-manager.conf.example $NODE:/etc/kubernetes/kube-controller-manager.conf</span><br><span class="line">    rsync -avpt kube-scheduler.conf.example $NODE:/etc/kubernetes/kube-scheduler.conf</span><br><span class="line">    rm -rf *conf.$&#123;NODE&#125;</span><br><span class="line">    ssh $NODE systemctl daemon-reload</span><br><span class="line">    ssh $NODE chown -R kube:kube /etc/kubernetes</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="启动kubernetes服务"><a href="#启动kubernetes服务" class="headerlink" title="启动kubernetes服务"></a>启动kubernetes服务</h3><blockquote><ul><li>可以先在<font color="red" size="3">k8s-m1</font>上面启动服务，确认正常之后再在其他master节点启动</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable --now kube-apiserver.service</span><br><span class="line">systemctl enable --now kube-controller-manager.service</span><br><span class="line">systemctl enable --now kube-scheduler.service</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">kubectl --kubeconfig=/etc/kubernetes/kube-admin.kubeconfig get cs</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME                 STATUS    MESSAGE             ERROR</span><br><span class="line">controller-manager   Healthy   ok                  </span><br><span class="line">scheduler            Healthy   ok                  </span><br><span class="line">etcd-2               Healthy   &#123;"health":"true"&#125;   </span><br><span class="line">etcd-0               Healthy   &#123;"health":"true"&#125;   </span><br><span class="line">etcd-1               Healthy   &#123;"health":"true"&#125;</span><br><span class="line"></span><br><span class="line">kubectl --kubeconfig=/etc/kubernetes/kube-admin.kubeconfig get endpoints</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME         ENDPOINTS            AGE</span><br><span class="line">kubernetes   172.16.80.201:6443   27s</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE $&#123;MasterArray[$NODE]&#125; ---"</span><br><span class="line">    ssh $NODE "systemctl enable --now kube-apiserver"</span><br><span class="line">    ssh $NODE "systemctl enable --now kube-controller-manager"</span><br><span class="line">    ssh $NODE "systemctl enable --now kube-scheduler"</span><br><span class="line">done</span><br></pre></td></tr></table></figure><blockquote><ul><li>三台master节点的<code>kube-apiserver</code>、<code>kube-controller-manager</code>、<code>kube-scheduler</code>服务启动成功后可以测试一下</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl --kubeconfig=/etc/kubernetes/kube-admin.kubeconfig get endpoints</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME         ENDPOINTS                                                  AGE</span><br><span class="line">kubernetes   172.16.80.201:6443,172.16.80.202:6443,172.16.80.203:6443   12m</span><br></pre></td></tr></table></figure><h3 id="设置kubectl"><a href="#设置kubectl" class="headerlink" title="设置kubectl"></a>设置kubectl</h3><blockquote><ul><li>kubectl命令默认会加载<code>~/.kube/config</code>文件，如果文件不存在则连接<code>http://127.0.0.1:8080</code>，这显然不符合预期，这里使用之前生成的kube-admin.kubeconfig</li><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE $&#123;MasterArray[$NODE]&#125; ---"</span><br><span class="line">    ssh $NODE mkdir -p /root/.kube</span><br><span class="line">    rsync -avpt /root/pki/kube-admin.kubeconfig $NODE:/root/.kube/config</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="设置命令补全"><a href="#设置命令补全" class="headerlink" title="设置命令补全"></a>设置命令补全</h3><blockquote><ul><li>设置<code>kubectl</code> 命令自动补全</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE $&#123;MasterArray[$NODE]&#125; ---"</span><br><span class="line">    echo "--- kubectl命令自动补全 ---"</span><br><span class="line">    ssh $NODE kubectl completion bash &gt;&gt; /etc/bash_completion.d/kubectl</span><br><span class="line">    echo "--- kubeadm命令自动补全 ---"</span><br><span class="line">    ssh $NODE kubeadm completion bash &gt;&gt; /etc/bash_completion.d/kubeadm</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">source /etc/bash_completion.d/kubectl</span><br></pre></td></tr></table></figure><h3 id="设置kubelet的bootstrap启动所需的RBAC"><a href="#设置kubelet的bootstrap启动所需的RBAC" class="headerlink" title="设置kubelet的bootstrap启动所需的RBAC"></a>设置kubelet的bootstrap启动所需的RBAC</h3><blockquote><ul><li><p>当集群开启了 TLS 认证后，每个节点的 kubelet 组件都要使用由 apiserver 使用的 CA 签发的有效证书才能与<br>apiserver 通讯；此时如果节点多起来，为每个节点单独签署证书将是一件非常繁琐的事情；TLS bootstrapping 功能就是让 kubelet 先使用一个预定的低权限用户连接到 apiserver，然后向 apiserver 申请证书，kubelet 的证书由 apiserver 动态签署；</p></li><li><p>在其中一个master节点上执行就可以，以<font color="red"><strong>k8s-m1</strong></font>为例</p></li></ul></blockquote><h4 id="创建工作目录-1"><a href="#创建工作目录-1" class="headerlink" title="创建工作目录"></a>创建工作目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/tls-bootstrap</span><br><span class="line">cd /root/yaml/tls-bootstrap/</span><br></pre></td></tr></table></figure><h4 id="kubelet-bootstrap-rbac-yaml"><a href="#kubelet-bootstrap-rbac-yaml" class="headerlink" title="kubelet-bootstrap-rbac.yaml"></a>kubelet-bootstrap-rbac.yaml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建yaml文件</span></span><br><span class="line">cat &gt; kubelet-bootstrap-rbac.yaml &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 给予 kubelet-bootstrap 用户进行 node-bootstrapper 的权限</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kubelet-bootstrap</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:node-bootstrapper</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: User</span><br><span class="line">  name: kubelet-bootstrap</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="tls-bootstrap-clusterrole-yaml"><a href="#tls-bootstrap-clusterrole-yaml" class="headerlink" title="tls-bootstrap-clusterrole.yaml"></a>tls-bootstrap-clusterrole.yaml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建yaml文件</span></span><br><span class="line">cat &gt; tls-bootstrap-clusterrole.yaml &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> A ClusterRole <span class="built_in">which</span> instructs the CSR approver to approve a node requesting a</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> serving cert matching its client cert.</span></span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeserver</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: ["certificates.k8s.io"]</span><br><span class="line">  resources: ["certificatesigningrequests/selfnodeserver"]</span><br><span class="line">  verbs: ["create"]</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="node-client-auto-approve-csr-yaml"><a href="#node-client-auto-approve-csr-yaml" class="headerlink" title="node-client-auto-approve-csr.yaml"></a>node-client-auto-approve-csr.yaml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建yaml文件</span></span><br><span class="line">cat &gt; node-client-auto-approve-csr.yaml &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 自动批准 system:bootstrappers 组用户 TLS bootstrapping 首次申请证书的 CSR 请求</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: node-client-auto-approve-csr</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:bootstrappers</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="node-client-auto-renew-crt-yaml"><a href="#node-client-auto-renew-crt-yaml" class="headerlink" title="node-client-auto-renew-crt.yaml"></a>node-client-auto-renew-crt.yaml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建yaml文件</span></span><br><span class="line">cat &gt; node-client-auto-renew-crt.yaml &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 自动批准 system:nodes 组用户更新 kubelet 自身与 apiserver 通讯证书的 CSR 请求</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: node-client-auto-renew-crt</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:nodes</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="node-server-auto-renew-crt-yaml"><a href="#node-server-auto-renew-crt-yaml" class="headerlink" title="node-server-auto-renew-crt.yaml"></a>node-server-auto-renew-crt.yaml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建yaml文件</span></span><br><span class="line">cat &gt; node-server-auto-renew-crt.yaml &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 自动批准 system:nodes 组用户更新 kubelet 10250 api 端口证书的 CSR 请求</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: node-server-auto-renew-crt</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeserver</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:nodes</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="创建tls-bootstrap-rbac"><a href="#创建tls-bootstrap-rbac" class="headerlink" title="创建tls-bootstrap-rbac"></a>创建tls-bootstrap-rbac</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f .</span><br></pre></td></tr></table></figure><h3 id="设置kube-apiserver获取node信息的权限"><a href="#设置kube-apiserver获取node信息的权限" class="headerlink" title="设置kube-apiserver获取node信息的权限"></a>设置kube-apiserver获取node信息的权限</h3><h4 id="说明-2"><a href="#说明-2" class="headerlink" title="说明"></a>说明</h4><p>本文部署的<code>kubelet</code>关闭了匿名访问，因此需要额外为<code>kube-apiserver</code>添加权限用于访问kubelet的信息</p><p>若没添加此<code>RBAC</code>，则<code>kubectl</code>在执行<code>logs</code>、<code>exec</code>等指令的时候会提示<code>401 Forbidden</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system logs calico-node-pc8lq </span><br><span class="line">Error from server (Forbidden): Forbidden (user=kube-apiserver, verb=get, resource=nodes, subresource=proxy) ( pods/log calico-node-pc8lq)</span><br></pre></td></tr></table></figure><p>参考文档：<a href="https://jimmysong.io/kubernetes-handbook/guide/kubelet-authentication-authorization.html" target="_blank" rel="noopener">Kublet的认证授权</a></p><h4 id="创建yaml文件"><a href="#创建yaml文件" class="headerlink" title="创建yaml文件"></a>创建yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /root/yaml/apiserver-to-kubelet-rbac.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: "true"</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - ""</span><br><span class="line">    resources:</span><br><span class="line">      - nodes/proxy</span><br><span class="line">      - nodes/stats</span><br><span class="line">      - nodes/log</span><br><span class="line">      - nodes/spec</span><br><span class="line">      - nodes/metrics</span><br><span class="line">    verbs:</span><br><span class="line">      - "*"</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: system:kube-apiserver</span><br><span class="line">  namespace: ""</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">subjects:</span><br><span class="line">  - apiGroup: rbac.authorization.k8s.io</span><br><span class="line">    kind: User</span><br><span class="line">    name: kube-apiserver</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="创建RBAC"><a href="#创建RBAC" class="headerlink" title="创建RBAC"></a>创建RBAC</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f /root/yaml/apiserver-to-kubelet-rbac.yaml</span><br></pre></td></tr></table></figure><h1 id="kubernetes-worker节点"><a href="#kubernetes-worker节点" class="headerlink" title="kubernetes worker节点"></a>kubernetes worker节点</h1><h2 id="worker节点说明"><a href="#worker节点说明" class="headerlink" title="worker节点说明"></a><strong>worker节点说明</strong></h2><blockquote><ul><li>安装Docker-ce，配置与master节点一致即可</li><li>安装cni-plugins、kubelet、kube-proxy</li><li>关闭防火墙和SELINUX</li><li>kubelet和kube-proxy运行需要root权限</li><li>这里是以k8s-m1、k8s-m2、k8s-m3作为Work节点加入集群</li></ul></blockquote><p><strong>kubelet</strong></p><blockquote><ul><li>管理容器生命周期、节点状态监控</li><li>目前 kubelet 支持三种数据源来获取节点Pod信息：<ul><li>本地文件</li><li>通过 url 从网络上某个地址来获取信息</li><li>API Server：从 kubernetes master 节点获取信息</li></ul></li><li>使用kubeconfig与kube-apiserver通信</li><li>这里启用<code>TLS-Bootstrap</code>实现kubelet证书动态签署证书，并自动生成kubeconfig</li></ul></blockquote><p><strong>kube-proxy</strong></p><blockquote><ul><li>Kube-proxy是实现Service的关键插件，kube-proxy会在每台节点上执行，然后监听API Server的Service与Endpoint资源物件的改变，然后来依据变化调用相应的组件来实现网路的转发</li><li>kube-proxy可以使用<code>userspace</code>（基本已废弃）、<code>iptables</code>（默认方式）和<code>ipvs</code>来实现数据报文的转发</li><li>这里使用的是性能更好、适合大规模使用的<code>ipvs</code></li><li>使用kubeconfig与kube-apiserver通信</li></ul></blockquote><h2 id="切换工作目录-1"><a href="#切换工作目录-1" class="headerlink" title="切换工作目录"></a>切换工作目录</h2><blockquote><ul><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/worker</span><br></pre></td></tr></table></figure><h2 id="worker组件配置模板"><a href="#worker组件配置模板" class="headerlink" title="worker组件配置模板"></a>worker组件配置模板</h2><h3 id="kubelet-conf"><a href="#kubelet-conf" class="headerlink" title="kubelet.conf"></a>kubelet.conf</h3><blockquote><ul><li><code>--bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig</code>指定bootstrap启动时使用的kubeconfig</li><li><code>--network-plugin=cni</code>定义网络插件，Pod生命周期使用此网络插件</li><li><code>--node-labels=node-role.kubernetes.io/node=&#39;&#39;</code>kubelet注册当前Node时设置的Label，以key=value的格式表示，多个labe以逗号分隔</li><li><code>--pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.1</code>Pod的pause镜像</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kubelet.conf &lt;&lt;EOF</span><br><span class="line">KUBELET_ARGS=" \\</span><br><span class="line">--bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \\</span><br><span class="line">--cert-dir=/etc/kubernetes/ssl \\</span><br><span class="line">--config=/etc/kubernetes/kubelet.config.file \\</span><br><span class="line">--cni-conf-dir=/etc/cni/net.d \\</span><br><span class="line">--cni-bin-dir=/opt/cni/bin \\</span><br><span class="line">--kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\</span><br><span class="line">--logtostderr=true \\</span><br><span class="line">--network-plugin=cni \\</span><br><span class="line">--node-labels=node-role.kubernetes.io/node='' \\</span><br><span class="line">--pod-infra-container-image=gcrxio/pause:3.1 \\</span><br><span class="line">--v=2 \\</span><br><span class="line">"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kubelet-config-file"><a href="#kubelet-config-file" class="headerlink" title="kubelet.config.file"></a>kubelet.config.file</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kubelet.config.file &lt;&lt;EOF</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">address: 0.0.0.0</span><br><span class="line">authentication:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> 匿名访问</span></span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 2m0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    # 这里写kubernetes-ca证书的路径</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/kube-ca.pem</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 5m0s</span><br><span class="line">    cacheUnauthorizedTTL: 30s</span><br><span class="line"><span class="meta">#</span><span class="bash"> cgroups的驱动，可选systemd和cgroupfs</span></span><br><span class="line">cgroupDriver: cgroupfs</span><br><span class="line">cgroupsPerQOS: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 指定Pod的DNS服务器IP地址</span></span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line"><span class="meta">#</span><span class="bash"> 集群的域名</span></span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">containerLogMaxFiles: 5</span><br><span class="line">containerLogMaxSize: 10Mi</span><br><span class="line">contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">cpuCFSQuota: true</span><br><span class="line">cpuManagerPolicy: none</span><br><span class="line">cpuManagerReconcilePeriod: 10s</span><br><span class="line">enableControllerAttachDetach: true</span><br><span class="line">enableDebuggingHandlers: true</span><br><span class="line">enforceNodeAllocatable:</span><br><span class="line">- pods</span><br><span class="line">eventBurst: 10</span><br><span class="line">eventRecordQPS: 5</span><br><span class="line"><span class="meta">#</span><span class="bash"> 达到某些阈值之后，kubelet会驱逐Pod</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> A <span class="built_in">set</span> of eviction thresholds (e.g. memory.available&lt;1Gi) that <span class="keyword">if</span> met would trigger a pod eviction.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> (default imagefs.available&lt;15%,memory.available&lt;100Mi,nodefs.available&lt;10%,nodefs.inodesFree&lt;5%)</span></span><br><span class="line">evictionHard:</span><br><span class="line">  imagefs.available: 15%</span><br><span class="line">  memory.available: 1000Mi</span><br><span class="line">  nodefs.available: 10%</span><br><span class="line">  nodefs.inodesFree: 10%</span><br><span class="line">evictionPressureTransitionPeriod: 5m0s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 检测到系统已启用swap分区时kubelet会启动失败</span></span><br><span class="line">failSwapOn: false</span><br><span class="line"><span class="meta">#</span><span class="bash"> 定义feature gates</span></span><br><span class="line">featureGates:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> kubelet 在证书即将到期时会自动发起一个 renew 自己证书的 CSR 请求</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> 其实rotate证书已经默认开启，这里显示定义是为了方便查看</span></span><br><span class="line">  RotateKubeletClientCertificate: true</span><br><span class="line">  RotateKubeletServerCertificate: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 检查kubelet配置文件变更的间隔</span></span><br><span class="line">fileCheckFrequency: 20s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 允许endpoint在尝试访问自己的服务时会被负载均衡分发到自身</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 可选值<span class="string">"promiscuous-bridge"</span>, <span class="string">"hairpin-veth"</span> and <span class="string">"none"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 默认值为promiscuous-bridge</span></span><br><span class="line">hairpinMode: promiscuous-bridge</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 20s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里定义容器镜像触发回收空间的上限值和下限值</span></span><br><span class="line">imageGCHighThresholdPercent: 85</span><br><span class="line">imageGCLowThresholdPercent: 80</span><br><span class="line">imageMinimumGCAge: 2m0s</span><br><span class="line">iptablesDropBit: 15</span><br><span class="line">iptablesMasqueradeBit: 14</span><br><span class="line">kubeAPIBurst: 10</span><br><span class="line">kubeAPIQPS: 5</span><br><span class="line">makeIPTablesUtilChains: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> kubelet进程最大能打开的文件数量，默认是1000000</span></span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line"><span class="meta">#</span><span class="bash"> 当前节点kubelet所能运行的最大Pod数量</span></span><br><span class="line">maxPods: 110</span><br><span class="line"><span class="meta">#</span><span class="bash"> node状态上报间隔</span></span><br><span class="line">nodeStatusUpdateFrequency: 10s</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">podPidsLimit: -1</span><br><span class="line"><span class="meta">#</span><span class="bash"> kubelet服务端口</span></span><br><span class="line">port: 10250</span><br><span class="line">registryBurst: 10</span><br><span class="line">registryPullQPS: 5</span><br><span class="line"><span class="meta">#</span><span class="bash"> 指定域名解析文件</span></span><br><span class="line">resolvConf: /etc/resolv.conf</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 2m0s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 拉镜像时，同一时间只拉取一个镜像</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> We recommend *not* changing the default value on nodes that run docker daemon with version &lt; 1.9 or an Aufs storage backend. Issue <span class="comment">#10959 has more details. (default true)</span></span></span><br><span class="line">serializeImagePulls: true</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 4h0m0s</span><br><span class="line">syncFrequency: 1m0s</span><br><span class="line">volumeStatsAggPeriod: 1m0s</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-proxy-conf"><a href="#kube-proxy-conf" class="headerlink" title="kube-proxy.conf"></a>kube-proxy.conf</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-proxy.conf &lt;&lt;EOF</span><br><span class="line">KUBE_PROXY_ARGS=" \\</span><br><span class="line">--config=/etc/kubernetes/kube-proxy.config.file \\</span><br><span class="line">--v=2 \\</span><br><span class="line">"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-proxy-config-file"><a href="#kube-proxy-config-file" class="headerlink" title="kube-proxy.config.file"></a>kube-proxy.config.file</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-proxy.config.file &lt;&lt;EOF</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: ""</span><br><span class="line">  burst: 10</span><br><span class="line">  contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line">  qps: 5</span><br><span class="line"><span class="meta">#</span><span class="bash"> 集群中pod的CIDR范围，从这个范围以外发送到服务集群IP的流量将被伪装，从POD发送到外部LoadBalanceIP的流量将被定向到各自的集群IP</span></span><br><span class="line">clusterCIDR: "10.244.0.0/16"</span><br><span class="line">configSyncPeriod: 15m0s</span><br><span class="line">conntrack:</span><br><span class="line">  max: null</span><br><span class="line"><span class="meta">  #</span><span class="bash"> 每个核心最大能跟踪的NAT连接数，默认32768</span></span><br><span class="line">  maxPerCore: 32768</span><br><span class="line">  min: 131072</span><br><span class="line">  tcpCloseWaitTimeout: 1h0m0s</span><br><span class="line">  tcpEstablishedTimeout: 24h0m0s</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: 0.0.0.0:10256</span><br><span class="line">hostnameOverride: ""</span><br><span class="line">iptables:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> SNAT所有通过服务集群ip发送的通信</span></span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: 14</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">ipvs:</span><br><span class="line">  excludeCIDRs: null</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line"><span class="meta">  #</span><span class="bash"> ipvs调度类型，默认是rr</span></span><br><span class="line">  scheduler: "rr"</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">metricsBindAddress: 127.0.0.1:10249</span><br><span class="line">mode: "ipvs"</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">portRange: ""</span><br><span class="line">resourceContainer: /kube-proxy</span><br><span class="line">udpIdleTimeout: 250ms</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="systemd服务文件-1"><a href="#systemd服务文件-1" class="headerlink" title="systemd服务文件"></a>systemd服务文件</h2><h3 id="kubelet-service"><a href="#kubelet-service" class="headerlink" title="kubelet.service"></a>kubelet.service</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kubelet.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/lib/kubelet</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kubelet.conf</span><br><span class="line">ExecStart=/usr/local/bin/kubelet \$KUBELET_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">KillMode=process</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-proxy-service"><a href="#kube-proxy-service" class="headerlink" title="kube-proxy.service"></a>kube-proxy.service</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-proxy.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube-Proxy Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-proxy.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里启动时使用ipvsadm将TCP的keepalive时间设置，默认是900</span></span><br><span class="line">ExecStartPre=/usr/sbin/ipvsadm --set 900 120 300 </span><br><span class="line">ExecStart=/usr/local/bin/kube-proxy \$KUBE_PROXY_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="分发证书和kubeconfig文件"><a href="#分发证书和kubeconfig文件" class="headerlink" title="分发证书和kubeconfig文件"></a>分发证书和kubeconfig文件</h2><blockquote><ul><li>在<font color="red">k8s-m1</font>上操作</li><li>在worker节点建立对应的目录</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!WorkerArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    echo "--- 创建目录 ---"</span><br><span class="line">    ssh $NODE mkdir -p /opt/cni/bin \</span><br><span class="line">                       /etc/cni/net.d \</span><br><span class="line">                       /etc/kubernetes/pki \</span><br><span class="line">                       /etc/kubernetes/manifests \</span><br><span class="line">                       /var/lib/kubelet</span><br><span class="line">    rsync -avpt /root/pki/kube-proxy.kubeconfig \</span><br><span class="line">                /root/pki/bootstrap.kubeconfig \</span><br><span class="line">                $NODE:/etc/kubernetes/</span><br><span class="line">    rsync -avpt /root/pki/kube-ca.pem \</span><br><span class="line">                /root/pki/front-proxy-ca.pem \</span><br><span class="line">                $NODE:/etc/kubernetes/pki/</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="分发二进制文件-1"><a href="#分发二进制文件-1" class="headerlink" title="分发二进制文件"></a>分发二进制文件</h2><blockquote><ul><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!WorkerArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    echo "--- 分发kubernetes二进制文件 ---"</span><br><span class="line">    rsync -avpt /root/software/kubernetes/server/bin/kubelet \</span><br><span class="line">                /root/software/kubernetes/server/bin/kube-proxy \</span><br><span class="line">                $NODE:/usr/local/bin/</span><br><span class="line">    echo "--- 分发CNI-Plugins ---"</span><br><span class="line">    rsync -avpt /root/software/cni-plugins/* $NODE:/opt/cni/bin/</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="分发配置文件和服务文件"><a href="#分发配置文件和服务文件" class="headerlink" title="分发配置文件和服务文件"></a>分发配置文件和服务文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!WorkerArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    rsync -avpt kubelet.conf kubelet.config.file kube-proxy.conf kube-proxy.config.file $NODE:/etc/kubernetes/</span><br><span class="line">    rsync -avpt kubelet.service kube-proxy.service $NODE:/usr/lib/systemd/system/</span><br><span class="line">    ssh $NODE systemctl daemon-reload</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!WorkerArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    ssh $NODE systemctl enable --now docker.service kubelet.service kube-proxy.service</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="获取节点信息"><a href="#获取节点信息" class="headerlink" title="获取节点信息"></a>获取节点信息</h2><blockquote><ul><li>此时由于未按照网络插件，所以节点状态为<font color="red"><code>NotReady</code></font></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl get node -o wide</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">NAME      STATUS     ROLES     AGE       VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION              CONTAINER-RUNTIME</span><br><span class="line">k8s-m1    NotReady   node      12s       v1.11.5   172.16.80.201   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-957.1.3.el7.x86_64   docker://18.3.1</span><br><span class="line">k8s-m2    NotReady   node      12s       v1.11.5   172.16.80.202   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-957.1.3.el7.x86_64   docker://18.3.1</span><br><span class="line">k8s-m3    NotReady   node      12s       v1.11.5   172.16.80.203   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-957.1.3.el7.x86_64   docker://18.3.1</span><br></pre></td></tr></table></figure><h1 id="kubernetes-Core-Addons"><a href="#kubernetes-Core-Addons" class="headerlink" title="kubernetes Core Addons"></a>kubernetes Core Addons</h1><h2 id="网络组件部署（二选其一）"><a href="#网络组件部署（二选其一）" class="headerlink" title="网络组件部署（二选其一）"></a>网络组件部署（二选其一）</h2><blockquote><ul><li>只要符合CNI规范的网络组件都可以给kubernetes使用</li><li>网络组件清单可以在这里看到<a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/" target="_blank" rel="noopener">Network Plugins</a></li><li>这里只列举<code>kube-flannel</code>和<code>calico</code>，flannel和calico的区别可以自己去找资料</li><li><font color="red">网络组件只能选一个来部署</font></li><li>本文使用<code>kube-flannel</code>部署网络组件，<code>calico</code>已测试可用</li><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><h3 id="创建工作目录-2"><a href="#创建工作目录-2" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/network-plugin/&#123;kube-flannel,calico&#125;</span><br></pre></td></tr></table></figure><h3 id="kube-flannel"><a href="#kube-flannel" class="headerlink" title="kube-flannel"></a>kube-flannel</h3><h4 id="说明-3"><a href="#说明-3" class="headerlink" title="说明"></a>说明</h4><blockquote><ul><li>kube-flannel基于VXLAN的方式创建容器二层网络，使用端口<font color="red"><code>8472/UDP</code></font>通信</li><li>flannel 第一次启动时，从 etcd 获取 Pod 网段信息，为本节点分配一个未使用的 /24 段地址，然后创建 flannel.1（也可能是其它名称，如 flannel1 等） 接口。</li><li>官方提供yaml文件部署为<code>DeamonSet</code></li><li>若需要使用<code>NetworkPolicy</code>功能，可以关注这个项目<a href="https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/flannel" target="_blank" rel="noopener">canal</a></li></ul></blockquote><h4 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h4><p><img src="https://jimmysong.io/kubernetes-handbook/images/flannel-networking.png" alt=""></p><h4 id="切换工作目录-2"><a href="#切换工作目录-2" class="headerlink" title="切换工作目录"></a>切换工作目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/network-plugin/kube-flannel</span><br></pre></td></tr></table></figure><h4 id="下载yaml文件"><a href="#下载yaml文件" class="headerlink" title="下载yaml文件"></a>下载yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure><blockquote><ul><li><p>官方yaml文件包含多个平台的daemonset，包括amd64、arm64、arm、ppc64le、s390x</p></li><li><p>这里以amd64作为例子，其他的可以自行根据需要修改或者直接删除不需要的daemonset</p></li><li><p>官方yaml文件已经配置好容器网络为<code>10.244.0.0/16</code>，这里需要跟<code>kube-controller-manager.conf</code>里面的<code>--cluster-cidr</code>匹配</p></li><li><p>如果在<code>kube-controller-manager.conf</code>里面把<code>--cluster-cidr</code>改成了其他地址段，例如<code>192.168.0.0/16</code>，用以下命令替换<code>kube-flannel.yaml</code>相应的字段</p></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -e 's,"Network": "10.244.0.0/16","Network": "192.168.0.0/16," -i kube-flannel.yml</span><br></pre></td></tr></table></figure><blockquote><ul><li><p>如果服务器有多个网卡，需要指定网卡用于flannel通信，以网卡ens33为例</p><ul><li>在<code>args</code>下面添加一行<font color="red"><code>- --iface=ens33</code></font></li></ul></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">containers:</span><br><span class="line">- name: kube-flannel</span><br><span class="line">  image: quay.io/coreos/flannel:v0.10.0-amd64</span><br><span class="line">  command:</span><br><span class="line">  - /opt/bin/flanneld</span><br><span class="line">  args:</span><br><span class="line">  - --ip-masq</span><br><span class="line">  - --kube-subnet-mgr</span><br><span class="line">  - --iface=ens33</span><br></pre></td></tr></table></figure><h4 id="修改backend"><a href="#修改backend" class="headerlink" title="修改backend"></a>修改backend</h4><blockquote><ul><li>flannel支持多种后端实现，可选值为<code>VXLAN</code>、<code>host-gw</code>、<code>UDP</code></li><li>从性能上，<code>host-gw</code>是最好的，<code>VXLAN</code>和<code>UDP</code>次之</li><li>默认值是<code>VXLAN</code>，这里以修改为<code>host-gw</code>为例，位置大概在75行左右</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">net-conf.json:</span> <span class="string">|</span></span><br><span class="line"><span class="string">  &#123;</span></span><br><span class="line"><span class="string">    "Network": "10.244.0.0/16",</span></span><br><span class="line"><span class="string">    "Backend": &#123;</span></span><br><span class="line"><span class="string">      "Type": "host-gw"</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  &#125;</span></span><br></pre></td></tr></table></figure><h4 id="部署kube-flannel"><a href="#部署kube-flannel" class="headerlink" title="部署kube-flannel"></a>部署kube-flannel</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f kube-flannel.yml</span><br></pre></td></tr></table></figure><h4 id="检查部署情况"><a href="#检查部署情况" class="headerlink" title="检查部署情况"></a>检查部署情况</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get pod -l k8s-app=flannel</span><br><span class="line">NAME                    READY     STATUS    RESTARTS   AGE</span><br><span class="line">kube-flannel-ds-27jwl   2/2       Running   0          59s</span><br><span class="line">kube-flannel-ds-4fgv6   2/2       Running   0          59s</span><br><span class="line">kube-flannel-ds-mvrt7   2/2       Running   0          59s</span><br></pre></td></tr></table></figure><blockquote><ul><li>如果等很久都没Running，可能是quay.io对你来说太慢了</li><li>可以替换一下镜像，重新apply</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed -e 's,quay.io/coreos/,zhangguanzhang/quay.io.coreos.,g' -i kube-flannel.yml</span><br><span class="line">kubectl apply -f kube-flannel.yaml</span><br></pre></td></tr></table></figure><h3 id="Calico"><a href="#Calico" class="headerlink" title="Calico"></a>Calico</h3><h4 id="说明-4"><a href="#说明-4" class="headerlink" title="说明"></a>说明</h4><blockquote><ul><li>Calico 是一款纯 Layer 3 的网络，节点之间基于BGP协议来通信。</li><li>这里以<code>calico-v3.4.0</code>来作为示例</li><li><a href="https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/calico" target="_blank" rel="noopener">部署文档</a></li></ul></blockquote><h4 id="架构图-1"><a href="#架构图-1" class="headerlink" title="架构图"></a>架构图</h4><p><img src="https://docs.projectcalico.org/images/calico-arch-gen-v3.2.svg" alt=""></p><h4 id="切换工作目录-3"><a href="#切换工作目录-3" class="headerlink" title="切换工作目录"></a>切换工作目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/network-plugin/calico</span><br></pre></td></tr></table></figure><h4 id="下载yaml文件-1"><a href="#下载yaml文件-1" class="headerlink" title="下载yaml文件"></a>下载yaml文件</h4><blockquote><ul><li>这里使用kubernetes API来保存网络信息</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://docs.projectcalico.org/v3.4/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml</span><br><span class="line">wget https://docs.projectcalico.org/v3.4/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calicoctl.yaml</span><br></pre></td></tr></table></figure><blockquote><ul><li>官方yaml文件默认配置容器网络为<code>192.168.0.0/16</code>，这里需要跟<code>kube-controller-manager.conf</code>里面的<code>--cluster-cidr</code>匹配，需要替换相应字段</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -e "s,192.168.0.0/16,$&#123;POD_NET_CIDR&#125;,g" -i calico.yaml</span><br></pre></td></tr></table></figure><blockquote><ul><li>官方yaml文件定义calicoctl为Pod，而不是deployment，所以需要调整一下</li><li>修改<code>kind: Pod</code>为<code>kind: Deployment</code>并补充其他字段</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      k8s-app:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">      namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        k8s-app:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      tolerations:</span></span><br><span class="line"><span class="attr">      - effect:</span> <span class="string">NoSchedule</span></span><br><span class="line"><span class="attr">        key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line"><span class="attr">      - effect:</span> <span class="string">NoSchedule</span></span><br><span class="line"><span class="attr">        key:</span> <span class="string">node.cloudprovider.kubernetes.io/uninitialized</span></span><br><span class="line"><span class="attr">        value:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">      hostNetwork:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      serviceAccountName:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">quay.io/calico/ctl:v3.4.0</span></span><br><span class="line"><span class="attr">        command:</span> <span class="string">["/bin/sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"while true; do sleep 3600; done"</span><span class="string">]</span></span><br><span class="line"><span class="attr">        tty:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">DATASTORE_TYPE</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">kubernetes</span></span><br></pre></td></tr></table></figure><h4 id="部署Calico"><a href="#部署Calico" class="headerlink" title="部署Calico"></a>部署Calico</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f /root/yaml/network-plugin/calico/</span><br></pre></td></tr></table></figure><h4 id="检查部署情况-1"><a href="#检查部署情况-1" class="headerlink" title="检查部署情况"></a>检查部署情况</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get pod -l k8s-app=calico-node</span><br><span class="line">NAME                READY     STATUS    RESTARTS   AGE</span><br><span class="line">calico-node-fjcj4   2/2       Running   0          6m</span><br><span class="line">calico-node-tzppt   2/2       Running   0          6m</span><br><span class="line">calico-node-zdq64   2/2       Running   0          6m</span><br><span class="line"></span><br><span class="line">kubectl get pod -n kube-system -l k8s-app=calicoctl</span><br><span class="line">NAME                         READY     STATUS    RESTARTS   AGE</span><br><span class="line">calicoctl-58df8955f6-sp8q9   0/1       Running   0          38s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl -n kube-system exec -it calicoctl-58df8955f6-sp8q9 -- /calicoctl get node -o wide</span><br><span class="line">NAME     ASN         IPV4               IPV6   </span><br><span class="line">k8s-m1   (unknown)   172.16.80.201/24          </span><br><span class="line">k8s-m2   (unknown)   172.16.80.202/24          </span><br><span class="line">k8s-m3   (unknown)   172.16.80.203/24</span><br><span class="line"></span><br><span class="line">kubectl -n kube-system exec -it calicoctl-58df8955f6-sp8q9 -- /calicoctl get profiles -o wide</span><br><span class="line">NAME              LABELS   </span><br><span class="line">kns.default       map[]    </span><br><span class="line">kns.kube-public   map[]    </span><br><span class="line">kns.kube-system   map[]</span><br></pre></td></tr></table></figure><blockquote><ul><li>如果镜像pull不下来，可以替换一下</li><li>替换完重新apply</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed -e 's,quay.io/calico/,zhangguanzhang/quay.io.calico.,g' -i *yaml</span><br><span class="line">kubectl apply -f .</span><br></pre></td></tr></table></figure><h3 id="检查节点状态"><a href="#检查节点状态" class="headerlink" title="检查节点状态"></a>检查节点状态</h3><blockquote><ul><li>网络组件部署完成之后，可以看到node状态已经为<code>Ready</code></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl get node </span><br><span class="line">NAME      STATUS    ROLES     AGE       VERSION</span><br><span class="line">k8s-m1    Ready     node      1d        v1.11.5</span><br><span class="line">k8s-m2    Ready     node      1d        v1.11.5</span><br><span class="line">k8s-m3    Ready     node      1d        v1.11.5</span><br></pre></td></tr></table></figure><h2 id="服务发现组件部署"><a href="#服务发现组件部署" class="headerlink" title="服务发现组件部署"></a>服务发现组件部署</h2><blockquote><ul><li>kubernetes从v1.11之后，已经使用CoreDNS取代原来的KUBE DNS作为服务发现的组件</li><li>CoreDNS 是由 CNCF 维护的开源 DNS 方案，前身是 SkyDNS</li><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><h3 id="创建工作目录-3"><a href="#创建工作目录-3" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/coredns</span><br></pre></td></tr></table></figure><blockquote><ul><li>切换工作目录</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/coredns</span><br></pre></td></tr></table></figure><h3 id="CoreDNS"><a href="#CoreDNS" class="headerlink" title="CoreDNS"></a>CoreDNS</h3><h4 id="创建yaml文件-1"><a href="#创建yaml文件-1" class="headerlink" title="创建yaml文件"></a>创建yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; coredns.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - ""</span><br><span class="line">  resources:</span><br><span class="line">  - endpoints</span><br><span class="line">  - services</span><br><span class="line">  - pods</span><br><span class="line">  - namespaces</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: "true"</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:coredns</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  Corefile: |</span><br><span class="line">    .:53 &#123;</span><br><span class="line">        errors</span><br><span class="line">        log</span><br><span class="line">        health</span><br><span class="line">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span><br><span class="line">          pods insecure</span><br><span class="line">          upstream</span><br><span class="line">          fallthrough in-addr.arpa ip6.arpa</span><br><span class="line">        &#125;</span><br><span class="line">        prometheus :9153</span><br><span class="line">        proxy . /etc/resolv.conf</span><br><span class="line">        cache 30</span><br><span class="line">        reload</span><br><span class="line">        loadbalance</span><br><span class="line">    &#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/name: "CoreDNS"</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-dns</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io/critical-pod: ""</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kube-dns</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: coredns</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      tolerations:</span><br><span class="line">      - key: CriticalAddonsOnly</span><br><span class="line">        operator: Exists</span><br><span class="line">      - effect: NoSchedule</span><br><span class="line">        key: node-role.kubernetes.io/master</span><br><span class="line">      containers:</span><br><span class="line">      - name: coredns</span><br><span class="line">        image: gcrxio/coredns:1.2.6</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        args: [ "-conf", "/etc/coredns/Corefile" ]</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /health</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 60</span><br><span class="line">          timeoutSeconds: 10</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          failureThreshold: 5</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns</span><br><span class="line">          protocol: UDP</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns-tcp</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 9153</span><br><span class="line">          name: metrics</span><br><span class="line">          protocol: TCP</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 200Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 70Mi</span><br><span class="line">        securityContext:</span><br><span class="line">          allowPrivilegeEscalation: false</span><br><span class="line">          capabilities:</span><br><span class="line">            add:</span><br><span class="line">            - NET_BIND_SERVICE</span><br><span class="line">            drop:</span><br><span class="line">            - all</span><br><span class="line">          readOnlyRootFilesystem: true</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          mountPath: /etc/coredns</span><br><span class="line">          readOnly: true</span><br><span class="line">        - name: host-time</span><br><span class="line">          mountPath: /etc/localtime</span><br><span class="line">      dnsPolicy: Default</span><br><span class="line">      volumes:</span><br><span class="line">      - name: host-time</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /etc/localtime</span><br><span class="line">      - name: config-volume</span><br><span class="line">        configMap:</span><br><span class="line">          name: coredns</span><br><span class="line">          items:</span><br><span class="line">          - key: Corefile</span><br><span class="line">            path: Corefile</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-dns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    prometheus.io/port: "9153"</span><br><span class="line">    prometheus.io/scrape: "true"</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/cluster-service: "true"</span><br><span class="line">    kubernetes.io/name: "CoreDNS"</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">  clusterIP: $&#123;POD_DNS_SERVER_IP&#125;</span><br><span class="line">  ports:</span><br><span class="line">  - name: dns</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: UDP</span><br><span class="line">  - name: dns-tcp</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: TCP</span><br><span class="line">  - name: metrics</span><br><span class="line">    port: 9153</span><br><span class="line">    protocol: TCP</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="修改yaml文件"><a href="#修改yaml文件" class="headerlink" title="修改yaml文件"></a>修改yaml文件</h4><blockquote><ul><li>yaml文件里面定义了<code>clusterIP</code>这里需要与<code>kubelet.config.file</code>里面定义的<code>cluster-dns</code>一致</li><li>如果kubelet.conf里面的<code>--cluster-dns</code>改成别的，例如<code>x.x.x.x</code>，这里也要做相应变动，不然Pod找不到DNS，无法正常工作</li><li>这里定义静态的hosts解析，这样Pod可以通过hostname来访问到各节点主机</li><li>用下面的命令根据<code>HostArray</code>的信息生成静态的hosts解析</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sed -e '57r '&lt;(\</span><br><span class="line">    echo '        hosts &#123;'; \</span><br><span class="line">    for NODE in "$&#123;!HostArray[@]&#125;";do \</span><br><span class="line">        echo "          $&#123;HostArray[$NODE]&#125; $NODE"; \</span><br><span class="line">    done;\</span><br><span class="line">    echo '          fallthrough'; \</span><br><span class="line">    echo '        &#125;';) \</span><br><span class="line">-i coredns.yaml</span><br></pre></td></tr></table></figure><blockquote><ul><li>上面的命令的作用是，通过<code>HostArray</code>的信息生成hosts解析配置，顺序是打乱的，可以手工调整顺序</li><li>也可以手动修改<code>coredns.yaml</code>文件来添加对应字段</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">coredns</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line"><span class="attr">  Corefile:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    .:53 &#123;</span></span><br><span class="line"><span class="string">        errors</span></span><br><span class="line"><span class="string">        log</span></span><br><span class="line"><span class="string">        health</span></span><br><span class="line"><span class="string">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span></span><br><span class="line"><span class="string">          pods insecure</span></span><br><span class="line"><span class="string">          upstream</span></span><br><span class="line"><span class="string">          fallthrough in-addr.arpa ip6.arpa</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        hosts &#123;</span></span><br><span class="line"><span class="string">          172.16.80.202 k8s-m2</span></span><br><span class="line"><span class="string">          172.16.80.203 k8s-m3</span></span><br><span class="line"><span class="string">          172.16.80.201 k8s-m1</span></span><br><span class="line"><span class="string">          fallthrough in-addr.arpa ip6.arpa</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        prometheus :9153</span></span><br><span class="line"><span class="string">        proxy . /etc/resolv.conf</span></span><br><span class="line"><span class="string">        cache 30</span></span><br><span class="line"><span class="string">        reload</span></span><br><span class="line"><span class="string">        loadbalance</span></span><br><span class="line"><span class="string">    &#125;</span></span><br></pre></td></tr></table></figure><h4 id="部署CoreDNS"><a href="#部署CoreDNS" class="headerlink" title="部署CoreDNS"></a>部署CoreDNS</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f coredns.yaml</span><br></pre></td></tr></table></figure><h4 id="检查部署状态"><a href="#检查部署状态" class="headerlink" title="检查部署状态"></a>检查部署状态</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get pod -l k8s-app=kube-dns</span><br><span class="line">NAME                       READY     STATUS    RESTARTS   AGE</span><br><span class="line">coredns-5566c96697-6gzzc   1/1       Running   0          45s</span><br><span class="line">coredns-5566c96697-q5slk   1/1       Running   0          45s</span><br></pre></td></tr></table></figure><h3 id="验证集群DNS服务"><a href="#验证集群DNS服务" class="headerlink" title="验证集群DNS服务"></a>验证集群DNS服务</h3><blockquote><ul><li>创建一个deployment测试DNS解析</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建一个基于busybox的deployment</span></span><br><span class="line">cat &gt; /root/yaml/busybox-deployment.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: busybox</span><br><span class="line">  name: busybox</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: busybox</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: busybox</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: busybox</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        image: busybox:1.26</span><br><span class="line">        command:</span><br><span class="line">        - sleep</span><br><span class="line">        - "3600"</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 基于文件创建deployment</span></span><br><span class="line">kubectl apply -f /root/yaml/busybox-deployment.yaml</span><br></pre></td></tr></table></figure><blockquote><ul><li>检查deployment部署情况</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod</span><br><span class="line">NAME                       READY     STATUS    RESTARTS   AGE</span><br><span class="line">busybox-7b9bfb5658-872gj   1/1       Running   0          6s</span><br></pre></td></tr></table></figure><blockquote><ul><li>验证集群DNS解析</li><li>上一个命令获取到pod名字为<code>busybox-7b9bfb5658-872gj</code></li><li>通过kubectl命令连接到Pod运行<code>nslookup</code>命令测试使用域名来访问kube-apiserver和各节点主机</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">echo "--- 通过CoreDNS访问kubernetes ---"</span><br><span class="line">kubectl exec -it busybox-7b9bfb5658-4cz94 -- nslookup kubernetes</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">echo "--- 通过CoreDNS访问k8s-m1 ---"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">kubectl exec -it busybox-7b9bfb5658-4cz94 -- nslookup k8s-m1</span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line">Name:      k8s-m1</span><br><span class="line">Address 1: 172.16.80.201 k8s-m1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">echo "--- 通过CoreDNS访问k8s-m2 ---"</span><br><span class="line">kubectl exec -it busybox-7b9bfb5658-4cz94 -- nslookup k8s-m2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line">Name:      k8s-n2</span><br><span class="line">Address 1: 172.16.80.202 k8s-m2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">echo "--- 通过CoreDNS访问并不存在的k8s-n3 ---"</span><br><span class="line">kubectl exec -it busybox-7b9bfb5658-4cz94 -- nslookup k8s-n3</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line">nslookup: can't resolve 'k8s-n3'</span><br></pre></td></tr></table></figure><h2 id="Metrics-Server"><a href="#Metrics-Server" class="headerlink" title="Metrics Server"></a>Metrics Server</h2><blockquote><ul><li><a href="https://github.com/kubernetes-incubator/metrics-server" target="_blank" rel="noopener">Metrics Server</a><br>是实现了 Metrics API 的元件,其目标是取代 Heapster 作位 Pod 与 Node 提供资源的 Usage<br>metrics,该元件会从每个 Kubernetes 节点上的 Kubelet 所公开的 Summary API 中收集 Metrics</li><li>Horizontal Pod Autoscaler（HPA）控制器用于实现基于CPU使用率进行自动Pod伸缩的功能。</li><li>HPA控制器基于Master的kube-controller-manager服务启动参数–horizontal-pod-autoscaler-sync-period定义是时长（默认30秒）,周期性监控目标Pod的CPU使用率,并在满足条件时对ReplicationController或Deployment中的Pod副本数进行调整,以符合用户定义的平均Pod<br>CPU使用率。</li><li>在新版本的kubernetes中 Pod CPU使用率不在来源于heapster,而是来自于metrics-server</li><li>官网原话是 The –horizontal-pod-autoscaler-use-rest-clients is true or unset. Setting this to false switches to Heapster-based autoscaling, which is deprecated.</li><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><h3 id="额外参数"><a href="#额外参数" class="headerlink" title="额外参数"></a>额外参数</h3><blockquote><ul><li>设置kube-apiserver参数，这里在配置kube-apiserver阶段已经加进去了</li><li>front-proxy证书，在证书生成阶段已经完成且已分发</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">--requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem</span><br><span class="line">--proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem</span><br><span class="line">--proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem</span><br><span class="line">--requestheader-allowed-names=aggregator</span><br><span class="line">--requestheader-group-headers=X-Remote-Group</span><br><span class="line">--requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class="line">--requestheader-username-headers=X-Remote-User</span><br></pre></td></tr></table></figure><h3 id="创建工作目录-4"><a href="#创建工作目录-4" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/metrics-server</span><br></pre></td></tr></table></figure><h3 id="切换工作目录-4"><a href="#切换工作目录-4" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/metrics-server</span><br></pre></td></tr></table></figure><h3 id="下载yaml文件-2"><a href="#下载yaml文件-2" class="headerlink" title="下载yaml文件"></a>下载yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes-incubator/metrics-server/master/deploy/1.8%2B/aggregated-metrics-reader.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes-incubator/metrics-server/master/deploy/1.8%2B/auth-delegator.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes-incubator/metrics-server/master/deploy/1.8%2B/auth-reader.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes-incubator/metrics-server/master/deploy/1.8%2B/metrics-apiservice.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes-incubator/metrics-server/master/deploy/1.8%2B/metrics-server-service.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes-incubator/metrics-server/master/deploy/1.8%2B/resource-reader.yaml</span><br></pre></td></tr></table></figure><h3 id="创建metrics-server-deployment-yaml"><a href="#创建metrics-server-deployment-yaml" class="headerlink" title="创建metrics-server-deployment.yaml"></a>创建metrics-server-deployment.yaml</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; metrics-server-deployment.yaml &lt;&lt;EOF</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: metrics-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: metrics-server</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: metrics-server</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: metrics-server</span><br><span class="line">      volumes:</span><br><span class="line">      # mount in tmp so we can safely use from-scratch images and/or read-only containers</span><br><span class="line">      - name: ca-ssl</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /etc/kubernetes/pki</span><br><span class="line">      containers:</span><br><span class="line">      - name: metrics-server</span><br><span class="line">        image: gcrxio/metrics-server-amd64:v0.3.1</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        command:</span><br><span class="line">        - /metrics-server</span><br><span class="line">        - --metric-resolution=30s</span><br><span class="line">        - --kubelet-port=10250</span><br><span class="line">        - --kubelet-preferred-address-types=InternalDNS,InternalIP,ExternalDNS,ExternalIP,Hostname</span><br><span class="line">        - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem</span><br><span class="line">        - --requestheader-username-headers=X-Remote-User </span><br><span class="line">        - --requestheader-group-headers=X-Remote-Group </span><br><span class="line">        - --requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class="line">        - --kubelet-insecure-tls</span><br><span class="line">        - -v=2</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: ca-ssl</span><br><span class="line">          mountPath: /etc/kubernetes/pki</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="部署metrics-server"><a href="#部署metrics-server" class="headerlink" title="部署metrics-server"></a>部署metrics-server</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f .</span><br></pre></td></tr></table></figure><h3 id="查看pod状态"><a href="#查看pod状态" class="headerlink" title="查看pod状态"></a>查看pod状态</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get pod -l k8s-app=metrics-server</span><br><span class="line">NAME                                  READY     STATUS    RESTARTS   AGE</span><br><span class="line">pod/metrics-server-86bd9d7667-5hbn6   1/1       Running   0          1m</span><br></pre></td></tr></table></figure><h3 id="验证metrics"><a href="#验证metrics" class="headerlink" title="验证metrics"></a>验证metrics</h3><blockquote><ul><li>完成后,等待一段时间(约 30s - 1m)收集 Metrics</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 请求metrics api的结果</span></span><br><span class="line">kubectl get --raw /apis/metrics.k8s.io/v1beta1</span><br><span class="line">&#123;"kind":"APIResourceList","apiVersion":"v1","groupVersion":"metrics.k8s.io/v1beta1","resources":[&#123;"name":"nodes","singularName":"","namespaced":false,"kind":"NodeMetrics","verbs":["get","list"]&#125;,&#123;"name":"pods","singularName":"","namespaced":true,"kind":"PodMetrics","verbs":["get","list"]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">kubectl get apiservice|grep metrics</span><br><span class="line">v1beta1.metrics.k8s.io                  2018-12-09T08:17:26Z</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取节点性能信息</span></span><br><span class="line">kubectl top node</span><br><span class="line">NAME      CPU(cores)   CPU%      MEMORY(bytes)   MEMORY%   </span><br><span class="line">k8s-m1    113m         2%        1080Mi          14%       </span><br><span class="line">k8s-m2    133m         3%        1086Mi          14%       </span><br><span class="line">k8s-m3    100m         2%        1029Mi          13%</span><br></pre></td></tr></table></figure><h1 id="至此集群已具备基本功能"><a href="#至此集群已具备基本功能" class="headerlink" title="至此集群已具备基本功能"></a>至此集群已具备基本功能</h1><blockquote><p>下面的Extra Addons就是一些额外的功能</p></blockquote><h1 id="kubernetes-Extra-Addons"><a href="#kubernetes-Extra-Addons" class="headerlink" title="kubernetes Extra Addons"></a>kubernetes Extra Addons</h1><h2 id="Dashboard"><a href="#Dashboard" class="headerlink" title="Dashboard"></a>Dashboard</h2><blockquote><ul><li>Dashboard 是kubernetes社区提供的GUI界面，用于图形化管理kubernetes集群，同时可以看到资源报表。</li><li>官方提供yaml文件直接部署，但是需要更改<code>image</code>以便国内部署</li><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><h3 id="创建工作目录-5"><a href="#创建工作目录-5" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/kubernetes-dashboard</span><br></pre></td></tr></table></figure><h3 id="切换工作目录-5"><a href="#切换工作目录-5" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/kubernetes-dashboard</span><br></pre></td></tr></table></figure><h3 id="获取yaml文件"><a href="#获取yaml文件" class="headerlink" title="获取yaml文件"></a>获取yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure><h3 id="修改镜像地址"><a href="#修改镜像地址" class="headerlink" title="修改镜像地址"></a>修改镜像地址</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -e 's,k8s.gcr.io/kubernetes-dashboard-amd64,gcrxio/kubernetes-dashboard-amd64,g' -i kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure><h3 id="创建kubernetes-Dashboard"><a href="#创建kubernetes-Dashboard" class="headerlink" title="创建kubernetes-Dashboard"></a>创建kubernetes-Dashboard</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure><h3 id="创建ServiceAccount-RBAC"><a href="#创建ServiceAccount-RBAC" class="headerlink" title="创建ServiceAccount RBAC"></a>创建ServiceAccount RBAC</h3><blockquote><ul><li>官方的yaml文件，ServiceAccount绑定的RBAC权限很低，很多资源无法查看</li><li>需要创建一个用于管理全局的ServiceAccount</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; cluster-admin.yaml &lt;&lt;EOF</span><br><span class="line">---</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在kube-system中创建名为admin-user的ServiceAccount</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将admin-user和cluster-admin绑定在一起</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> cluster-admin是kubernetes内置的clusterrole，具有集群管理员权限</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 其他内置的clusterrole可以通过kubectl get clusterrole查看</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl apply -f cluster-admin.yaml</span><br></pre></td></tr></table></figure><h3 id="获取ServiceAccount的Token"><a href="#获取ServiceAccount的Token" class="headerlink" title="获取ServiceAccount的Token"></a>获取ServiceAccount的Token</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '&#123;print $1&#125;')</span><br></pre></td></tr></table></figure><h3 id="查看部署情况"><a href="#查看部署情况" class="headerlink" title="查看部署情况"></a>查看部署情况</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get all -n kube-system --selector k8s-app=kubernetes-dashboard</span><br></pre></td></tr></table></figure><h3 id="访问Dashboard"><a href="#访问Dashboard" class="headerlink" title="访问Dashboard"></a>访问Dashboard</h3><blockquote><ul><li>kubernetes-dashborad的svc默认是<code>clusterIP</code>，需要修改为<code>nodePort</code>才能被外部访问</li><li>随机分配<code>NodePort</code>，分配范围由<code>kube-apiserver</code>的<code>--service-node-port-range</code>参数指定</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl patch -n kube-system svc kubernetes-dashboard -p '&#123;"spec":&#123;"type":"NodePort"&#125;&#125;'</span><br></pre></td></tr></table></figure><blockquote><ul><li>修改完之后，通过以下命令获取访问kubernetes-Dashboard的端口</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get svc --selector k8s-app=kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.106.183.192   &lt;none&gt;        443:30216/TCP   12s</span><br></pre></td></tr></table></figure><blockquote><ul><li>可以看到已经将节点的<code>30216</code>端口暴露出来</li></ul></blockquote><blockquote><ul><li><p>IP地址不固定，只要运行了kube-proxy组件，都会在节点上添加<code>30216</code>端口规则用于转发请求到Pod</p><p><a href="https://172.16.80.200:30216" target="_blank" rel="noopener">https://172.16.80.200:30216</a></p><p><a href="https://172.16.80.201:30216" target="_blank" rel="noopener">https://172.16.80.201:30216</a></p><p><a href="https://172.16.80.202:30216" target="_blank" rel="noopener">https://172.16.80.202:30216</a></p><p><a href="https://172.16.80.203:30216" target="_blank" rel="noopener">https://172.16.80.203:30216</a></p></li><li><p>登录Dashboard，上面已经获取了token，这里只需要把token的值填入输入框，点击<code>SIGN IN</code>即可登录</p></li></ul></blockquote><h3 id="Dashboard-UI预览图"><a href="#Dashboard-UI预览图" class="headerlink" title="Dashboard UI预览图"></a>Dashboard UI预览图</h3><p><img src="https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.0/docs/dashboard-ui.png" alt=""></p><h2 id="Ingress-Controller"><a href="#Ingress-Controller" class="headerlink" title="Ingress Controller"></a>Ingress Controller</h2><blockquote><ul><li>Ingress 是 Kubernetes 中的一个抽象资源，其功能是通过 Web Server 的 Virtual Host<br>概念以域名(Domain Name)方式转发到內部 Service，这避免了使用 Service 中的 NodePort 与<br>LoadBalancer 类型所带來的限制(如 Port 数量上限)，而实现 Ingress 功能则是通过 Ingress Controller<br>来达成，它会负责监听 Kubernetes API 中的 Ingress 与 Service 资源，并在发生资源变化时，根据资源预期的结果来设置 Web Server。</li><li>Ingress Controller 有许多实现可以选择，这里只是列举一小部分<ul><li><a href="https://github.com/kubernetes/ingress-nginx" target="_blank" rel="noopener">Ingress NGINX</a>：Kubernetes 官方维护的方案，<font color="red">本次安装使用此方案</font></li><li><a href="https://github.com/nginxinc/kubernetes-ingress" target="_blank" rel="noopener">kubernetes-ingress</a>：由nginx社区维护的方案，使用社区版nginx和nginx-plus</li><li><a href="https://github.com/containous/traefik" target="_blank" rel="noopener">treafik</a>：一款开源的反向代理与负载均衡工具。它最大的优点是能够与常见的微服务系统直接整合，可以实现自动化动态配置</li></ul></li><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><h3 id="创建工作目录-6"><a href="#创建工作目录-6" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/ingress/ingress-nginx</span><br></pre></td></tr></table></figure><h3 id="切换工作目录-6"><a href="#切换工作目录-6" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/ingress/ingress-nginx</span><br></pre></td></tr></table></figure><h3 id="下载yaml文件-3"><a href="#下载yaml文件-3" class="headerlink" title="下载yaml文件"></a>下载yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.20.0/deploy/mandatory.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.20.0/deploy/provider/baremetal/service-nodeport.yaml</span><br></pre></td></tr></table></figure><h3 id="修改镜像地址-1"><a href="#修改镜像地址-1" class="headerlink" title="修改镜像地址"></a>修改镜像地址</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sed -e 's,k8s.gcr.io/,zhangguanzhang/gcr.io.google_containers.,g' \</span><br><span class="line">    -e 's,quay.io/kubernetes-ingress-controller/,zhangguanzhang/quay.io.kubernetes-ingress-controller.,g' \</span><br><span class="line">    -i mandatory.yaml</span><br></pre></td></tr></table></figure><h3 id="创建ingress-nginx"><a href="#创建ingress-nginx" class="headerlink" title="创建ingress-nginx"></a>创建ingress-nginx</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f .</span><br></pre></td></tr></table></figure><h3 id="检查部署情况-2"><a href="#检查部署情况-2" class="headerlink" title="检查部署情况"></a>检查部署情况</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n ingress-nginx get pod</span><br></pre></td></tr></table></figure><h3 id="访问ingress"><a href="#访问ingress" class="headerlink" title="访问ingress"></a>访问ingress</h3><blockquote><ul><li>默认的backend会返回404</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n ingress-nginx get svc</span><br><span class="line">NAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">ingress-nginx   NodePort   10.96.250.140   &lt;none&gt;        80:32603/TCP,443:30083/TCP   1m</span><br><span class="line"></span><br><span class="line">curl http://172.16.80.200:32603</span><br><span class="line">default backend - 404</span><br><span class="line"></span><br><span class="line">curl -k https://172.16.80.200:30083</span><br><span class="line">default backend - 404</span><br></pre></td></tr></table></figure><blockquote><font color="red"><strong>注意</strong></font><ul><li><p>这里部署之后，是<code>deployment</code>，且通过<code>nodePort</code>暴露服务</p></li><li><p>也可以修改yaml文件，将<code>Ingress-nginx</code>部署为<code>DaemonSet</code></p><ul><li>使用<code>labels</code>和<code>nodeSelector</code>来指定运行ingress-nginx的节点</li><li>使用<code>hostNetwork=true</code>来共享主机网络命名空间，或者使用<code>hostPort</code>指定主机端口映射</li><li>如果使用<code>hostNetwork</code>共享宿主机网络栈或者<code>hostPort</code>映射宿主机端口，记得要看看有没有端口冲突，否则无法启动</li><li>修改监听端口可以在<code>ingress-nginx</code>启动命令中添加<code>--http-port=8180</code>和<code>--https-port=8543</code>，还有下面的端口定义也相应变更即可</li></ul></li></ul></blockquote><h3 id="创建kubernetes-Dashboard的Ingress"><a href="#创建kubernetes-Dashboard的Ingress" class="headerlink" title="创建kubernetes-Dashboard的Ingress"></a>创建kubernetes-Dashboard的Ingress</h3><blockquote><ul><li>kubernetes-Dashboard默认是开启了HTTPS访问的</li><li>ingress-nginx需要以HTTPS的方式反向代理kubernetes-Dashboard</li><li>以HTTP方式访问kubernetes-Dashboard的时候会被重定向到HTTPS</li><li>需要创建HTTPS证书，用于访问ingress-nginx的HTTPS端口</li></ul></blockquote><h4 id="创建HTTPS证书"><a href="#创建HTTPS证书" class="headerlink" title="创建HTTPS证书"></a>创建HTTPS证书</h4><blockquote><ul><li>这里的<code>CN=域名/O=域名</code>需要跟后面的ingress主机名匹配</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">openssl req -x509 \</span><br><span class="line">            -nodes \</span><br><span class="line">            -days 3650 \</span><br><span class="line">            -newkey rsa:2048 \</span><br><span class="line">            -keyout tls.key \</span><br><span class="line">            -out tls.crt \</span><br><span class="line">            -subj "/CN=dashboard.k8s.local/O=dashboard.k8s.local"</span><br></pre></td></tr></table></figure><h4 id="创建secret对象"><a href="#创建secret对象" class="headerlink" title="创建secret对象"></a>创建secret对象</h4><blockquote><ul><li>这里将HTTPS证书创建为kubernetes的secret对象<code>dashboard-tls</code></li><li>ingress创建的时候需要加载这个作为HTTPS证书</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system create secret tls dashboard-tls --key ./tls.key --cert ./tls.crt</span><br></pre></td></tr></table></figure><h4 id="创建dashboard-ingress-yaml"><a href="#创建dashboard-ingress-yaml" class="headerlink" title="创建dashboard-ingress.yaml"></a>创建dashboard-ingress.yaml</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">dashboard-ingress</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/ssl-passthrough:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/secure-backends:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  tls:</span></span><br><span class="line"><span class="attr">  - hosts:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">dashboard.k8s.local</span></span><br><span class="line"><span class="attr">    secretName:</span> <span class="string">dashboard-tls</span></span><br><span class="line"><span class="attr">  rules:</span></span><br><span class="line"><span class="attr">  - host:</span> <span class="string">dashboard.k8s.local</span></span><br><span class="line"><span class="attr">    http:</span></span><br><span class="line"><span class="attr">      paths:</span></span><br><span class="line"><span class="attr">        - path:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">          backend:</span></span><br><span class="line"><span class="attr">            serviceName:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">            servicePort:</span> <span class="number">443</span></span><br></pre></td></tr></table></figure><h4 id="创建ingress"><a href="#创建ingress" class="headerlink" title="创建ingress"></a>创建ingress</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f dashboard-ingress.yaml</span><br></pre></td></tr></table></figure><h4 id="检查ingress"><a href="#检查ingress" class="headerlink" title="检查ingress"></a>检查ingress</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get ingress</span><br><span class="line">NAME                HOSTS                 ADDRESS         PORTS     AGE</span><br><span class="line">dashboard-ingress   dashboard.k8s.local                   80, 443   16m</span><br></pre></td></tr></table></figure><h4 id="访问kubernetes-Dashboard"><a href="#访问kubernetes-Dashboard" class="headerlink" title="访问kubernetes-Dashboard"></a>访问kubernetes-Dashboard</h4><ul><li>修改主机hosts静态域名解析，以本文为例在hosts文件里添加<code>172.16.80.200 dashboard.k8s.local</code></li><li>使用<code>https://dashboard.k8s.local:30083</code>访问kubernetesDashboard了</li><li>添加了TLS之后，访问HTTP会被跳转到HTTPS端口，这里比较坑爹，没法自定义跳转HTTPS的端口</li><li>此处使用的是自签名证书，浏览器会提示不安全，请忽略</li><li>建议搭配<code>external-DNS</code>和<code>LoadBalancer</code>一起食用，效果更佳</li></ul><p><img src="/2018/12/08/./二进制部署 kubernetes v1.11.x 高可用集群\访问kubernetes-dashboard-ingress.png" alt=""></p><h2 id="Helm"><a href="#Helm" class="headerlink" title="Helm"></a>Helm</h2><blockquote><ul><li><a href="http://helm.sh/" target="_blank" rel="noopener">Helm</a>是一个kubernetes应用的包管理工具，用来管理<a href="https://github.com/kubernetes/charts" target="_blank" rel="noopener">charts</a>——预先配置好的安装包资源，有点类似于Ubuntu的APT和CentOS中的yum。</li><li>Helm chart是用来封装kubernetes原生应用程序的yaml文件，可以在你部署应用的时候自定义应用程序的一些metadata，便与应用程序的分发。</li><li>Helm和charts的主要作用：<ul><li>应用程序封装</li><li>版本管理</li><li>依赖检查</li><li>便于应用程序分发</li></ul></li></ul></blockquote><h3 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h3><blockquote><ul><li>kubernetes v1.6及以上的版本，启用RBAC</li><li>集群可以访问到chart仓库</li><li>helm客户端主机能访问kubernetes集群</li></ul></blockquote><h3 id="安装客户端"><a href="#安装客户端" class="headerlink" title="安装客户端"></a>安装客户端</h3><blockquote><p>安装方式二选一，需要<font color="red">科学上网</font></p></blockquote><h4 id="直接脚本安装"><a href="#直接脚本安装" class="headerlink" title="直接脚本安装"></a>直接脚本安装</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 使用脚本安装，默认是最新版 ---'</span><br><span class="line">curl https://raw.githubusercontent.com/helm/helm/master/scripts/get | bash</span><br></pre></td></tr></table></figure><h4 id="下载二进制文件安装"><a href="#下载二进制文件安装" class="headerlink" title="下载二进制文件安装"></a>下载二进制文件安装</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 下载二进制文件安装 ---'</span><br><span class="line">wget https://storage.googleapis.com/kubernetes-helm/helm-v2.12.0-linux-amd64.tar.gz</span><br><span class="line">tar xzf helm-v2.12.0-linux-amd64.tar.gz linux-amd64/helm</span><br><span class="line">mv linux-amd64/helm /usr/local/bin/</span><br><span class="line">rm -rf linux-amd64</span><br></pre></td></tr></table></figure><h3 id="创建工作目录-7"><a href="#创建工作目录-7" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /root/yaml/helm/</span><br></pre></td></tr></table></figure><h3 id="切换工作目录-7"><a href="#切换工作目录-7" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/helm</span><br></pre></td></tr></table></figure><h3 id="创建RBAC规则"><a href="#创建RBAC规则" class="headerlink" title="创建RBAC规则"></a>创建RBAC规则</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /root/yaml/helm/helm-rbac.yaml &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建名为tiller的ServiceAccount</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: tiller</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"><span class="meta">#</span><span class="bash"> 给tiller绑定cluster-admin权限</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: tiller-cluster-rule</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: tiller</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl apply -f /root/yaml/helm/helm-rbac.yaml</span><br></pre></td></tr></table></figure><h3 id="安装服务端"><a href="#安装服务端" class="headerlink" title="安装服务端"></a>安装服务端</h3><blockquote><ul><li>这里指定了helm的stable repo国内镜像地址</li><li>具体说明请看<a href="https://github.com/BurdenBear/kube-charts-mirror" target="_blank" rel="noopener">这里</a></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">helm init --tiller-image gcrxio/tiller:v2.12.0 \</span><br><span class="line">          --service-account tiller \</span><br><span class="line">          --stable-repo-url http://mirror.azure.cn/kubernetes/charts/</span><br></pre></td></tr></table></figure><h3 id="检查安装情况"><a href="#检查安装情况" class="headerlink" title="检查安装情况"></a>检查安装情况</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get pod -l app=helm,name=tiller</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME                             READY     STATUS    RESTARTS   AGE</span><br><span class="line">tiller-deploy-84fc6cd5f9-nz4m7   1/1       Running   0          1m</span><br><span class="line"></span><br><span class="line">helm version</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">Client: &amp;version.Version&#123;SemVer:"v2.12.0", GitCommit:"d325d2a9c179b33af1a024cdb5a4472b6288016a", GitTreeState:"clean"&#125;</span><br><span class="line">Server: &amp;version.Version&#123;SemVer:"v2.12.0", GitCommit:"d325d2a9c179b33af1a024cdb5a4472b6288016a", GitTreeState:"clean"&#125;</span><br></pre></td></tr></table></figure><h3 id="添加命令行补全"><a href="#添加命令行补全" class="headerlink" title="添加命令行补全"></a>添加命令行补全</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm completion bash  &gt; /etc/bash_completion.d/helm</span><br><span class="line">source /etc/bash_completion.d/helm</span><br></pre></td></tr></table></figure><h2 id="Rook（测试用途）"><a href="#Rook（测试用途）" class="headerlink" title="Rook（测试用途）"></a>Rook（<font color="red">测试用途</font>）</h2><h3 id="说明-5"><a href="#说明-5" class="headerlink" title="说明"></a>说明</h3><blockquote><ul><li><a href="https://github.com/rook/rook" target="_blank" rel="noopener">Rook</a>是一款云原生环境下的开源分布式存储编排系统，目前已进入CNCF孵化。Rook的官方网站是<a href="https://rook.io" target="_blank" rel="noopener">https://rook.io</a></li><li>Rook将分布式存储软件转变为自我管理，自我缩放和自我修复的存储服务。它通过自动化部署，引导、配置、供应、扩展、升级、迁移、灾难恢复、监控和资源管理来实现。 Rook使用基础的云原生容器管理、调度和编排平台提供的功能来履行其职责。</li><li>Rook利用扩展点深入融入云原生环境，为调度、生命周期管理、资源管理、安全性、监控和用户体验提供无缝体验。</li><li>Ceph Custom Resource Definition（CRD）已经在Rook v0.8版本升级到Beta</li><li>其他特性请查看项目文档</li><li><font color="red"><strong>这里只用作测试环境中提供StorageClass和持久化存储</strong></font></li><li><font color="red"><strong>请慎重考虑是否部署在生产环境中</strong></font></li></ul></blockquote><h3 id="Rook与kubernetes的集成"><a href="#Rook与kubernetes的集成" class="headerlink" title="Rook与kubernetes的集成"></a>Rook与kubernetes的集成</h3><p><img src="https://rook.io/docs/rook/v0.8/media/rook-architecture.png" alt=""></p><h3 id="Rook架构图"><a href="#Rook架构图" class="headerlink" title="Rook架构图"></a>Rook架构图</h3><p><img src="https://rook.io/docs/rook/v0.8/media/kubernetes.png" alt=""></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><ul><li>这里以<code>Rook v0.8.3</code>作为示例</li><li>这里默认使用<code>/var/lib/rook/osd*</code>目录来运行OSD</li><li>需要<font color="red">最少3个节点</font>，否则无足够的节点启动集群</li><li>可以使用<code>yaml文件</code>部署和使用<code>helm chart</code>部署，这里使用<code>yaml文件</code>部署</li></ul><h4 id="创建工作目录-8"><a href="#创建工作目录-8" class="headerlink" title="创建工作目录"></a>创建工作目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/rook/</span><br></pre></td></tr></table></figure><h4 id="进入工作目录"><a href="#进入工作目录" class="headerlink" title="进入工作目录"></a>进入工作目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/rook/</span><br></pre></td></tr></table></figure><h4 id="下载yaml文件-4"><a href="#下载yaml文件-4" class="headerlink" title="下载yaml文件"></a>下载yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> operator实现自定义API用于管理rook-ceph</span></span><br><span class="line">wget https://raw.githubusercontent.com/rook/rook/v0.8.3/cluster/examples/kubernetes/ceph/operator.yaml</span><br><span class="line"><span class="meta">#</span><span class="bash"> cluster用于部署rook-ceph集群</span></span><br><span class="line">wget https://raw.githubusercontent.com/rook/rook/v0.8.3/cluster/examples/kubernetes/ceph/cluster.yaml</span><br></pre></td></tr></table></figure><h4 id="部署operator"><a href="#部署operator" class="headerlink" title="部署operator"></a>部署operator</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f operator.yaml</span><br></pre></td></tr></table></figure><h4 id="检查operator安装情况"><a href="#检查operator安装情况" class="headerlink" title="检查operator安装情况"></a>检查operator安装情况</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n rook-ceph-system get all</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME                                      READY     STATUS    RESTARTS   AGE</span><br><span class="line">pod/rook-ceph-agent-4qwvd                 1/1       Running   0          11m</span><br><span class="line">pod/rook-ceph-agent-v5ghj                 1/1       Running   0          11m</span><br><span class="line">pod/rook-ceph-agent-zv8s6                 1/1       Running   0          11m</span><br><span class="line">pod/rook-ceph-operator-745f756bd8-9gdpk   1/1       Running   0          12m</span><br><span class="line">pod/rook-discover-44lx5                   1/1       Running   0          11m</span><br><span class="line">pod/rook-discover-4d6mn                   1/1       Running   0          11m</span><br><span class="line">pod/rook-discover-mvqfv                   1/1       Running   0          11m</span><br><span class="line"></span><br><span class="line">NAME                             DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">daemonset.apps/rook-ceph-agent   3         3         3         3            3           &lt;none&gt;          11m</span><br><span class="line">daemonset.apps/rook-discover     3         3         3         3            3           &lt;none&gt;          11m</span><br><span class="line"></span><br><span class="line">NAME                                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/rook-ceph-operator   1         1         1            1           12m</span><br><span class="line"></span><br><span class="line">NAME                                            DESIRED   CURRENT   READY     AGE</span><br><span class="line">replicaset.apps/rook-ceph-operator-745f756bd8   1         1         1         12m</span><br></pre></td></tr></table></figure><h4 id="部署cluster"><a href="#部署cluster" class="headerlink" title="部署cluster"></a>部署cluster</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f cluster.yaml</span><br></pre></td></tr></table></figure><h4 id="检查cluster部署情况"><a href="#检查cluster部署情况" class="headerlink" title="检查cluster部署情况"></a>检查cluster部署情况</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n rook-ceph get all</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME                                      READY     STATUS      RESTARTS   AGE</span><br><span class="line">pod/rook-ceph-mgr-a-7944d8d79b-pvrsf      1/1       Running     0          10m</span><br><span class="line">pod/rook-ceph-mon0-ll7fc                  1/1       Running     0          11m</span><br><span class="line">pod/rook-ceph-mon1-cd2gb                  1/1       Running     0          11m</span><br><span class="line">pod/rook-ceph-mon2-vlmfc                  1/1       Running     0          10m</span><br><span class="line">pod/rook-ceph-osd-id-0-745486df7b-4dxdc   1/1       Running     0          10m</span><br><span class="line">pod/rook-ceph-osd-id-1-85fdf4cd64-ftmc4   1/1       Running     0          10m</span><br><span class="line">pod/rook-ceph-osd-id-2-6bc4fbb457-295pn   1/1       Running     0          10m</span><br><span class="line">pod/rook-ceph-osd-prepare-k8s-m1-klv5j    0/1       Completed   0          10m</span><br><span class="line">pod/rook-ceph-osd-prepare-k8s-m2-dt2pl    0/1       Completed   0          10m</span><br><span class="line">pod/rook-ceph-osd-prepare-k8s-m3-ndqpl    0/1       Completed   0          10m</span><br><span class="line"></span><br><span class="line">NAME                                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">service/rook-ceph-mgr                      ClusterIP   10.100.158.219   &lt;none&gt;        9283/TCP         10m</span><br><span class="line">service/rook-ceph-mgr-dashboard            ClusterIP   10.107.141.138   &lt;none&gt;        7000/TCP         10m</span><br><span class="line">service/rook-ceph-mgr-dashboard-external   NodePort    10.99.89.12      &lt;none&gt;        7000:30660/TCP   10m</span><br><span class="line">service/rook-ceph-mon0                     ClusterIP   10.100.50.229    &lt;none&gt;        6790/TCP         11m</span><br><span class="line">service/rook-ceph-mon1                     ClusterIP   10.110.105.207   &lt;none&gt;        6790/TCP         11m</span><br><span class="line">service/rook-ceph-mon2                     ClusterIP   10.103.223.166   &lt;none&gt;        6790/TCP         10m</span><br><span class="line"></span><br><span class="line">NAME                                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/rook-ceph-mgr-a      1         1         1            1           10m</span><br><span class="line">deployment.apps/rook-ceph-osd-id-0   1         1         1            1           10m</span><br><span class="line">deployment.apps/rook-ceph-osd-id-1   1         1         1            1           10m</span><br><span class="line">deployment.apps/rook-ceph-osd-id-2   1         1         1            1           10m</span><br><span class="line"></span><br><span class="line">NAME                                            DESIRED   CURRENT   READY     AGE</span><br><span class="line">replicaset.apps/rook-ceph-mgr-a-7944d8d79b      1         1         1         10m</span><br><span class="line">replicaset.apps/rook-ceph-mon0                  1         1         1         11m</span><br><span class="line">replicaset.apps/rook-ceph-mon1                  1         1         1         11m</span><br><span class="line">replicaset.apps/rook-ceph-mon2                  1         1         1         10m</span><br><span class="line">replicaset.apps/rook-ceph-osd-id-0-745486df7b   1         1         1         10m</span><br><span class="line">replicaset.apps/rook-ceph-osd-id-1-85fdf4cd64   1         1         1         10m</span><br><span class="line">replicaset.apps/rook-ceph-osd-id-2-6bc4fbb457   1         1         1         10m</span><br><span class="line"></span><br><span class="line">NAME                                     DESIRED   SUCCESSFUL   AGE</span><br><span class="line">job.batch/rook-ceph-osd-prepare-k8s-m1   1         1            10m</span><br><span class="line">job.batch/rook-ceph-osd-prepare-k8s-m2   1         1            10m</span><br><span class="line">job.batch/rook-ceph-osd-prepare-k8s-m3   1         1            10m</span><br></pre></td></tr></table></figure><h4 id="检查ceph集群状态"><a href="#检查ceph集群状态" class="headerlink" title="检查ceph集群状态"></a>检查ceph集群状态</h4><blockquote><ul><li>上面命令已经获取ceph-mon0节点的pod名<code>rook-ceph-mon0-ll7fc</code>，以此pod为例运行以下命令</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n rook-ceph exec -it rook-ceph-mon0-ll7fc -- ceph -s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">  cluster:</span><br><span class="line">    id:     1fcee02c-fd98-4b13-bfed-de7b6605a237</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum rook-ceph-mon0,rook-ceph-mon2,rook-ceph-mon1</span><br><span class="line">    mgr: a(active)</span><br><span class="line">    osd: 3 osds: 3 up, 3 in</span><br><span class="line"> </span><br><span class="line">  data:</span><br><span class="line">    pools:   1 pools, 100 pgs</span><br><span class="line">    objects: 0 objects, 0 bytes</span><br><span class="line">    usage:   22767 MB used, 96979 MB / 116 GB avail</span><br><span class="line">    pgs:     100 active+clean</span><br></pre></td></tr></table></figure><h3 id="暴露ceph-mgr的dashboard"><a href="#暴露ceph-mgr的dashboard" class="headerlink" title="暴露ceph-mgr的dashboard"></a>暴露ceph-mgr的dashboard</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/rook/rook/v0.8.3/cluster/examples/kubernetes/ceph/dashboard-external.yaml</span><br><span class="line">kubectl apply -f dashboard-external.yaml</span><br></pre></td></tr></table></figure><h3 id="访问已暴露的dashboard"><a href="#访问已暴露的dashboard" class="headerlink" title="访问已暴露的dashboard"></a>访问已暴露的dashboard</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n rook-ceph get svc</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME                               TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">rook-ceph-mgr                      ClusterIP   10.100.158.219   &lt;none&gt;        9283/TCP         12m</span><br><span class="line">rook-ceph-mgr-dashboard            ClusterIP   10.107.141.138   &lt;none&gt;        7000/TCP         12m</span><br><span class="line">rook-ceph-mgr-dashboard-external   NodePort    10.99.89.12      &lt;none&gt;        7000:30660/TCP   11m</span><br><span class="line">rook-ceph-mon0                     ClusterIP   10.100.50.229    &lt;none&gt;        6790/TCP         13m</span><br><span class="line">rook-ceph-mon1                     ClusterIP   10.110.105.207   &lt;none&gt;        6790/TCP         13m</span><br><span class="line">rook-ceph-mon2                     ClusterIP   10.103.223.166   &lt;none&gt;        6790/TCP         12m</span><br></pre></td></tr></table></figure><blockquote><ul><li>可以见到这里暴露<code>30660</code>端口，通过此端口可以访问Dashboard</li></ul></blockquote><h3 id="添加StorageClass"><a href="#添加StorageClass" class="headerlink" title="添加StorageClass"></a>添加StorageClass</h3><blockquote><ul><li>添加<code>多副本</code>存储池</li><li>注释部分是创建<code>纠删码</code>存储池</li><li>添加<code>StorageClass</code>指定使用<code>多副本</code>存储池，格式化为<code>xfs</code></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; rbd-storageclass.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: ceph.rook.io/v1beta1</span><br><span class="line">kind: Pool</span><br><span class="line">metadata:</span><br><span class="line">  name: replicapool</span><br><span class="line">  namespace: rook-ceph</span><br><span class="line">spec:</span><br><span class="line">  replicated:</span><br><span class="line">    size: 3</span><br><span class="line"><span class="meta">  #</span><span class="bash"> For an erasure-coded pool, comment out the replication size above and uncomment the following settings.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Make sure you have enough OSDs to support the replica size or erasure code chunks.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">erasureCoded:</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">  dataChunks: 2</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">  codingChunks: 1</span></span><br><span class="line">---</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">   name: rook-ceph-block</span><br><span class="line">provisioner: ceph.rook.io/block</span><br><span class="line">parameters:</span><br><span class="line">  pool: replicapool</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Specify the namespace of the rook cluster from <span class="built_in">which</span> to create volumes.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> If not specified, it will use `rook` as the default namespace of the cluster.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> This is also the namespace <span class="built_in">where</span> the cluster will be</span></span><br><span class="line">  clusterNamespace: rook-ceph</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Specify the filesystem <span class="built_in">type</span> of the volume. If not specified, it will use `ext4`.</span></span><br><span class="line">  fstype: xfs</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl apply -f rbd-storageclass.yaml</span><br></pre></td></tr></table></figure><blockquote><ul><li>还可以添加<code>cephFS</code>和<code>object</code>类型的存储池，然后创建对应的<code>StorageClass</code></li></ul></blockquote><p>具体可以看<a href="https://raw.githubusercontent.com/rook/rook/v0.8.3/cluster/examples/kubernetes/ceph/filesystem.yaml" target="_blank" rel="noopener">filesystem.yaml</a>和<a href="https://raw.githubusercontent.com/rook/rook/v0.8.3/cluster/examples/kubernetes/ceph/object.yaml" target="_blank" rel="noopener">object.yaml</a></p><h3 id="检查StorageClass"><a href="#检查StorageClass" class="headerlink" title="检查StorageClass"></a>检查StorageClass</h3><blockquote><ul><li>创建sc时，会在<code>rook-ceph</code>上创建对应的Pool</li><li>这里以<code>rbd-storageclass.yaml</code>为例</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">kubectl get sc</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME              PROVISIONER          AGE</span><br><span class="line">rook-ceph-block   ceph.rook.io/block   15m</span><br><span class="line"></span><br><span class="line">kubectl describe sc rook-ceph-block </span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">Name:            rook-ceph-block</span><br><span class="line">IsDefaultClass:  No</span><br><span class="line">Annotations:     kubectl.kubernetes.io/last-applied-configuration=&#123;"apiVersion":"storage.k8s.io/v1","kind":"StorageClass","metadata":&#123;"annotations":&#123;&#125;,"name":"rook-ceph-block","namespace":""&#125;,"parameters":&#123;"clusterNamespace":"rook-ceph","fstype":"xfs","pool":"replicapool"&#125;,"provisioner":"ceph.rook.io/block"&#125;</span><br><span class="line"></span><br><span class="line">Provisioner:           ceph.rook.io/block</span><br><span class="line">Parameters:            clusterNamespace=rook-ceph,fstype=xfs,pool=replicapool</span><br><span class="line">AllowVolumeExpansion:  &lt;unset&gt;</span><br><span class="line">MountOptions:          &lt;none&gt;</span><br><span class="line">ReclaimPolicy:         Delete</span><br><span class="line">VolumeBindingMode:     Immediate</span><br><span class="line">Events:                &lt;none&gt;</span><br><span class="line"></span><br><span class="line">kubectl -n rook-ceph exec -it rook-ceph-mon0-ll7fc -- ceph df</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">GLOBAL:</span><br><span class="line">    SIZE     AVAIL      RAW USED     %RAW USED </span><br><span class="line">    116G     96979M       22767M         19.01 </span><br><span class="line">POOLS:</span><br><span class="line">    NAME            ID     USED     %USED     MAX AVAIL     OBJECTS </span><br><span class="line">    replicapool     1         0         0        29245M           0</span><br></pre></td></tr></table></figure><h3 id="卸载Rook-ceph"><a href="#卸载Rook-ceph" class="headerlink" title="卸载Rook-ceph"></a>卸载Rook-ceph</h3><blockquote><ul><li>这里提供卸载的操作步骤，请按需操作！</li></ul></blockquote><h4 id="删除StorageClass"><a href="#删除StorageClass" class="headerlink" title="删除StorageClass"></a>删除StorageClass</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f rbd-storageclass.yaml</span><br></pre></td></tr></table></figure><h4 id="删除Rook-Ceph-Cluster"><a href="#删除Rook-Ceph-Cluster" class="headerlink" title="删除Rook-Ceph-Cluster"></a>删除Rook-Ceph-Cluster</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f cluster.yaml</span><br></pre></td></tr></table></figure><h4 id="删除Rook-Operator"><a href="#删除Rook-Operator" class="headerlink" title="删除Rook-Operator"></a>删除Rook-Operator</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f operator.yaml</span><br></pre></td></tr></table></figure><h4 id="清理目录"><a href="#清理目录" class="headerlink" title="清理目录"></a>清理目录</h4><blockquote><ul><li><font color="red">注意！</font>这里是所有运行rook-ceph集群的节点都需要做清理</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf /var/lib/rook</span><br></pre></td></tr></table></figure><h2 id="Prometheus-Operator"><a href="#Prometheus-Operator" class="headerlink" title="Prometheus Operator"></a>Prometheus Operator</h2><h3 id="说明-6"><a href="#说明-6" class="headerlink" title="说明"></a>说明</h3><blockquote><ul><li>Prometheus Operator 是 CoreOS 开发的基于 Prometheus 的 Kubernetes 监控方案，也可能是目前功能最全面的开源方案。</li><li>Prometheus Operator 通过 Grafana 展示监控数据，预定义了一系列的 Dashboard</li><li>要求kubernetes版本大于等于<code>1.8.0</code></li><li><a href="https://github.com/coreos/prometheus-operator" target="_blank" rel="noopener">CoreOS/Prometheus-Operator项目地址</a></li></ul></blockquote><h3 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h3><blockquote><ul><li>Prometheus 是一套开源的系统监控报警框架，启发于 Google 的 borgmon 监控系统，作为社区开源项目进行开发，并成为CNCF第二个毕业的项目（第一个是kubernetes）</li><li>特点<ul><li>强大的多维度数据模型</li><li>灵活而强大的查询语句（PromQL）</li><li>易于管理，高效</li><li>使用 pull 模式采集时间序列数据，这样不仅有利于本机测试而且可以避免有问题的服务器推送坏的 metrics。</li><li>可以采用 push gateway 的方式把时间序列数据推送至 Prometheus server 端</li><li>可以通过服务发现或者静态配置去获取监控的 targets</li><li>有多种可视化图形界面</li><li>易于伸缩</li></ul></li></ul></blockquote><h4 id="Prometheus组成架构"><a href="#Prometheus组成架构" class="headerlink" title="Prometheus组成架构"></a>Prometheus组成架构</h4><blockquote><ul><li><strong>Prometheus Server</strong>: 用于收集和存储时间序列数据</li><li><strong>Client Library</strong>: 客户端库，为需要监控的服务生成相应的 metrics 并暴露给<br>Prometheus server</li><li><strong>Push Gateway</strong>: 主要用于短期的 jobs。 jobs 可以直接向 Prometheus server 端推送它们的<br>metrics。这种方式主要用于服务层面的 metrics。</li><li><strong>Exporters</strong>: 用于暴露已有的第三方服务的 metrics 给 Prometheus。</li><li><strong>Alertmanager</strong>: 从 Prometheus server 端接收到 alerts<br>后，会进行去除重复数据，分组，并路由到对收的接受方式，发出报警。</li></ul></blockquote><h4 id="架构图-2"><a href="#架构图-2" class="headerlink" title="架构图"></a>架构图</h4><p><img src="https://prometheus.io/assets/architecture.png" alt=""></p><h3 id="Operator架构"><a href="#Operator架构" class="headerlink" title="Operator架构"></a>Operator架构</h3><blockquote><ul><li><p><strong>Operator</strong></p><p>即 Prometheus Operator，在 Kubernetes 中以 Deployment 运行。其职责是部署和管理<br>Prometheus Server，根据 ServiceMonitor 动态更新 Prometheus Server 的监控对象。</p></li><li><p><strong>Prometheus Server</strong></p><p>Prometheus Server 会作为 Kubernetes 应用部署到集群中。为了更好地在 Kubernetes 中管理 Prometheus，CoreOS 的开发人员专门定义了一个命名为 <code>Prometheus</code> 类型的 Kubernetes 定制化资源。我们可以把 <code>Prometheus</code>看作是一种特殊的 Deployment，它的用途就是专门部署 Prometheus Server。</p></li><li><p><strong>Service</strong></p><p>这里的<br>Service 就是 Cluster 中的 Service 资源，也是 Prometheus 要监控的对象，在 Prometheus 中叫做<br>Target。每个监控对象都有一个对应的 Service。比如要监控 Kubernetes Scheduler，就得有一个与 Scheduler<br>对应的 Service。当然，Kubernetes 集群默认是没有这个 Service 的，Prometheus Operator<br>会负责创建。</p></li><li><p><strong>ServiceMonitor</strong></p><p>Operator<br>能够动态更新 Prometheus 的 Target 列表，ServiceMonitor 就是 Target 的抽象。比如想监控<br>Kubernetes Scheduler，用户可以创建一个与 Scheduler Service 相映射的 ServiceMonitor<br>对象。Operator 则会发现这个新的 ServiceMonitor，并将 Scheduler 的 Target 添加到 Prometheus<br>的监控列表中。</p><p>ServiceMonitor 也是 Prometheus Operator 专门开发的一种 Kubernetes 定制化资源类型。</p></li><li><p><strong>Alertmanager</strong></p><p>除了 Prometheus 和 ServiceMonitor，Alertmanager 是 Operator 开发的第三种 Kubernetes 定制化资源。我们可以把 <code>Alertmanager</code> 看作是一种特殊的 Deployment，它的用途就是专门部署 Alertmanager 组件。</p></li></ul></blockquote><p><img src="https://github.com/coreos/prometheus-operator/raw/release-0.26/Documentation/user-guides/images/architecture.png" alt=""></p><h3 id="部署Prometheus-Operator"><a href="#部署Prometheus-Operator" class="headerlink" title="部署Prometheus-Operator"></a>部署Prometheus-Operator</h3><h4 id="切换工作目录-8"><a href="#切换工作目录-8" class="headerlink" title="切换工作目录"></a>切换工作目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/prometheus-operator</span><br><span class="line">cd /root/yaml/prometheus-operator</span><br></pre></td></tr></table></figure><h4 id="添加coreos源"><a href="#添加coreos源" class="headerlink" title="添加coreos源"></a>添加coreos源</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 添加coreos源</span></span><br><span class="line">helm repo add coreos https://s3-eu-west-1.amazonaws.com/coreos-charts/stable/</span><br></pre></td></tr></table></figure><h4 id="创建命名空间"><a href="#创建命名空间" class="headerlink" title="创建命名空间"></a>创建命名空间</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create namespace monitoring</span><br></pre></td></tr></table></figure><h4 id="部署prometheus-operator"><a href="#部署prometheus-operator" class="headerlink" title="部署prometheus-operator"></a>部署prometheus-operator</h4><blockquote><ul><li>这里通过<code>--set</code>指定了image的地址</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">helm install coreos/prometheus-operator \</span><br><span class="line">    --name coreos-prometheus-operator \</span><br><span class="line">    --namespace monitoring \</span><br><span class="line">    --set global.hyperkube.repository=zhangguanzhang/quay.io.coreos.hyperkube \</span><br><span class="line">    --set image.repository=zhangguanzhang/quay.io.coreos.prometheus-operator \</span><br><span class="line">    --set prometheusConfigReloader.repository=zhangguanzhang/quay.io.coreos.prometheus-config-reloader \</span><br><span class="line">    --set rbacEnable=true</span><br></pre></td></tr></table></figure><h4 id="部署kube-prometheus"><a href="#部署kube-prometheus" class="headerlink" title="部署kube-prometheus"></a>部署kube-prometheus</h4><blockquote><ul><li>通过运行<code>helm</code>命令安装时，指定一些变量来达到自定义配置的目的</li><li>定义<code>grafana</code>初始admin密码为<code>password</code>，默认值是<code>admin</code></li><li>定义<code>alertmanager</code>和<code>prometheus</code>使用名为<code>rook-ceph-block</code>的<code>StorageClass</code>，访问模式为<code>ReadWriteOnce</code>，大小<code>5Gi</code>，默认是<code>50Gi</code></li><li>定义<code>grafana</code>、<code>alertmanager</code>、<code>prometheus</code>的<code>Service</code>类型为<code>NodePort</code>，默认是<code>ClusterIP</code></li><li>这里的<code>--set</code>可以定义很多变量，具体可以在<a href="https://github.com/coreos/prometheus-operator/tree/master/helm" target="_blank" rel="noopener">这里</a>，查看里面每个文件夹的<code>values.yaml</code></li><li>这里<font color="red">配置的变量</font>请自己根据情况修改</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">helm install coreos/kube-prometheus \</span><br><span class="line">    --name kube-prometheus \</span><br><span class="line">    --namespace monitoring \</span><br><span class="line">    --set alertmanager.image.repository="zhangguanzhang/quay.io.prometheus.alertmanager" \</span><br><span class="line">    --set alertmanager.service.type="NodePort" \</span><br><span class="line">    --set alertmanager.storageSpec.volumeClaimTemplate.spec.storageClassName="rook-ceph-block" \</span><br><span class="line">    --set alertmanager.storageSpec.volumeClaimTemplate.spec.accessModes[0]="ReadWriteOnce" \</span><br><span class="line">    --set alertmanager.storageSpec.volumeClaimTemplate.spec.resources.requests.storage="5Gi" \</span><br><span class="line">    --set grafana.adminPassword="password" \</span><br><span class="line">    --set grafana.service.type="NodePort" \</span><br><span class="line">    --set prometheus.image.repository="zhangguanzhang/quay.io.prometheus.prometheus" \</span><br><span class="line">    --set prometheus.service.type="NodePort" \</span><br><span class="line">    --set prometheus.storageSpec.volumeClaimTemplate.spec.storageClassName="rook-ceph-block" \</span><br><span class="line">    --set prometheus.storageSpec.volumeClaimTemplate.spec.accessModes[0]="ReadWriteOnce" \</span><br><span class="line">    --set prometheus.storageSpec.volumeClaimTemplate.spec.resources.requests.storage="5Gi" \</span><br><span class="line">    --set prometheus.deployCoreDNS=true \</span><br><span class="line">    --set prometheus.deployKubeDNS=false \</span><br><span class="line">    --set prometheus.deployKubeEtcd=true \</span><br><span class="line">    --set exporter-kube-controller-manager.endpoints[0]="172.16.80.201" \</span><br><span class="line">    --set exporter-kube-controller-manager.endpoints[1]="172.16.80.202" \</span><br><span class="line">    --set exporter-kube-controller-manager.endpoints[2]="172.16.80.203" \</span><br><span class="line">    --set exporter-kube-etcd.etcdPort=2379 \</span><br><span class="line">    --set exporter-kube-etcd.scheme="https" \</span><br><span class="line">    --set exporter-kube-etcd.endpoints[0]="172.16.80.201" \</span><br><span class="line">    --set exporter-kube-etcd.endpoints[1]="172.16.80.202" \</span><br><span class="line">    --set exporter-kube-etcd.endpoints[2]="172.16.80.203" \</span><br><span class="line">    --set exporter-kube-scheduler.endpoints[0]="172.16.80.201" \</span><br><span class="line">    --set exporter-kube-scheduler.endpoints[1]="172.16.80.202" \</span><br><span class="line">    --set exporter-kube-scheduler.endpoints[2]="172.16.80.203" \</span><br><span class="line">    --set exporter-kube-state.kube_state_metrics.image.repository="gcrxio/kube-state-metrics" \</span><br><span class="line">    --set exporter-kube-state.addon_resizer.image.repository="gcrxio/addon-resizer"</span><br></pre></td></tr></table></figure><h4 id="检查部署情况-3"><a href="#检查部署情况-3" class="headerlink" title="检查部署情况"></a>检查部署情况</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n monitoring get all</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME                                                       READY     STATUS    RESTARTS   AGE</span><br><span class="line">pod/alertmanager-kube-prometheus-0                         2/2       Running   0          43m</span><br><span class="line">pod/kube-prometheus-exporter-kube-state-66b8849c9b-cq5pp   2/2       Running   0          42m</span><br><span class="line">pod/kube-prometheus-exporter-node-p6z67                    1/1       Running   0          43m</span><br><span class="line">pod/kube-prometheus-exporter-node-qnmjt                    1/1       Running   0          43m</span><br><span class="line">pod/kube-prometheus-exporter-node-vr4sp                    1/1       Running   0          43m</span><br><span class="line">pod/kube-prometheus-grafana-f869c754-x5x7n                 2/2       Running   0          43m</span><br><span class="line">pod/prometheus-kube-prometheus-0                           3/3       Running   1          43m</span><br><span class="line">pod/prometheus-operator-5db9df7ffc-dxtqh                   1/1       Running   0          49m</span><br><span class="line"></span><br><span class="line">NAME                                          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">service/alertmanager-operated                 ClusterIP   None             &lt;none&gt;        9093/TCP,6783/TCP   43m</span><br><span class="line">service/kube-prometheus                       NodePort    10.97.183.252    &lt;none&gt;        9090:30900/TCP      43m</span><br><span class="line">service/kube-prometheus-alertmanager          NodePort    10.105.140.173   &lt;none&gt;        9093:30903/TCP      43m</span><br><span class="line">service/kube-prometheus-exporter-kube-state   ClusterIP   10.108.236.146   &lt;none&gt;        80/TCP              43m</span><br><span class="line">service/kube-prometheus-exporter-node         ClusterIP   10.96.14.75      &lt;none&gt;        9100/TCP            43m</span><br><span class="line">service/kube-prometheus-grafana               NodePort    10.109.4.170     &lt;none&gt;        80:30164/TCP        43m</span><br><span class="line">service/prometheus-operated                   ClusterIP   None             &lt;none&gt;        9090/TCP            43m</span><br><span class="line"></span><br><span class="line">NAME                                           DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">daemonset.apps/kube-prometheus-exporter-node   3         3         3         3            3           &lt;none&gt;          43m</span><br><span class="line"></span><br><span class="line">NAME                                                  DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/kube-prometheus-exporter-kube-state   1         1         1            1           43m</span><br><span class="line">deployment.apps/kube-prometheus-grafana               1         1         1            1           43m</span><br><span class="line">deployment.apps/prometheus-operator                   1         1         1            1           49m</span><br><span class="line"></span><br><span class="line">NAME                                                             DESIRED   CURRENT   READY     AGE</span><br><span class="line">replicaset.apps/kube-prometheus-exporter-kube-state-658f46b8dd   0         0         0         43m</span><br><span class="line">replicaset.apps/kube-prometheus-exporter-kube-state-66b8849c9b   1         1         1         42m</span><br><span class="line">replicaset.apps/kube-prometheus-grafana-f869c754                 1         1         1         43m</span><br><span class="line">replicaset.apps/prometheus-operator-5db9df7ffc                   1         1         1         49m</span><br><span class="line"></span><br><span class="line">NAME                                            DESIRED   CURRENT   AGE</span><br><span class="line">statefulset.apps/alertmanager-kube-prometheus   1         1         43m</span><br><span class="line">statefulset.apps/prometheus-kube-prometheus     1         1         43m</span><br></pre></td></tr></table></figure><h3 id="访问Prometheus-Operator"><a href="#访问Prometheus-Operator" class="headerlink" title="访问Prometheus-Operator"></a>访问Prometheus-Operator</h3><blockquote><ul><li>部署时已经定义alertmanager、prometheus、grafana的Service为NodePort</li><li>根据检查部署的情况，得知<ul><li><code>kube-prometheus</code>的<code>NodePort</code>为<code>30900</code></li><li><code>kube-prometheus-alertmanager</code>的<code>NodePort</code>为<code>30903</code></li><li><code>kube-prometheus-grafana</code>的<code>NodePort</code>为<code>30164</code></li></ul></li><li>直接通过这些端口访问即可</li><li>grafana已内嵌了基础的Dashboard模板，以<code>admin</code>用户登录即可见</li></ul></blockquote><h2 id="EFK"><a href="#EFK" class="headerlink" title="EFK"></a>EFK</h2><h3 id="说明-7"><a href="#说明-7" class="headerlink" title="说明"></a>说明</h3><blockquote><ul><li>官方提供简单的<code>fluentd-elasticsearch</code>样例，可以作为测试用途</li><li>已经包含在<code>kubernetes</code>项目当中<a href="https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/fluentd-elasticsearch" target="_blank" rel="noopener">链接</a></li><li>这里使用<code>kubernetes-server-linux-amd64.tar.gz</code>里面的<code>kubernetes-src.tar.gz</code>提供的Addons</li><li>修改<code>elasticsearch</code>使用<code>rook-ceph</code>提供的<code>StorageClass</code>作为持久化存储，默认是使用<code>emptyDir</code></li></ul></blockquote><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a><font color="red">注意</font></h3><blockquote><ul><li>EFK集群部署之后，<code>kibana</code>和<code>elasticsearch</code>初始化过程会极大的消耗服务器资源</li><li>请保证你的环境能撑的住！！！！</li><li>配置不够，服务器真的会失去响应</li><li>实测3节点4C 16G SSD硬盘，CPU持续十几分钟的满载</li></ul></blockquote><h3 id="解压源代码"><a href="#解压源代码" class="headerlink" title="解压源代码"></a>解压源代码</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tar xzf kubernetes-server-linux-amd64.tar.gz kubernetes/kubernetes-src.tar.gz</span><br><span class="line">cd kubernetes</span><br><span class="line">tar xzf kubernetes/kubernetes-src.tar.gz</span><br><span class="line">tar xzf kubernetes-src.tar.gz \</span><br><span class="line">cluster/addons/fluentd-elasticsearch/es-service.yaml \</span><br><span class="line">cluster/addons/fluentd-elasticsearch/es-statefulset.yaml \</span><br><span class="line">cluster/addons/fluentd-elasticsearch/fluentd-es-configmap.yaml \</span><br><span class="line">cluster/addons/fluentd-elasticsearch/fluentd-es-ds.yaml \</span><br><span class="line">cluster/addons/fluentd-elasticsearch/kibana-deployment.yaml \</span><br><span class="line">cluster/addons/fluentd-elasticsearch/kibana-service.yaml</span><br></pre></td></tr></table></figure><h3 id="切换工作目录-9"><a href="#切换工作目录-9" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd cluster/addons/fluentd-elasticsearch/</span><br></pre></td></tr></table></figure><h3 id="修改yaml文件-1"><a href="#修改yaml文件-1" class="headerlink" title="修改yaml文件"></a>修改yaml文件</h3><blockquote><ul><li>删除es-statefuleset.yaml里面的字段，位置大概在100行左右</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">    emptyDir:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure><blockquote><ul><li>添加<code>volumeClaimTemplates</code>字段，声明使用<code>rook-ceph</code>提供的<code>StorageClass</code>，大小5Gi</li><li>位置在<code>StatefulSet.spec</code>，大概67行左右</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">volumeClaimTemplates:</span></span><br><span class="line"><span class="attr">- metadata:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  spec:</span></span><br><span class="line"><span class="attr">    accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line"><span class="attr">    storageClassName:</span> <span class="string">"rook-ceph-block"</span></span><br><span class="line"><span class="attr">    resources:</span></span><br><span class="line"><span class="attr">      requests:</span></span><br><span class="line"><span class="attr">        storage:</span> <span class="number">5</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure><blockquote><ul><li>修改后，<code>es-statefulset.yaml</code>内容如下</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># RBAC authn and authz</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">""</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"services"</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"namespaces"</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"endpoints"</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"get"</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">- kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">""</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Elasticsearch deployment itself</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">    version:</span> <span class="string">v5.6.4</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  serviceName:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      k8s-app:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">      version:</span> <span class="string">v5.6.4</span></span><br><span class="line"><span class="attr">  volumeClaimTemplates:</span></span><br><span class="line"><span class="attr">  - metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line"><span class="attr">      storageClassName:</span> <span class="string">rook-ceph-block</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          storage:</span> <span class="number">5</span><span class="string">Gi</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        k8s-app:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">        version:</span> <span class="string">v5.6.4</span></span><br><span class="line">        <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      serviceAccountName:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - image:</span> <span class="string">gcrxio/elasticsearch:v5.6.4</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line">          <span class="comment"># need more cpu upon initialization, therefore burstable class</span></span><br><span class="line"><span class="attr">          limits:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">1000</span><span class="string">m</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">9200</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">db</span></span><br><span class="line"><span class="attr">          protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">9300</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">transport</span></span><br><span class="line"><span class="attr">          protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/data</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">"NAMESPACE"</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            fieldRef:</span></span><br><span class="line"><span class="attr">              fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">        emptyDir:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">      <span class="comment"># Elasticsearch requires vm.max_map_count to be at least 262144.</span></span><br><span class="line">      <span class="comment"># If your OS already sets up this number to a higher value, feel free</span></span><br><span class="line">      <span class="comment"># to remove this init container.</span></span><br><span class="line"><span class="attr">      initContainers:</span></span><br><span class="line"><span class="attr">      - image:</span> <span class="attr">alpine:3.6</span></span><br><span class="line"><span class="attr">        command:</span> <span class="string">["/sbin/sysctl",</span> <span class="string">"-w"</span><span class="string">,</span> <span class="string">"vm.max_map_count=262144"</span><span class="string">]</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">elasticsearch-logging-init</span></span><br><span class="line"><span class="attr">        securityContext:</span></span><br><span class="line"><span class="attr">          privileged:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><blockquote><ul><li>注释<code>kibana-deployment.yaml</code>定义的环境变量</li><li>大概在35行左右</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> - name: SERVER_BASEPATH</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   value: /api/v1/namespaces/kube-system/services/kibana-logging/proxy</span></span><br></pre></td></tr></table></figure><h3 id="修改镜像地址-2"><a href="#修改镜像地址-2" class="headerlink" title="修改镜像地址"></a>修改镜像地址</h3><blockquote><ul><li>默认yaml定义的镜像地址是<code>k8s.gcr.io</code>，需要科学上网</li><li>变更成<code>gcrxio</code></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -e 's,k8s.gcr.io,gcrxio,g' -i *yaml</span><br></pre></td></tr></table></figure><h3 id="给节点打Label"><a href="#给节点打Label" class="headerlink" title="给节点打Label"></a>给节点打Label</h3><blockquote><ul><li><code>fluentd-es-ds.yaml</code>有<code>nodeSelector</code>字段定义了运行在带有<code>beta.kubernetes.io/fluentd-ds-ready: &quot;true&quot;</code>标签的节点上</li><li>这里为了方便，直接给所有节点都打上标签</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label node --all beta.kubernetes.io/fluentd-ds-ready=true</span><br></pre></td></tr></table></figure><h3 id="部署EFK"><a href="#部署EFK" class="headerlink" title="部署EFK"></a>部署EFK</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f .</span><br></pre></td></tr></table></figure><h3 id="查看部署情况-1"><a href="#查看部署情况-1" class="headerlink" title="查看部署情况"></a>查看部署情况</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get pod -l k8s-app=elasticsearch-logging</span><br><span class="line">NAME                      READY     STATUS    RESTARTS   AGE</span><br><span class="line">elasticsearch-logging-0   1/1       Running   1          10m</span><br><span class="line">elasticsearch-logging-1   1/1       Running   0          10m</span><br><span class="line"></span><br><span class="line">kubectl -n kube-system get pod -l k8s-app=kibana-logging</span><br><span class="line">NAME                             READY     STATUS    RESTARTS   AGE</span><br><span class="line">kibana-logging-56fb9d765-l95kj   1/1       Running   1          37m</span><br><span class="line"></span><br><span class="line">kubectl -n kube-system get pod -l k8s-app=fluentd-es</span><br><span class="line">NAME                      READY     STATUS    RESTARTS   AGE</span><br><span class="line">fluentd-es-v2.0.4-2mwz7   1/1       Running   0          3m</span><br><span class="line">fluentd-es-v2.0.4-7mk4d   1/1       Running   0          3m</span><br><span class="line">fluentd-es-v2.0.4-zqtpc   1/1       Running   0          3m</span><br><span class="line"></span><br><span class="line">kubectl -n kube-system get svc -l k8s-app=elasticsearch-logging</span><br><span class="line">NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">elasticsearch-logging   ClusterIP   10.111.107.21   &lt;none&gt;        9200/TCP   39m</span><br><span class="line"></span><br><span class="line">kubectl -n kube-system get svc -l k8s-app=kibana-logging</span><br><span class="line">NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">kibana-logging   ClusterIP   10.96.170.77   &lt;none&gt;        5601/TCP   39m</span><br></pre></td></tr></table></figure><h3 id="访问EFK"><a href="#访问EFK" class="headerlink" title="访问EFK"></a>访问EFK</h3><blockquote><ul><li>修改<code>elasticsearch</code>和<code>kibana</code>的<code>svc</code>为<code>nodePort</code></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl patch -n kube-system svc elasticsearch-logging -p '&#123;"spec":&#123;"type":"NodePort"&#125;&#125;'</span><br><span class="line">kubectl patch -n kube-system svc kibana-logging -p '&#123;"spec":&#123;"type":"NodePort"&#125;&#125;'</span><br></pre></td></tr></table></figure><blockquote><ul><li>查看分配的<code>nodePort</code></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get svc -l k8s-app=elasticsearch-logging</span><br><span class="line">NAME                    TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">elasticsearch-logging   NodePort   10.111.107.21   &lt;none&gt;        9200:30542/TCP   42m</span><br><span class="line"></span><br><span class="line">kubectl -n kube-system get svc -l k8s-app=kibana-logging</span><br><span class="line">NAME             TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">kibana-logging   NodePort   10.96.170.77   &lt;none&gt;        5601:30998/TCP   42m</span><br></pre></td></tr></table></figure><blockquote><ul><li>可以看到端口分别为<code>30542</code>和<code>30998</code></li></ul></blockquote><h3 id="在github上获取yaml文件"><a href="#在github上获取yaml文件" class="headerlink" title="在github上获取yaml文件"></a>在github上获取yaml文件</h3><blockquote><ul><li>如果不想用<code>kubernetes-src.tar.gz</code>里面的Addons</li><li>可以直接下载github上面的文件，也是一样的</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/kubernetes/$&#123;KUBERNETES_VERSION&#125;/cluster/addons/fluentd-elasticsearch/es-service.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/kubernetes/$&#123;KUBERNETES_VERSION&#125;/cluster/addons/fluentd-elasticsearch/es-statefulset.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/kubernetes/$&#123;KUBERNETES_VERSION&#125;/cluster/addons/fluentd-elasticsearch/fluentd-es-configmap.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/kubernetes/$&#123;KUBERNETES_VERSION&#125;/cluster/addons/fluentd-elasticsearch/fluentd-es-ds.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/kubernetes/$&#123;KUBERNETES_VERSION&#125;/cluster/addons/fluentd-elasticsearch/kibana-deployment.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/kubernetes/$&#123;KUBERNETES_VERSION&#125;/cluster/addons/fluentd-elasticsearch/kibana-service.yaml</span><br></pre></td></tr></table></figure><h1 id="本文至此结束"><a href="#本文至此结束" class="headerlink" title="本文至此结束"></a>本文至此结束</h1>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;更新记录&quot;&gt;&lt;a href=&quot;#更新记录&quot; class=&quot;headerlink&quot; title=&quot;更新记录&quot;&gt;&lt;/a&gt;更新记录&lt;/h1&gt;&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;2019年1月7日添加基于ingress-nginx使用域名+HTTPS的方式访问ku
      
    
    </summary>
    
    
      <category term="kubernetes docker" scheme="https://luanlengli.github.io/tags/kubernetes-docker/"/>
    
  </entry>
  
  <entry>
    <title>CentOS-7.6(1810)虚拟机模板制作</title>
    <link href="https://luanlengli.github.io/2018/12/05/CentOS-7-6-1810-%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A8%A1%E6%9D%BF%E5%88%B6%E4%BD%9C.html"/>
    <id>https://luanlengli.github.io/2018/12/05/CentOS-7-6-1810-虚拟机模板制作.html</id>
    <published>2018-12-05T04:23:05.000Z</published>
    <updated>2019-01-21T09:15:32.032Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CentOS-7-6-1810-虚拟机模板制作"><a href="#CentOS-7-6-1810-虚拟机模板制作" class="headerlink" title="CentOS-7.6(1810)虚拟机模板制作"></a>CentOS-7.6(1810)虚拟机模板制作</h1><blockquote><ul><li>基于RHEL7.6的CentOS-7.6(1810)在12月初正式发布了</li><li><a href="https://wiki.centos.org/zh/Manuals/ReleaseNotes/CentOS7.1810" target="_blank" rel="noopener">发行注记</a></li><li>顺便更新一下虚拟机模板，这里记录一下操作过程。</li></ul></blockquote><h1 id="下载镜像"><a href="#下载镜像" class="headerlink" title="下载镜像"></a>下载镜像</h1><blockquote><ul><li>可以在CentOS官网下载，也可以通过国内镜像源下载</li><li>下载镜像名<code>CentOS-7-x86_64-Minimal-1810.iso</code></li><li><a href="http://isoredirect.centos.org/centos/7/isos/x86_64/CentOS-7-x86_64-Minimal-1810.iso" target="_blank" rel="noopener">CentOS官网下载链接</a></li><li><a href="https://mirrors.aliyun.com/centos/7/isos/x86_64/CentOS-7-x86_64-Minimal-1810.iso" target="_blank" rel="noopener">阿里云下载链接</a></li></ul></blockquote><h1 id="创建虚拟机"><a href="#创建虚拟机" class="headerlink" title="创建虚拟机"></a>创建虚拟机</h1><blockquote><ul><li>这里使用VMware Workstation 14 Pro 版本号14.1.3 build-9474260</li><li>虚拟机规格<ul><li>客户机操作系统版本<code>Red Hat Enterprise Linux 7 64 位</code></li><li>处理器数量1</li><li>内存2GB</li><li>硬盘40GB</li><li>网络适配器<code>NAT模式</code></li></ul></li></ul></blockquote><h1 id="安装操作系统"><a href="#安装操作系统" class="headerlink" title="安装操作系统"></a>安装操作系统</h1><blockquote><ul><li>语言选择<code>English</code></li><li>软件包选择<code>Minimal Install</code></li><li>硬盘分区<ul><li>/dev/sda1<code>boot分区、1GB、EXT4</code></li><li>/dev/sda2<code>/分区、39GB、XFS</code></li><li>这里不使用swap分区，有需要可以自己增加swap分区</li></ul></li><li>网络设置<ul><li>NAT地址段为<code>172.16.80.0/24</code></li><li>这里设置为<ul><li>IP地址<code>172.16.80.200</code></li><li>子网掩码<code>255.255.255.0</code></li><li>网关<code>172.16.80.2</code></li><li>DNS<code>114.114.114.114</code></li></ul></li></ul></li><li>时区选择<code>Asia/Shanghai</code></li><li>打开网络对时</li><li>KDUMP看情况选择<code>打开</code>或者<code>关闭</code>，这里我选择<code>关闭</code></li><li>设置ROOT密码</li></ul></blockquote><h1 id="操作系统启动后初始化设置"><a href="#操作系统启动后初始化设置" class="headerlink" title="操作系统启动后初始化设置"></a>操作系统启动后初始化设置</h1><h2 id="关闭SELINUX"><a href="#关闭SELINUX" class="headerlink" title="关闭SELINUX"></a>关闭SELINUX</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed -i 's,SELINUX=enforcing,SELINUX=disabled,' /etc/selinux/config</span><br><span class="line">setenforce 0</span><br></pre></td></tr></table></figure><h2 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line">systemctl mask firewalld</span><br></pre></td></tr></table></figure><h2 id="清空iptables规则"><a href="#清空iptables规则" class="headerlink" title="清空iptables规则"></a>清空iptables规则</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">iptables -Z</span><br><span class="line">iptables -P INPUT ACCEPT</span><br><span class="line">iptables -P FORWARD ACCEPT</span><br><span class="line">iptables -P OUTPUT ACCEPT</span><br></pre></td></tr></table></figure><h2 id="配置ssh证书登录"><a href="#配置ssh证书登录" class="headerlink" title="配置ssh证书登录"></a>配置ssh证书登录</h2><blockquote><ul><li>通过ssh命令生成密钥对</li><li>将~/.ssh/id_rsa.pub提取出来</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen -t rsa -b 2048 -N "" -f ~/.ssh/id_rsa</span><br></pre></td></tr></table></figure><h2 id="添加sysctl参数"><a href="#添加sysctl参数" class="headerlink" title="添加sysctl参数"></a>添加sysctl参数</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/sysctl.d/centos.conf &lt;&lt;EOF </span><br><span class="line"><span class="meta">#</span> 最大文件句柄数</span><br><span class="line">fs.file-max=1024000</span><br><span class="line"><span class="meta">#</span> 在CentOS7.4引入了一个新的参数来控制内核的行为。 </span><br><span class="line"><span class="meta">#</span> /proc/sys/fs/may_detach_mounts 默认设置为0</span><br><span class="line"><span class="meta">#</span> 当系统有容器运行的时候，需要将该值设置为1。</span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line"><span class="meta">#</span> 最大文件打开数</span><br><span class="line">fs.nr_open=1024000</span><br><span class="line"><span class="meta">#</span> 二层的网桥在转发包时也会被iptables的FORWARD规则所过滤</span><br><span class="line">net.bridge.bridge-nf-call-arptables=1</span><br><span class="line">net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables=1</span><br><span class="line"><span class="meta">#</span> 关闭严格校验数据包的反向路径</span><br><span class="line">net.ipv4.conf.default.rp_filter=0</span><br><span class="line">net.ipv4.conf.all.rp_filter=0</span><br><span class="line"><span class="meta">#</span> 打开ipv4数据包转发</span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line"><span class="meta">#</span> 允许应用程序能够绑定到不属于本地网卡的地址</span><br><span class="line">net.ipv4.ip_nonlocal_bind=1 </span><br><span class="line"><span class="meta">#</span> 内存耗尽才使用swap分区</span><br><span class="line">vm.swappiness = 0 </span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="修改limits参数"><a href="#修改limits参数" class="headerlink" title="修改limits参数"></a>修改limits参数</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/security/limits.d/99-centos.conf &lt;&lt;EOF</span><br><span class="line">* soft nproc 1024000</span><br><span class="line">* hard nproc 1024000</span><br><span class="line">* soft nofile 1024000</span><br><span class="line">* hard nofile 1024000</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="修改终端提示符"><a href="#修改终端提示符" class="headerlink" title="修改终端提示符"></a>修改终端提示符</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">export PS1='[\t]\[\033[1;31m\]&lt;\u@\h:\w&gt;\[\033[0m\]\$ '</span><br><span class="line">cat &gt;&gt; /root/.bashrc &lt;&lt; EOF</span><br><span class="line">export PS1='[\t]\[\033[1;31m\]&lt;\u@\h:\w&gt;\[\033[0m\]\\$ '</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="修改网卡配置信息"><a href="#修改网卡配置信息" class="headerlink" title="修改网卡配置信息"></a>修改网卡配置信息</h2><blockquote><ul><li>CentOS安装设置网卡后，会添加很多不需要的字段，例如UUID、HWADDR什么的</li><li>删减后字段信息如下</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">cat /etc/sysconfig/network-scripts/ifcfg-ens33 </span><br><span class="line">TYPE=Ethernet</span><br><span class="line">BOOTPROTO=none</span><br><span class="line">NAME=ens33</span><br><span class="line">DEVICE=ens33</span><br><span class="line">ONBOOT=yes</span><br><span class="line">IPADDR=172.16.80.200</span><br><span class="line">NETMASK=255.255.255.0</span><br><span class="line">GATEWAY=172.16.80.2</span><br><span class="line">DNS1=114.114.114.114</span><br><span class="line">NM_CONTROLLED=no</span><br><span class="line">USERCTL=no</span><br></pre></td></tr></table></figure><h2 id="更新软件包"><a href="#更新软件包" class="headerlink" title="更新软件包"></a>更新软件包</h2><blockquote><ul><li>通常来说，安装完操作系统，都需要更新一下软件包</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum update -y</span><br></pre></td></tr></table></figure><h2 id="安装常用软件包"><a href="#安装常用软件包" class="headerlink" title="安装常用软件包"></a>安装常用软件包</h2><blockquote><ul><li>CentOS最小化安装不能满足我的使用，需要额外安装一些软件包</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum groups install base -y</span><br><span class="line">yum install epel-release -y</span><br><span class="line">yum install redhat-lsb vim ipvsadm tree dstat iotop htop socat ipset conntrack bash-completion-extras -y</span><br></pre></td></tr></table></figure><h2 id="添加vim设置（可选）"><a href="#添加vim设置（可选）" class="headerlink" title="添加vim设置（可选）"></a>添加vim设置（可选）</h2><blockquote><ul><li>将vim设置写入<code>~/.vimrc</code>文件</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; ~/.vimrc &lt;&lt;EOF</span><br><span class="line">" 显示行号</span><br><span class="line">set number</span><br><span class="line">" 高亮光标所在行</span><br><span class="line">set cursorline</span><br><span class="line">" 打开语法显示</span><br><span class="line">syntax on</span><br><span class="line">" 关闭备份</span><br><span class="line">set nobackup</span><br><span class="line">" 没有保存或文件只读时弹出确认</span><br><span class="line">set confirm</span><br><span class="line">" tab缩进</span><br><span class="line">set tabstop=4</span><br><span class="line">set shiftwidth=4</span><br><span class="line">set expandtab</span><br><span class="line">set smarttab</span><br><span class="line">" 默认缩进4个空格大小 </span><br><span class="line">set shiftwidth=4 </span><br><span class="line">" 文件自动检测外部更改</span><br><span class="line">set autoread</span><br><span class="line">" 高亮查找匹配</span><br><span class="line">set hlsearch</span><br><span class="line">" 显示匹配</span><br><span class="line">set showmatch</span><br><span class="line">" 背景色设置为黑色</span><br><span class="line">set background=dark</span><br><span class="line">" 浅色高亮显示当前行</span><br><span class="line">autocmd InsertLeave * se nocul</span><br><span class="line">" 显示输入的命令</span><br><span class="line">set showcmd</span><br><span class="line">" 字符编码</span><br><span class="line">set encoding=utf-8</span><br><span class="line">" 开启终端256色显示</span><br><span class="line">set t_Co=256</span><br><span class="line">" 增量式搜索 </span><br><span class="line">set incsearch</span><br><span class="line">" 设置默认进行大小写不敏感查找</span><br><span class="line">set ignorecase</span><br><span class="line">" 如果有一个大写字母，则切换到大小写敏感查找</span><br><span class="line">set smartcase</span><br><span class="line">" 不产生swap文件</span><br><span class="line">set noswapfile</span><br><span class="line">" 关闭提示音</span><br><span class="line">set noerrorbells</span><br><span class="line">" 历史记录</span><br><span class="line">set history=10000</span><br><span class="line">" 显示行尾空格</span><br><span class="line">set listchars=tab:»■,trail:■</span><br><span class="line">" 显示非可见字符</span><br><span class="line">set list</span><br><span class="line">" c文件自动缩进</span><br><span class="line">set cindent</span><br><span class="line">" 文件自动缩进</span><br><span class="line">set autoindent</span><br><span class="line">" 检测文件类型</span><br><span class="line">filetype on</span><br><span class="line">" 智能缩进</span><br><span class="line">set smartindent</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="编写ipvs模块启动关闭脚本（可选）"><a href="#编写ipvs模块启动关闭脚本（可选）" class="headerlink" title="编写ipvs模块启动关闭脚本（可选）"></a>编写ipvs模块启动关闭脚本（可选）</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 启动脚本</span><br><span class="line">cat &gt; /usr/local/bin/enable_ipvs.sh &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">ipvs_modules="ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack_ipv4"</span><br><span class="line">for kernel_module in \$&#123;ipvs_modules&#125;; do</span><br><span class="line">    /sbin/modinfo -F filename \$&#123;kernel_module&#125; &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">    if [ $? -eq 0 ]; then</span><br><span class="line">        /sbin/modprobe \$&#123;kernel_module&#125;</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">chmod 755 /usr/local/bin/enable_ipvs.sh</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 关闭脚本</span><br><span class="line">cat &gt; /usr/local/bin/disable_ipvs.sh &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">ipvs_modules="ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack_ipv4"</span><br><span class="line">for kernel_module in \$&#123;ipvs_modules&#125;; do</span><br><span class="line">    /sbin/modinfo -F filename \$&#123;kernel_module&#125; &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">    if [ $? -eq 0 ]; then</span><br><span class="line">        /sbin/modprobe -r \$&#123;kernel_module&#125;</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">chmod 755 /usr/local/bin/disable_ipvs.sh</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 开机启动脚本</span><br><span class="line">cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span>!/bin/bash</span><br><span class="line">ipvs_modules="ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack_ipv4"</span><br><span class="line">for kernel_module in \$&#123;ipvs_modules&#125;; do</span><br><span class="line">    /sbin/modinfo -F filename \$&#123;kernel_module&#125; &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">    if [ $? -eq 0 ]; then</span><br><span class="line">        /sbin/modprobe \$&#123;kernel_module&#125;</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line">EOF</span><br><span class="line">chmod 755 /etc/sysconfig/modules/ipvs.modules</span><br></pre></td></tr></table></figure><h2 id="安装docker（可选）"><a href="#安装docker（可选）" class="headerlink" title="安装docker（可选）"></a>安装docker（可选）</h2><blockquote><ul><li>版本可以自行选择自带的Docker1.13或者docker-ce</li><li>这里以docker-ce 18.03版本为例</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 删除原有的Docker包</span><br><span class="line"><span class="meta">#</span> 安装依赖包</span><br><span class="line">yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-selinux docker-engine-selinux docker-engine -y</span><br><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2 -y</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 添加Docker-CE YUM源</span><br><span class="line">yum-config-manager --add-repo http://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line"><span class="meta">#</span> 修改Docker—CE源地址</span><br><span class="line">sed -e 's,https://download.docker.com,https://mirrors.ustc.edu.cn/docker-ce,g' -i /etc/yum.repos.d/docker-ce.repo</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 安装Docker-CE 18.03</span><br><span class="line">yum install docker-ce-18.03.1.ce -y</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span> 配置docker</span><br><span class="line">mkdir -p /etc/docker</span><br><span class="line"><span class="meta">cat&gt;</span>/etc/docker/daemon.json&lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">    "registry-mirrors": ["https://registry.docker-cn.com"],</span><br><span class="line">    "insecure-registries": [],</span><br><span class="line">    "log-driver": "json-file",</span><br><span class="line">    "log-opts": &#123;</span><br><span class="line">        "max-size": "100m",</span><br><span class="line">        "max-file": "3"</span><br><span class="line">    &#125;,</span><br><span class="line">    "max-concurrent-downloads": 10</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="修改HISTORY参数"><a href="#修改HISTORY参数" class="headerlink" title="修改HISTORY参数"></a>修改HISTORY参数</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /etc/profile &lt;&lt;EOF</span><br><span class="line">export HISTSIZE=10000</span><br><span class="line">export HISTFILESIZE=10000</span><br><span class="line">export HISTCONTROL=ignoredups</span><br><span class="line">export HISTTIMEFORMAT="`whoami` %F %T "</span><br><span class="line">export HISTIGNORE="ls:pwd:"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h1 id="清理现场"><a href="#清理现场" class="headerlink" title="清理现场"></a>清理现场</h1><h3 id="清理yum缓存"><a href="#清理yum缓存" class="headerlink" title="清理yum缓存"></a>清理yum缓存</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum clean all</span><br></pre></td></tr></table></figure><h3 id="关闭操作系统"><a href="#关闭操作系统" class="headerlink" title="关闭操作系统"></a>关闭操作系统</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">history -c &amp;&amp; sys-unconfig</span><br></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;CentOS-7-6-1810-虚拟机模板制作&quot;&gt;&lt;a href=&quot;#CentOS-7-6-1810-虚拟机模板制作&quot; class=&quot;headerlink&quot; title=&quot;CentOS-7.6(1810)虚拟机模板制作&quot;&gt;&lt;/a&gt;CentOS-7.6(1810)虚
      
    
    </summary>
    
    
      <category term="linux" scheme="https://luanlengli.github.io/tags/linux/"/>
    
  </entry>
  
  <entry>
    <title>hello world~</title>
    <link href="https://luanlengli.github.io/2018/12/01/hello-world.html"/>
    <id>https://luanlengli.github.io/2018/12/01/hello-world.html</id>
    <published>2018-12-01T04:50:07.000Z</published>
    <updated>2018-12-09T06:07:41.000Z</updated>
    
    <content type="html"><![CDATA[<p>参考了<a href="https://hexo.io/zh-cn/docs/index.html" target="_blank" rel="noopener">Hexo文档</a>，简单搭建完hexo之后，又花了一些时间来调整主题什么的。</p><p>慢慢会将以前积累的文档，放到这里来。</p><p>用<code>输出</code>倒逼<code>输入</code></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;参考了&lt;a href=&quot;https://hexo.io/zh-cn/docs/index.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo文档&lt;/a&gt;，简单搭建完hexo之后，又花了一些时间来调整主题什么的。&lt;/p&gt;
&lt;p&gt;慢慢会将以前积累
      
    
    </summary>
    
    
      <category term="杂谈" scheme="https://luanlengli.github.io/tags/%E6%9D%82%E8%B0%88/"/>
    
  </entry>
  
</feed>
