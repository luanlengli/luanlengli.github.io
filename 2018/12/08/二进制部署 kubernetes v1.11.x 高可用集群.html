<!DOCTYPE html><html class="theme-next gemini use-motion" lang="zh-Hans"><head><meta name="generator" content="Hexo 3.8.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4"><link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222"><meta name="keywords" content="kubernetes,docker,"><meta name="description" content="更新记录2019年2月13日由于runc逃逸漏洞CVE-2019-5736，根据kubernetes的文档建议，修改docker-ce版本为18.09.22019年1月7日添加基于ingress-nginx使用域名+HTTPS的方式访问kubernetes-Dashboard2019年1月2日添加RBAC规则，修复kube-apiserver无法访问kubelet的问题2019年1月1日调整mas"><meta name="keywords" content="kubernetes,docker"><meta property="og:type" content="article"><meta property="og:title" content="【不定时更新】二进制部署 kubernetes v1.11.x 高可用集群"><meta property="og:url" content="https://luanlengli.github.io/2018/12/08/二进制部署 kubernetes v1.11.x 高可用集群.html"><meta property="og:site_name" content="luanlengli&#39;s Blog"><meta property="og:description" content="更新记录2019年2月13日由于runc逃逸漏洞CVE-2019-5736，根据kubernetes的文档建议，修改docker-ce版本为18.09.22019年1月7日添加基于ingress-nginx使用域名+HTTPS的方式访问kubernetes-Dashboard2019年1月2日添加RBAC规则，修复kube-apiserver无法访问kubelet的问题2019年1月1日调整mas"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="https://jimmysong.io/kubernetes-handbook/images/flannel-networking.png"><meta property="og:image" content="https://docs.projectcalico.org/images/calico-arch-gen-v3.2.svg"><meta property="og:image" content="https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.0/docs/dashboard-ui.png"><meta property="og:image" content="https://luanlengli.github.io/2018/12/08/二进制部署%20kubernetes%20v1.11.x%20高可用集群/访问kubernetes-dashboard-ingress.png"><meta property="og:image" content="https://rook.io/docs/rook/v0.8/media/rook-architecture.png"><meta property="og:image" content="https://rook.io/docs/rook/v0.8/media/kubernetes.png"><meta property="og:image" content="https://prometheus.io/assets/architecture.png"><meta property="og:image" content="https://github.com/coreos/prometheus-operator/raw/release-0.26/Documentation/user-guides/images/architecture.png"><meta property="og:updated_time" content="2019-05-21T03:13:22.000Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="【不定时更新】二进制部署 kubernetes v1.11.x 高可用集群"><meta name="twitter:description" content="更新记录2019年2月13日由于runc逃逸漏洞CVE-2019-5736，根据kubernetes的文档建议，修改docker-ce版本为18.09.22019年1月7日添加基于ingress-nginx使用域名+HTTPS的方式访问kubernetes-Dashboard2019年1月2日添加RBAC规则，修复kube-apiserver无法访问kubelet的问题2019年1月1日调整mas"><meta name="twitter:image" content="https://jimmysong.io/kubernetes-handbook/images/flannel-networking.png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"5.1.4",sidebar:{position:"right",display:"always",offset:12,b2t:!0,scrollpercent:!0,onmobile:!1},fancybox:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="https://luanlengli.github.io/2018/12/08/二进制部署 kubernetes v1.11.x 高可用集群.html"><title>【不定时更新】二进制部署 kubernetes v1.11.x 高可用集群 | luanlengli's Blog</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-right page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">luanlengli's Blog</span> <span class="logo-line-after"><i></i></span></a></div><h1 class="site-subtitle" itemprop="description">“不知道”的五大理由，不读，不查，不试，理解能力差，满脑子想着怎么利用他人</h1></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i><br>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li><li class="menu-item menu-item-search"><a href="javascript:;" class="popup-trigger"><i class="menu-item-icon fa fa-search fa-fw"></i><br>搜索</a></li></ul><div class="site-search"><div class="popup search-popup local-search-popup"><div class="local-search-header clearfix"><span class="search-icon"><i class="fa fa-search"></i> </span><span class="popup-btn-close"><i class="fa fa-times-circle"></i></span><div class="local-search-input-wrapper"><input autocomplete="off" placeholder="搜索..." spellcheck="false" type="text" id="local-search-input"></div></div><div id="local-search-result"></div></div></div></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="https://luanlengli.github.io/2018/12/08/二进制部署 kubernetes v1.11.x 高可用集群.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="乱愣黎"><meta itemprop="description" content=""><meta itemprop="image" content="/images/avatar.png"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="luanlengli's Blog"></span><header class="post-header"><h2 class="post-title" itemprop="name headline">【不定时更新】二进制部署 kubernetes v1.11.x 高可用集群</h2><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-12-08T11:34:08+08:00">2018-12-08 </time><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-calendar-check-o"></i> </span><span class="post-meta-item-text">更新于&#58;</span> <time title="更新于" itemprop="dateModified" datetime="2019-05-21T11:13:22+08:00">2019-05-21 </time></span><span id="/2018/12/08/二进制部署 kubernetes v1.11.x 高可用集群.html" class="leancloud_visitors" data-flag-title="【不定时更新】二进制部署 kubernetes v1.11.x 高可用集群"><span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-eye"></i> </span><span class="post-meta-item-text">阅读次数&#58;</span> <span class="leancloud-visitors-count"></span></span><div class="post-wordcount"><span class="post-meta-item-icon"><i class="fa fa-file-word-o"></i> </span><span class="post-meta-item-text">字数统计&#58;</span> <span title="字数统计">21.4k</span></div></div></header><div class="post-body" itemprop="articleBody"><h1 id="更新记录"><a href="#更新记录" class="headerlink" title="更新记录"></a>更新记录</h1><blockquote><ul><li>2019年2月13日由于runc逃逸漏洞<a href="https://www.anquanke.com/post/id/170762" target="_blank" rel="noopener">CVE-2019-5736</a>，根据kubernetes的<a href="https://kubernetes.io/blog/2019/02/11/runc-and-cve-2019-5736/" target="_blank" rel="noopener">文档建议</a>，修改docker-ce版本为18.09.2</li><li>2019年1月7日添加基于ingress-nginx使用域名+HTTPS的方式访问kubernetes-Dashboard</li><li>2019年1月2日添加RBAC规则，修复kube-apiserver无法访问kubelet的问题</li><li>2019年1月1日调整master节点和worker节点的操作步骤，添加CoreDNS的configmap中的hosts静态解析</li><li>2018年12月28日修改kube-prometheus部分，修复Prometheus的Targets无法发现的问题</li><li>2018年12月26日修改kubernetes-dashboard链接指向</li><li>2018年12月25日修改kubele.config.file路径问题</li><li>2018年12月18日修改kubelet和kube-proxy启动时加载config file</li><li>2018年12月17日添加EFK部署内容</li><li>2018年12月16日添加prometheus-operator部署内容</li><li>2018年12月14日添加helm部署内容，拆分etcd的server证书和client证书</li><li>2018年12月13日添加rook-ceph部署内容</li><li>2018年12月12日添加Metrics-Server内容</li><li>2018年12月11日添加Dashboard、Ingress内容</li><li>2018年12月10日添加kube-flannel、calico、CoreDNS内容</li><li>2018年12月9日分拆master节点和work节点的内容</li><li>2018年12月8日初稿</li></ul></blockquote><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>本次部署方式为二进制可执行文件的方式部署</p><blockquote><ul><li>注意<font color="red">请根据自己的实际情况调整</font></li><li>对于生产环境部署，请注意某些参数的选择</li></ul></blockquote><p>如无特殊说明，均在<font color="red">k8s-m1</font>节点上执行</p><h2 id="参考博文"><a href="#参考博文" class="headerlink" title="参考博文"></a>参考博文</h2><p>感谢两位大佬的文章，这里整合一下两位大佬的内容，结合自己的理解整理本文</p><blockquote><ul><li><a href="https://mritd.me/2018/04/19/set-up-kubernetes-1.10.1-cluster-by-hyperkube/" target="_blank" rel="noopener">【漠然】Kubernetes 1.10.1 集群搭建</a></li><li><a href="https://mritd.me/2018/08/28/kubernetes-tls-bootstrapping-with-bootstrap-token/" target="_blank" rel="noopener">【漠然】使用 Bootstrap Token 完成 TLS Bootstrapping</a></li><li><a href="https://zhangguanzhang.github.io/2018/09/18/kubernetes-1-11-x-bin/" target="_blank" rel="noopener">【张馆长】二进制部署Kubernetes v1.11.x(1.12.x) HA可选</a></li></ul></blockquote><h2 id="软件版本"><a href="#软件版本" class="headerlink" title="软件版本"></a>软件版本</h2><blockquote><ul><li><a href="https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.11.md" target="_blank" rel="noopener">kubernetes v1.11.5</a> <font color="red">【下载链接需要爬墙，自行解决】</font></li><li><a href="https://docs.docker.com/install/linux/docker-ce/" target="_blank" rel="noopener">docker-ce 18.03</a></li><li><a href="https://github.com/containernetworking/plugins/releases" target="_blank" rel="noopener">cni-plugin v0.7.4</a></li><li><a href="https://github.com/etcd-io/etcd/releases" target="_blank" rel="noopener">etcd v3.3.10</a></li></ul></blockquote><h2 id="网络信息"><a href="#网络信息" class="headerlink" title="网络信息"></a>网络信息</h2><blockquote><ul><li>基于CNI的模式实现容器网络</li><li>Cluster IP CIDR: <code>10.244.0.0/16</code></li><li>Service Cluster IP CIDR: <code>10.96.0.0/12</code></li><li>Service DNS IP: <code>10.96.0.10</code></li><li>Kubernetes API VIP: <code>172.16.80.200</code></li></ul></blockquote><h2 id="节点信息"><a href="#节点信息" class="headerlink" title="节点信息"></a>节点信息</h2><blockquote><ul><li>操作系统可采用 <code>Ubuntu Server 16.04+</code> 和 <code>CentOS 7.4+</code>，本文使用CentOS 7.6 (1810) Minimal</li><li>由<code>keepalived</code>提供VIP</li><li>由<code>haproxy</code>提供kube-apiserver四层负载均衡</li><li>由于实验环境受限，以3台服务器同时作为master和worker节点运行</li><li>服务器配置请根据实际情况适当调整</li></ul></blockquote><table><thead><tr><th style="text-align:center">IP地址</th><th style="text-align:center">主机名</th><th style="text-align:center">角色</th><th style="text-align:center">CPU</th><th style="text-align:center">内存</th></tr></thead><tbody><tr><td style="text-align:center">172.16.80.201</td><td style="text-align:center">k8s-m1</td><td style="text-align:center">master+worker</td><td style="text-align:center">4</td><td style="text-align:center">8G</td></tr><tr><td style="text-align:center">172.16.80.202</td><td style="text-align:center">k8s-m2</td><td style="text-align:center">master+worker</td><td style="text-align:center">4</td><td style="text-align:center">8G</td></tr><tr><td style="text-align:center">172.16.80.203</td><td style="text-align:center">k8s-m3</td><td style="text-align:center">master+worker</td><td style="text-align:center">4</td><td style="text-align:center">8G</td></tr></tbody></table><h2 id="目录说明"><a href="#目录说明" class="headerlink" title="目录说明"></a>目录说明</h2><blockquote><ul><li>/usr/local/bin/：存放kubernetes和etcd二进制文件</li><li>/opt/cni/bin/： 存放cni-plugin二进制文件</li><li>/etc/etcd/：存放etcd配置文件和SSL证书</li><li>/etc/kubernetes/：存放kubernetes配置和SSL证书</li><li>/etc/cni/net.d/：安装CNI插件后会在这里生成配置文件</li><li>$HOME/.kube/：kubectl命令会在家目录下建立此目录，用于保存访问kubernetes集群的配置和缓存</li><li>$HOME/.helm/：helm命令会建立此目录，用于保存helm缓存和repository信息</li></ul></blockquote><h1 id="事前准备"><a href="#事前准备" class="headerlink" title="事前准备"></a>事前准备</h1><blockquote><p>事情准备在所有服务器上都需要完成</p><p>部署过程以<code>root用户</code>完成</p></blockquote><ul><li>所有服务器<code>网络互通</code>，<code>k8s-m1</code>可以通过SSH证书免密登录到其他master节点，用于分发文件</li><li>编辑<code>/etc/hosts</code></li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/hosts &lt;&lt;EOF</span><br><span class="line">127.0.0.1 localhost</span><br><span class="line">172.16.80.200 k8s-vip</span><br><span class="line">172.16.80.201 k8s-m1</span><br><span class="line">172.16.80.202 k8s-m2</span><br><span class="line">172.16.80.203 k8s-m3</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>时间同步服务</li></ul><p>集群系统需要各节点时间同步</p><p>参考链接：<a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/system_administrators_guide/sect-using_chrony" target="_blank" rel="noopener">RHEL7官方文档</a></p><p>这里使用公网对时，如果需要内网对时，请自行配置</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum install -y chrony</span><br><span class="line">systemctl enable chronyd</span><br><span class="line">systemctl start chronyd</span><br></pre></td></tr></table></figure><ul><li>关闭firewalld和SELINUX（可根据实际情况自行决定关闭不需要的服务）</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop firewalld</span><br><span class="line">systemctl disable firewalld</span><br><span class="line">systemctl mask firewalld</span><br><span class="line"><span class="meta">#</span><span class="bash"> 清空iptables规则</span></span><br><span class="line">iptables -t filter -F</span><br><span class="line">iptables -t filter -X</span><br><span class="line">iptables -t nat -F</span><br><span class="line">iptables -t nat -X</span><br><span class="line">iptables -t mangle -F</span><br><span class="line">iptables -t mangle -X</span><br><span class="line">iptables -t raw -F</span><br><span class="line">iptables -t raw -X</span><br><span class="line">iptables -t security -F</span><br><span class="line">iptables -t security -X</span><br><span class="line">iptables -P INPUT ACCEPT</span><br><span class="line">iptables -P FORWARD ACCEPT</span><br><span class="line">iptables -P OUTPUT ACCEPT</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">setenforce 0</span><br><span class="line">sed -ri '/^[^#]*SELINUX=/s#=.+$#=disabled#' /etc/selinux/config</span><br></pre></td></tr></table></figure><ul><li>禁用swap</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">swapoff -a &amp;&amp; sysctl -w vm.swappiness=0</span><br><span class="line">sed -ri '/^[^#]*swap/s@^@#@' /etc/fstab</span><br></pre></td></tr></table></figure><ul><li>添加<code>sysctl</code>参数</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /etc/sysctl.d/centos.conf &lt;&lt;EOF </span><br><span class="line"><span class="meta">#</span><span class="bash"> 最大文件句柄数</span></span><br><span class="line">fs.file-max=1024000</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在CentOS7.4引入了一个新的参数来控制内核的行为。 </span></span><br><span class="line"><span class="meta">#</span><span class="bash"> /proc/sys/fs/may_detach_mounts 默认设置为0</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 当系统有容器运行的时候，需要将该值设置为1。</span></span><br><span class="line">fs.may_detach_mounts = 1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 最大文件打开数</span></span><br><span class="line">fs.nr_open=1024000</span><br><span class="line"><span class="meta">#</span><span class="bash"> 二层的网桥在转发包时也会被iptables的FORWARD规则所过滤</span></span><br><span class="line">net.bridge.bridge-nf-call-arptables=1</span><br><span class="line">net.bridge.bridge-nf-call-iptables=1</span><br><span class="line">net.bridge.bridge-nf-call-ip6tables=1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 关闭严格校验数据包的反向路径</span></span><br><span class="line">net.ipv4.conf.default.rp_filter=0</span><br><span class="line">net.ipv4.conf.all.rp_filter=0</span><br><span class="line"><span class="meta">#</span><span class="bash"> 打开ipv4数据包转发</span></span><br><span class="line">net.ipv4.ip_forward=1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 允许应用程序能够绑定到不属于本地网卡的地址</span></span><br><span class="line">net.ipv4.ip_nonlocal_bind=1 </span><br><span class="line"><span class="meta">#</span><span class="bash"> 表示最大限度使用物理内存，然后才是swap空间</span></span><br><span class="line">vm.swappiness = 0 </span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置系统TCP连接keepalive的持续时间，默认7200</span></span><br><span class="line">net.ipv4.tcp_keepalive_time = 600</span><br><span class="line">net.ipv4.tcp_keepalive_intvl = 30</span><br><span class="line">net.ipv4.tcp_keepalive_probes = 10</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 让sysctl参数生效</span></span><br><span class="line">sysctl --system</span><br></pre></td></tr></table></figure><ul><li>确保操作系统已经最新</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum update -y</span><br></pre></td></tr></table></figure><ul><li>安装软件包</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">yum groups install base -y</span><br><span class="line">yum install epel-release bash-completion-extras -y</span><br><span class="line">yum install git vim ipvsadm tree dstat iotop htop socat ipset conntrack -y</span><br></pre></td></tr></table></figure><ul><li>加载ipvs模块</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 开机自动加载ipvs模块</span></span><br><span class="line">cat &gt; /etc/sysconfig/modules/ipvs.modules &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">ipvs_modules="ip_vs ip_vs_lc ip_vs_wlc ip_vs_rr ip_vs_wrr ip_vs_lblc ip_vs_lblcr ip_vs_dh ip_vs_sh ip_vs_fo ip_vs_nq ip_vs_sed ip_vs_ftp nf_conntrack_ipv4"</span><br><span class="line">for kernel_module in \$&#123;ipvs_modules&#125;; do</span><br><span class="line">    /sbin/modinfo -F filename \$&#123;kernel_module&#125; &gt; /dev/null 2&gt;&amp;1</span><br><span class="line">    if [ $? -eq 0 ]; then</span><br><span class="line">        /sbin/modprobe \$&#123;kernel_module&#125;</span><br><span class="line">    fi</span><br><span class="line">done</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">chmod 755 /etc/sysconfig/modules/ipvs.modules &amp;&amp; bash /etc/sysconfig/modules/ipvs.modules &amp;&amp; lsmod | grep ip_vs</span><br></pre></td></tr></table></figure><ul><li>安装docker-ce 18.09.2</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">yum remove docker docker-client docker-client-latest docker-common docker-latest docker-latest-logrotate docker-logrotate docker-selinux docker-engine-selinux docker-engine -y</span><br><span class="line">yum install -y yum-utils device-mapper-persistent-data lvm2 -y</span><br><span class="line">yum-config-manager --add-repo http://mirrors.ustc.edu.cn/docker-ce/linux/centos/docker-ce.repo</span><br><span class="line">sed -e 's,download.docker.com,mirrors.aliyun.com/docker-ce,g' -i /etc/yum.repos.d/docker-ce.repo</span><br><span class="line">yum install docker-ce-18.09.2 -y</span><br></pre></td></tr></table></figure><ul><li>创建docker配置文件</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /etc/docker</span><br><span class="line"><span class="meta">cat&gt;</span><span class="bash">/etc/docker/daemon.json&lt;&lt;EOF</span></span><br><span class="line">&#123;</span><br><span class="line">    "registry-mirrors": ["https://registry.docker-cn.com"],</span><br><span class="line">    "insecure-registries": [],</span><br><span class="line">    "log-driver": "json-file",</span><br><span class="line">    "log-opts": &#123;</span><br><span class="line">        "max-size": "100m",</span><br><span class="line">        "max-file": "3"</span><br><span class="line">    &#125;,</span><br><span class="line">    "max-concurrent-downloads": 10</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><ul><li>配置docker命令补全</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cp /usr/share/bash-completion/completions/docker /etc/bash_completion.d/</span><br><span class="line">source /etc/bash_completion.d/docker</span><br></pre></td></tr></table></figure><ul><li>配置docker服务开机自启动</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable docker.service</span><br><span class="line">systemctl start docker.service</span><br></pre></td></tr></table></figure><ul><li>查看docker信息</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker info</span><br></pre></td></tr></table></figure><ul><li>禁用docker源</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 为避免yum update时更新docker，将docker源禁用</span></span><br><span class="line">sed -e 's,enabled=1,enabled=0,g' -i /etc/yum.repos.d/docker-ce.repo</span><br></pre></td></tr></table></figure><ul><li>确保以最新的内核启动系统</li></ul><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">reboot</span><br></pre></td></tr></table></figure><h1 id="定义集群变量"><a href="#定义集群变量" class="headerlink" title="定义集群变量"></a><strong><font color="red">定义集群变量</font></strong></h1><blockquote><font color="red"><strong>注意</strong></font><ul><li>这里的变量只对当前会话生效，如果会话断开或者重启服务器，都需要重新定义变量</li><li><code>HostArray</code>定义集群中所有节点的主机名和IP</li><li><code>MasterArray</code>定义master节点的主机名和IP</li><li><code>WorkerArray</code>定义worker节点的主机名和IP，这里master和worker都在一起，所以MasterArray和WorkerArray一样</li><li><code>VIP_IFACE</code>定义keepalived的VIP绑定在哪一个网卡</li><li><code>ETCD_SERVERS</code>以MasterArray的信息生成etcd集群服务器列表</li><li><code>ETCD_INITIAL_CLUSTER</code>以MasterArray信息生成etcd集群初始化列表</li><li><code>POD_DNS_SERVER_IP</code>定义Pod的DNS服务器IP地址</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">declare -A HostArray MasterArray WorkerArray</span><br><span class="line"><span class="meta">#</span><span class="bash"> 声明所有节点的信息</span></span><br><span class="line">HostArray=(['k8s-m1']=172.16.80.201 ['k8s-m2']=172.16.80.202 ['k8s-m3']=172.16.80.203)</span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果节点多，可以按照下面的方式声明Array</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> HostArray=([<span class="string">'k8s-m1'</span>]=172.16.80.201 [<span class="string">'k8s-m2'</span>]=172.16.80.202 [<span class="string">'k8s-m3'</span>]=172.16.80.203 [<span class="string">'k8s-n1'</span>]=172.16.80.204 [<span class="string">'k8s-n2'</span>]=172.16.80.205)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 声明master节点信息</span></span><br><span class="line">MasterArray=(['k8s-m1']=172.16.80.201 ['k8s-m2']=172.16.80.202 ['k8s-m3']=172.16.80.203)</span><br><span class="line"><span class="meta">#</span><span class="bash"> 声明worker节点信息</span></span><br><span class="line">WorkerArray=(['k8s-m1']=172.16.80.201 ['k8s-m2']=172.16.80.202 ['k8s-m3']=172.16.80.203)</span><br><span class="line"><span class="meta">#</span><span class="bash"> </span></span><br><span class="line">VIP="172.16.80.200"</span><br><span class="line">KUBE_APISERVER="https://172.16.80.200:8443"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> etcd版本号</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubeadm-v1.11.5里面使用的是v3.2.18，这里直接上到最新的v3.3.10</span></span><br><span class="line">ETCD_VERSION="v3.3.10"</span><br><span class="line"><span class="meta">#</span><span class="bash"> kubernetes版本号</span></span><br><span class="line">KUBERNETES_VERSION="v1.11.5"</span><br><span class="line"><span class="meta">#</span><span class="bash"> cni-plugin版本号</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> kubernetes YUM源里用的还是v0.6.0版，这里上到最新的v0.7.4</span></span><br><span class="line">CNI_PLUGIN_VERSION="v0.7.4"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 声明VIP所在的网卡名称，以ens33为例</span></span><br><span class="line">VIP_IFACE="ens33"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 声明etcd_server</span></span><br><span class="line">ETCD_SERVERS=$( xargs -n1&lt;&lt;&lt;$&#123;MasterArray[@]&#125; | sort | sed 's#^#https://#;s#$#:2379#;$s#\n##' | paste -d, -s - )</span><br><span class="line">ETCD_INITIAL_CLUSTER=$( for i in $&#123;!MasterArray[@]&#125;;do  echo $i=https://$&#123;MasterArray[$i]&#125;:2380; done | sort | paste -d, -s - )</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 定义POD_CLUSTER_CIDR</span></span><br><span class="line">POD_NET_CIDR="10.244.0.0/16"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 定义SVC_CLUSTER_CIDR</span></span><br><span class="line">SVC_CLUSTER_CIDR="10.96.0.0/12"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 定义POD_DNS_SERVER_IP</span></span><br><span class="line">POD_DNS_SERVER_IP="10.96.0.10"</span><br></pre></td></tr></table></figure><h1 id="下载所需软件包"><a href="#下载所需软件包" class="headerlink" title="下载所需软件包"></a>下载所需软件包</h1><blockquote><ul><li>创建工作目录</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/software</span><br><span class="line">cd /root/software</span><br></pre></td></tr></table></figure><blockquote><ul><li>二进制文件需要分发到master和worker节点</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 下载kubernetes二进制包</span></span><br><span class="line">echo "--- 下载kubernetes $&#123;KUBERNETES_VERSION&#125; 二进制包 ---"</span><br><span class="line">wget https://dl.k8s.io/$&#123;KUBERNETES_VERSION&#125;/kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">tar xzf kubernetes-server-linux-amd64.tar.gz \</span><br><span class="line">        kubernetes/server/bin/hyperkube \</span><br><span class="line">        kubernetes/server/bin/kube-controller-manager \</span><br><span class="line">        kubernetes/server/bin/kubectl \</span><br><span class="line">        kubernetes/server/bin/apiextensions-apiserver \</span><br><span class="line">        kubernetes/server/bin/kube-proxy \</span><br><span class="line">        kubernetes/server/bin/kube-apiserver \</span><br><span class="line">        kubernetes/server/bin/kubelet \</span><br><span class="line">        kubernetes/server/bin/kubeadm \</span><br><span class="line">        kubernetes/server/bin/kube-aggregator \</span><br><span class="line">        kubernetes/server/bin/kube-scheduler \</span><br><span class="line">        kubernetes/server/bin/cloud-controller-manager \</span><br><span class="line">        kubernetes/server/bin/mounter</span><br><span class="line">chown -R root:root kubernetes/server/bin/*</span><br><span class="line">chmod 0755 kubernetes/server/bin/*</span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里需要先拷贝kubectl到/usr/<span class="built_in">local</span>/bin目录下，用于生成kubeconfig文件</span></span><br><span class="line">rsync -avpt kubernetes/server/bin/kubectl /usr/local/bin/kubectl</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 下载etcd二进制包</span></span><br><span class="line">echo "--- 下载etcd $&#123;ETCD_VERSION&#125; 二进制包 ---"</span><br><span class="line">wget https://github.com/etcd-io/etcd/releases/download/$&#123;ETCD_VERSION&#125;/etcd-$&#123;ETCD_VERSION&#125;-linux-amd64.tar.gz</span><br><span class="line">tar xzf etcd-$&#123;ETCD_VERSION&#125;-linux-amd64.tar.gz \</span><br><span class="line">        etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcdctl \</span><br><span class="line">        etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcd</span><br><span class="line">chown root:root etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcdctl etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcd</span><br><span class="line">chmod 0755 etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcdctl etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcd</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 下载CNI-plugin</span></span><br><span class="line">echo "--- 下载cni-plugins $&#123;CNI_PLUGIN_VERSION&#125; 二进制包 ---"</span><br><span class="line">wget https://github.com/containernetworking/plugins/releases/download/$&#123;CNI_PLUGIN_VERSION&#125;/cni-plugins-amd64-$&#123;CNI_PLUGIN_VERSION&#125;.tgz</span><br><span class="line">mkdir /root/software/cni-plugins</span><br><span class="line">tar xzf cni-plugins-amd64-$&#123;CNI_PLUGIN_VERSION&#125;.tgz -C /root/software/cni-plugins/</span><br></pre></td></tr></table></figure><h1 id="生成集群Key和Certificates"><a href="#生成集群Key和Certificates" class="headerlink" title="生成集群Key和Certificates"></a>生成集群Key和Certificates</h1><h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>本次部署，需要为<code>etcd-server</code>、<code>etcd-client</code>、<code>kube-apiserver</code>、<code>kube-controller-manager</code>、<code>kube-scheduler</code>、<code>kube-proxy</code>生成证书。另外还需要生成<code>sa</code>、<code>front-proxy-ca</code>、<code>front-proxy-client</code>证书用于集群的其他功能。</p><blockquote><ul><li>要注意CA JSON文件的<code>CN(Common Name)</code>与<code>O(Organization)</code>等内容是会影响Kubernetes组件认证的。<ul><li><code>CN</code> Common Name，kube-apiserver会从证书中提取该字段作为请求的用户名（User Name）</li><li><code>O</code> Oragnization，kube-apiserver会从证书中提取该字段作为请求用户的所属组（Group）</li></ul></li><li>CA是自签名根证书，用来给后续各种证书签名</li><li>kubernetes集群的所有状态信息都保存在etcd中，kubernetes组件会通过kube-apiserver读写etcd里面的信息</li><li>etcd如果暴露在公网且没做SSL/TLS验证，那么任何人都能读写数据，那么很可能会无端端在kubernetes集群里面多了挖坑Pod或者肉鸡Pod</li><li>本文使用<code>CFSSL</code>创建证书，证书有效期10年</li><li>建立证书过程在<font color="red" size="3">k8s-m1</font>上完成</li></ul></blockquote><h2 id="下载CFSSL工具"><a href="#下载CFSSL工具" class="headerlink" title="下载CFSSL工具"></a>下载CFSSL工具</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl-certinfo_linux-amd64 -O /usr/local/bin/cfssl-certinfo</span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssl_linux-amd64 -O /usr/local/bin/cfssl</span><br><span class="line">wget https://pkg.cfssl.org/R1.2/cfssljson_linux-amd64 -O /usr/local/bin/cfssljson</span><br><span class="line">chmod 755 /usr/local/bin/cfssl-certinfo \</span><br><span class="line">          /usr/local/bin/cfssl \</span><br><span class="line">          /usr/local/bin/cfssljson</span><br></pre></td></tr></table></figure><h2 id="创建工作目录"><a href="#创建工作目录" class="headerlink" title="创建工作目录"></a>创建工作目录</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/pki /root/master /root/worker</span><br><span class="line">cd /root/pki</span><br></pre></td></tr></table></figure><h2 id="创建用于生成证书的json文件"><a href="#创建用于生成证书的json文件" class="headerlink" title="创建用于生成证书的json文件"></a>创建用于生成证书的json文件</h2><h3 id="ca-config-json"><a href="#ca-config-json" class="headerlink" title="ca-config.json"></a>ca-config.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; ca-config.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "signing": &#123;</span><br><span class="line">    "default": &#123;</span><br><span class="line">      "expiry": "87600h"</span><br><span class="line">    &#125;,</span><br><span class="line">    "profiles": &#123;</span><br><span class="line">      "kubernetes": &#123;</span><br><span class="line">        "usages": [</span><br><span class="line">            "signing",</span><br><span class="line">            "key encipherment",</span><br><span class="line">            "server auth",</span><br><span class="line">            "client auth"</span><br><span class="line">        ],</span><br><span class="line">        "expiry": "87600h"</span><br><span class="line">      &#125;,</span><br><span class="line">      "etcd-server": &#123;</span><br><span class="line">        "usages": [</span><br><span class="line">            "signing",</span><br><span class="line">            "key encipherment",</span><br><span class="line">            "server auth",</span><br><span class="line">            "client auth"</span><br><span class="line">        ],</span><br><span class="line">        "expiry": "87600h"</span><br><span class="line">      &#125;,</span><br><span class="line">      "etcd-client": &#123;</span><br><span class="line">          "usages": [</span><br><span class="line">              "signing",</span><br><span class="line">              "key encipherment",</span><br><span class="line">              "client auth"</span><br><span class="line">          ],</span><br><span class="line">          "expiry": "87600h"</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="ca-csr-json"><a href="#ca-csr-json" class="headerlink" title="ca-csr.json"></a>ca-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; ca-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "kubernetes",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "Kubernetes",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="etcd-ca-csr-json"><a href="#etcd-ca-csr-json" class="headerlink" title="etcd-ca-csr.json"></a>etcd-ca-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd-ca-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "etcd",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "etcd",</span><br><span class="line">      "OU": "Etcd Security"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="etcd-server-csr-json"><a href="#etcd-server-csr-json" class="headerlink" title="etcd-server-csr.json"></a>etcd-server-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd-server-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "etcd-server",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "etcd",</span><br><span class="line">      "OU": "Etcd Security"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="etcd-client-csr-json"><a href="#etcd-client-csr-json" class="headerlink" title="etcd-client-csr.json"></a>etcd-client-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd-client-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "etcd-client",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "hosts": [</span><br><span class="line">    ""</span><br><span class="line">  ],</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "etcd",</span><br><span class="line">      "OU": "Etcd Security"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-apiserver-csr-json"><a href="#kube-apiserver-csr-json" class="headerlink" title="kube-apiserver-csr.json"></a>kube-apiserver-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-apiserver-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "kube-apiserver",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "Kubernetes",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-manager-csr-json"><a href="#kube-manager-csr-json" class="headerlink" title="kube-manager-csr.json"></a>kube-manager-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-manager-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "system:kube-controller-manager",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "system:kube-controller-manager",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-scheduler-csr-json"><a href="#kube-scheduler-csr-json" class="headerlink" title="kube-scheduler-csr.json"></a>kube-scheduler-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-scheduler-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "system:kube-scheduler",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "system:kube-scheduler",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-proxy-csr-json"><a href="#kube-proxy-csr-json" class="headerlink" title="kube-proxy-csr.json"></a>kube-proxy-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-proxy-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "system:kube-proxy",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "system:kube-proxy",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-admin-csr-json"><a href="#kube-admin-csr-json" class="headerlink" title="kube-admin-csr.json"></a>kube-admin-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-admin-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "admin",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "system:masters",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="front-proxy-ca-csr-json"><a href="#front-proxy-ca-csr-json" class="headerlink" title="front-proxy-ca-csr.json"></a>front-proxy-ca-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; front-proxy-ca-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "kubernetes",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="front-proxy-client-csr-json"><a href="#front-proxy-client-csr-json" class="headerlink" title="front-proxy-client-csr.json"></a>front-proxy-client-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; front-proxy-client-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "front-proxy-client",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="sa-csr-json"><a href="#sa-csr-json" class="headerlink" title="sa-csr.json"></a>sa-csr.json</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; sa-csr.json &lt;&lt;EOF</span><br><span class="line">&#123;</span><br><span class="line">  "CN": "service-accounts",</span><br><span class="line">  "key": &#123;</span><br><span class="line">    "algo": "rsa",</span><br><span class="line">    "size": 2048</span><br><span class="line">  &#125;,</span><br><span class="line">  "names": [</span><br><span class="line">    &#123;</span><br><span class="line">      "C": "CN",</span><br><span class="line">      "ST": "Guangdong",</span><br><span class="line">      "L": "Guangzhou",</span><br><span class="line">      "O": "Kubernetes",</span><br><span class="line">      "OU": "System"</span><br><span class="line">    &#125;</span><br><span class="line">  ]</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="创建etcd证书"><a href="#创建etcd证书" class="headerlink" title="创建etcd证书"></a>创建etcd证书</h2><h3 id="etcd-ca证书"><a href="#etcd-ca证书" class="headerlink" title="etcd-ca证书"></a>etcd-ca证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建etcd-ca证书 ---'</span><br><span class="line">cfssl gencert -initca etcd-ca-csr.json | cfssljson -bare etcd-ca</span><br></pre></td></tr></table></figure><h3 id="etcd-server证书"><a href="#etcd-server证书" class="headerlink" title="etcd-server证书"></a>etcd-server证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建etcd-server证书 ---'</span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=etcd-ca.pem \</span><br><span class="line">      -ca-key=etcd-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -hostname=127.0.0.1,$(xargs -n1&lt;&lt;&lt;$&#123;MasterArray[@]&#125; | sort  | paste -d, -s -) \</span><br><span class="line">      -profile=etcd-server etcd-server-csr.json | cfssljson -bare etcd-server</span><br></pre></td></tr></table></figure><h3 id="etcd-client证书"><a href="#etcd-client证书" class="headerlink" title="etcd-client证书"></a>etcd-client证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建etcd-client证书 ---'</span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=etcd-ca.pem \</span><br><span class="line">      -ca-key=etcd-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=etcd-client etcd-client-csr.json | cfssljson -bare etcd-client</span><br></pre></td></tr></table></figure><h2 id="创建kubernetes证书"><a href="#创建kubernetes证书" class="headerlink" title="创建kubernetes证书"></a>创建kubernetes证书</h2><h3 id="kubernetes-CA-证书"><a href="#kubernetes-CA-证书" class="headerlink" title="kubernetes-CA 证书"></a>kubernetes-CA 证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建kubernetes-ca证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建kubernetes-ca证书</span></span><br><span class="line">cfssl gencert -initca ca-csr.json | cfssljson -bare kube-ca</span><br></pre></td></tr></table></figure><h3 id="kube-apiserver证书"><a href="#kube-apiserver证书" class="headerlink" title="kube-apiserver证书"></a>kube-apiserver证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建kube-apiserver证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建kube-apiserver证书</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里的hostname字段中的10.96.0.1要跟上文提到的service cluster ip cidr对应</span></span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=kube-ca.pem \</span><br><span class="line">      -ca-key=kube-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -hostname=10.96.0.1,127.0.0.1,localhost,kubernetes,kubernetes.default,kubernetes.default.svc,kubernetes.default.svc.cluster,kubernetes.default.svc.cluster.local,$&#123;VIP&#125;,$(xargs -n1&lt;&lt;&lt;$&#123;MasterArray[@]&#125; | sort  | paste -d, -s -) \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      kube-apiserver-csr.json | cfssljson -bare kube-apiserver</span><br></pre></td></tr></table></figure><h3 id="kube-controller-manager证书"><a href="#kube-controller-manager证书" class="headerlink" title="kube-controller-manager证书"></a>kube-controller-manager证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建kube-controller-manager证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建kube-controller-manager证书</span></span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=kube-ca.pem \</span><br><span class="line">      -ca-key=kube-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      kube-manager-csr.json | cfssljson -bare kube-controller-manager</span><br></pre></td></tr></table></figure><h3 id="kube-scheduler证书"><a href="#kube-scheduler证书" class="headerlink" title="kube-scheduler证书"></a>kube-scheduler证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建kube-scheduler证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建kube-scheduler证书</span></span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=kube-ca.pem \</span><br><span class="line">      -ca-key=kube-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      kube-scheduler-csr.json | cfssljson -bare kube-scheduler</span><br></pre></td></tr></table></figure><h3 id="kube-proxy证书"><a href="#kube-proxy证书" class="headerlink" title="kube-proxy证书"></a>kube-proxy证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建kube-proxy证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建kube-proxy证书</span></span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=kube-ca.pem \</span><br><span class="line">      -ca-key=kube-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      kube-proxy-csr.json | cfssljson -bare kube-proxy</span><br></pre></td></tr></table></figure><h3 id="kube-admin证书"><a href="#kube-admin证书" class="headerlink" title="kube-admin证书"></a>kube-admin证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建kube-admin证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建kube-admin证书</span></span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=kube-ca.pem \</span><br><span class="line">      -ca-key=kube-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      kube-admin-csr.json | cfssljson -bare kube-admin</span><br></pre></td></tr></table></figure><h3 id="Front-Proxy证书"><a href="#Front-Proxy证书" class="headerlink" title="Front Proxy证书"></a>Front Proxy证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建Front Proxy Certificate证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建Front Proxy Certificate证书</span></span><br><span class="line">cfssl gencert -initca front-proxy-ca-csr.json | cfssljson -bare front-proxy-ca</span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=front-proxy-ca.pem \</span><br><span class="line">      -ca-key=front-proxy-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      front-proxy-client-csr.json | cfssljson -bare front-proxy-client</span><br></pre></td></tr></table></figure><h3 id="Service-Account证书"><a href="#Service-Account证书" class="headerlink" title="Service Account证书"></a>Service Account证书</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建service account证书 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建创建service account证书</span></span><br><span class="line">cfssl gencert \</span><br><span class="line">      -ca=kube-ca.pem \</span><br><span class="line">      -ca-key=kube-ca-key.pem \</span><br><span class="line">      -config=ca-config.json \</span><br><span class="line">      -profile=kubernetes \</span><br><span class="line">      sa-csr.json | cfssljson -bare sa</span><br></pre></td></tr></table></figure><h3 id="bootstrap-token"><a href="#bootstrap-token" class="headerlink" title="bootstrap-token"></a>bootstrap-token</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">BOOTSTRAP_TOKEN=$(dd if=/dev/urandom bs=128 count=1 2&gt;/dev/null | base64 | tr -d "=+/[:space:]" | dd bs=32 count=1 2&gt;/dev/null)</span><br><span class="line">echo "BOOTSTRAP_TOKEN: $&#123;BOOTSTRAP_TOKEN&#125;"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建token.csv文件</span></span><br><span class="line">cat &gt; token.csv &lt;&lt;EOF</span><br><span class="line"><span class="meta">$</span><span class="bash">&#123;BOOTSTRAP_TOKEN&#125;,kubelet-bootstrap,10001,<span class="string">"system:bootstrappers"</span></span></span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="encryption-yaml"><a href="#encryption-yaml" class="headerlink" title="encryption.yaml"></a>encryption.yaml</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">ENCRYPTION_TOKEN=$(head -c 32 /dev/urandom | base64)</span><br><span class="line">echo "ENCRYPTION_TOKEN: $&#123;ENCRYPTION_TOKEN&#125;"</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建encryption.yaml文件</span></span><br><span class="line">cat &gt; encryption.yaml &lt;&lt;EOF</span><br><span class="line">kind: EncryptionConfig</span><br><span class="line">apiVersion: v1</span><br><span class="line">resources:</span><br><span class="line">  - resources:</span><br><span class="line">      - secrets</span><br><span class="line">    providers:</span><br><span class="line">      - aescbc:</span><br><span class="line">          keys:</span><br><span class="line">            - name: key1</span><br><span class="line">              secret: $&#123;ENCRYPTION_TOKEN&#125;</span><br><span class="line">      - identity: &#123;&#125;</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="audit-policy-yaml"><a href="#audit-policy-yaml" class="headerlink" title="audit-policy.yaml"></a>audit-policy.yaml</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 创建创建高级审计配置 ---'</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建高级审计配置</span></span><br><span class="line">cat &gt;&gt; audit-policy.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: audit.k8s.io/v1beta1</span><br><span class="line">kind: Policy</span><br><span class="line">rules:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> The following requests were manually identified as high-volume and low-risk,</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> so drop them.</span></span><br><span class="line">  - level: None</span><br><span class="line">    users: ["system:kube-proxy"]</span><br><span class="line">    verbs: ["watch"]</span><br><span class="line">    resources:</span><br><span class="line">      - group: "" # core</span><br><span class="line">        resources: ["endpoints", "services", "services/status"]</span><br><span class="line">  - level: None</span><br><span class="line">    # Ingress controller reads 'configmaps/ingress-uid' through the unsecured port.</span><br><span class="line">    # TODO(#46983): Change this to the ingress controller service account.</span><br><span class="line">    users: ["system:unsecured"]</span><br><span class="line">    namespaces: ["kube-system"]</span><br><span class="line">    verbs: ["get"]</span><br><span class="line">    resources:</span><br><span class="line">      - group: "" # core</span><br><span class="line">        resources: ["configmaps"]</span><br><span class="line">  - level: None</span><br><span class="line">    users: ["kubelet"] # legacy kubelet identity</span><br><span class="line">    verbs: ["get"]</span><br><span class="line">    resources:</span><br><span class="line">      - group: "" # core</span><br><span class="line">        resources: ["nodes", "nodes/status"]</span><br><span class="line">  - level: None</span><br><span class="line">    userGroups: ["system:nodes"]</span><br><span class="line">    verbs: ["get"]</span><br><span class="line">    resources:</span><br><span class="line">      - group: "" # core</span><br><span class="line">        resources: ["nodes", "nodes/status"]</span><br><span class="line">  - level: None</span><br><span class="line">    users:</span><br><span class="line">      - system:kube-controller-manager</span><br><span class="line">      - system:kube-scheduler</span><br><span class="line">      - system:serviceaccount:kube-system:endpoint-controller</span><br><span class="line">    verbs: ["get", "update"]</span><br><span class="line">    namespaces: ["kube-system"]</span><br><span class="line">    resources:</span><br><span class="line">      - group: "" # core</span><br><span class="line">        resources: ["endpoints"]</span><br><span class="line">  - level: None</span><br><span class="line">    users: ["system:apiserver"]</span><br><span class="line">    verbs: ["get"]</span><br><span class="line">    resources:</span><br><span class="line">      - group: "" # core</span><br><span class="line">        resources: ["namespaces", "namespaces/status", "namespaces/finalize"]</span><br><span class="line">  - level: None</span><br><span class="line">    users: ["cluster-autoscaler"]</span><br><span class="line">    verbs: ["get", "update"]</span><br><span class="line">    namespaces: ["kube-system"]</span><br><span class="line">    resources:</span><br><span class="line">      - group: "" # core</span><br><span class="line">        resources: ["configmaps", "endpoints"]</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Don<span class="string">'t log HPA fetching metrics.</span></span></span><br><span class="line">  - level: None</span><br><span class="line">    users:</span><br><span class="line">      - system:kube-controller-manager</span><br><span class="line">    verbs: ["get", "list"]</span><br><span class="line">    resources:</span><br><span class="line">      - group: "metrics.k8s.io"</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Don<span class="string">'t log these read-only URLs.</span></span></span><br><span class="line">  - level: None</span><br><span class="line">    nonResourceURLs:</span><br><span class="line">      - /healthz*</span><br><span class="line">      - /version</span><br><span class="line">      - /swagger*</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Don<span class="string">'t log events requests.</span></span></span><br><span class="line">  - level: None</span><br><span class="line">    resources:</span><br><span class="line">      - group: "" # core</span><br><span class="line">        resources: ["events"]</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> node and pod status calls from nodes are high-volume and can be large, don<span class="string">'t log responses for expected updates from nodes</span></span></span><br><span class="line">  - level: Request</span><br><span class="line">    users: ["kubelet", "system:node-problem-detector", "system:serviceaccount:kube-system:node-problem-detector"]</span><br><span class="line">    verbs: ["update","patch"]</span><br><span class="line">    resources:</span><br><span class="line">      - group: "" # core</span><br><span class="line">        resources: ["nodes/status", "pods/status"]</span><br><span class="line">    omitStages:</span><br><span class="line">      - "RequestReceived"</span><br><span class="line">  - level: Request</span><br><span class="line">    userGroups: ["system:nodes"]</span><br><span class="line">    verbs: ["update","patch"]</span><br><span class="line">    resources:</span><br><span class="line">      - group: "" # core</span><br><span class="line">        resources: ["nodes/status", "pods/status"]</span><br><span class="line">    omitStages:</span><br><span class="line">      - "RequestReceived"</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> deletecollection calls can be large, don<span class="string">'t log responses for expected namespace deletions</span></span></span><br><span class="line">  - level: Request</span><br><span class="line">    users: ["system:serviceaccount:kube-system:namespace-controller"]</span><br><span class="line">    verbs: ["deletecollection"]</span><br><span class="line">    omitStages:</span><br><span class="line">      - "RequestReceived"</span><br><span class="line"></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Secrets, ConfigMaps, and TokenReviews can contain sensitive &amp; binary data,</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> so only <span class="built_in">log</span> at the Metadata level.</span></span><br><span class="line">  - level: Metadata</span><br><span class="line">    resources:</span><br><span class="line">      - group: "" # core</span><br><span class="line">        resources: ["secrets", "configmaps"]</span><br><span class="line">      - group: authentication.k8s.io</span><br><span class="line">        resources: ["tokenreviews"]</span><br><span class="line">    omitStages:</span><br><span class="line">      - "RequestReceived"</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Get repsonses can be large; skip them.</span></span><br><span class="line">  - level: Request</span><br><span class="line">    verbs: ["get", "list", "watch"]</span><br><span class="line">    resources: </span><br><span class="line">      - group: "" # core</span><br><span class="line">      - group: "admissionregistration.k8s.io"</span><br><span class="line">      - group: "apiextensions.k8s.io"</span><br><span class="line">      - group: "apiregistration.k8s.io"</span><br><span class="line">      - group: "apps"</span><br><span class="line">      - group: "authentication.k8s.io"</span><br><span class="line">      - group: "authorization.k8s.io"</span><br><span class="line">      - group: "autoscaling"</span><br><span class="line">      - group: "batch"</span><br><span class="line">      - group: "certificates.k8s.io"</span><br><span class="line">      - group: "extensions"</span><br><span class="line">      - group: "metrics.k8s.io"</span><br><span class="line">      - group: "networking.k8s.io"</span><br><span class="line">      - group: "policy"</span><br><span class="line">      - group: "rbac.authorization.k8s.io"</span><br><span class="line">      - group: "scheduling.k8s.io"</span><br><span class="line">      - group: "settings.k8s.io"</span><br><span class="line">      - group: "storage.k8s.io"</span><br><span class="line">    omitStages:</span><br><span class="line">      - "RequestReceived"</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Default level <span class="keyword">for</span> known APIs</span></span><br><span class="line">  - level: RequestResponse</span><br><span class="line">    resources: </span><br><span class="line">      - group: "" # core</span><br><span class="line">      - group: "admissionregistration.k8s.io"</span><br><span class="line">      - group: "apiextensions.k8s.io"</span><br><span class="line">      - group: "apiregistration.k8s.io"</span><br><span class="line">      - group: "apps"</span><br><span class="line">      - group: "authentication.k8s.io"</span><br><span class="line">      - group: "authorization.k8s.io"</span><br><span class="line">      - group: "autoscaling"</span><br><span class="line">      - group: "batch"</span><br><span class="line">      - group: "certificates.k8s.io"</span><br><span class="line">      - group: "extensions"</span><br><span class="line">      - group: "metrics.k8s.io"</span><br><span class="line">      - group: "networking.k8s.io"</span><br><span class="line">      - group: "policy"</span><br><span class="line">      - group: "rbac.authorization.k8s.io"</span><br><span class="line">      - group: "scheduling.k8s.io"</span><br><span class="line">      - group: "settings.k8s.io"</span><br><span class="line">      - group: "storage.k8s.io"</span><br><span class="line">    omitStages:</span><br><span class="line">      - "RequestReceived"</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Default level <span class="keyword">for</span> all other requests.</span></span><br><span class="line">  - level: Metadata</span><br><span class="line">    omitStages:</span><br><span class="line">      - "RequestReceived"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="创建kubeconfig文件"><a href="#创建kubeconfig文件" class="headerlink" title="创建kubeconfig文件"></a>创建kubeconfig文件</h2><h3 id="说明-1"><a href="#说明-1" class="headerlink" title="说明"></a>说明</h3><blockquote><ul><li>kubeconfig 文件用于组织关于集群、用户、命名空间和认证机制的信息。</li><li>命令行工具 <code>kubectl</code> 从 kubeconfig 文件中得到它要选择的集群以及跟集群 API server 交互的信息。</li><li>默认情况下，<code>kubectl</code> 会从 <code>$HOME/.kube</code> 目录下查找文件名为 <code>config</code> 的文件。</li></ul></blockquote><blockquote><p><strong>注意：</strong> 用于配置集群访问信息的文件叫作 <code>kubeconfig文件</code>，这是一种引用配置文件的通用方式，并不是说它的文件名就是 <code>kubeconfig</code>。</p></blockquote><h3 id="kube-controller-manager-kubeconfig"><a href="#kube-controller-manager-kubeconfig" class="headerlink" title="kube-controller-manager.kubeconfig"></a>kube-controller-manager.kubeconfig</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">echo "Create kube-controller-manager kubeconfig..."</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=kube-ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-controller-manager.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials system:kube-controller-manager \</span><br><span class="line">  --client-certificate=kube-controller-manager.pem \</span><br><span class="line">  --client-key=kube-controller-manager-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-controller-manager.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=system:kube-controller-manager \</span><br><span class="line">  --kubeconfig=kube-controller-manager.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line">kubectl config use-context default --kubeconfig=kube-controller-manager.kubeconfig</span><br></pre></td></tr></table></figure><h3 id="kube-scheduler-kubeconfig"><a href="#kube-scheduler-kubeconfig" class="headerlink" title="kube-scheduler.kubeconfig"></a>kube-scheduler.kubeconfig</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">echo "Create kube-scheduler kubeconfig..."</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=kube-ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-scheduler.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials system:kube-scheduler \</span><br><span class="line">  --client-certificate=kube-scheduler.pem \</span><br><span class="line">  --client-key=kube-scheduler-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-scheduler.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=system:kube-scheduler \</span><br><span class="line">  --kubeconfig=kube-scheduler.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line">kubectl config use-context default --kubeconfig=kube-scheduler.kubeconfig</span><br></pre></td></tr></table></figure><h3 id="kube-proxy-kubeconfig"><a href="#kube-proxy-kubeconfig" class="headerlink" title="kube-proxy.kubeconfig"></a>kube-proxy.kubeconfig</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">echo "Create kube-proxy kubeconfig..."</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=kube-ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials system:kube-proxy \</span><br><span class="line">  --client-certificate=kube-proxy.pem \</span><br><span class="line">  --client-key=kube-proxy-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=system:kube-proxy \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line">kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure><h3 id="kube-admin-kubeconfig"><a href="#kube-admin-kubeconfig" class="headerlink" title="kube-admin.kubeconfig"></a>kube-admin.kubeconfig</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">echo "Create kube-admin kubeconfig..."</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=kube-ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-admin.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials kubernetes-admin \</span><br><span class="line">  --client-certificate=kube-admin.pem \</span><br><span class="line">  --client-key=kube-admin-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-admin.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kubernetes-admin \</span><br><span class="line">  --kubeconfig=kube-admin.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line">kubectl config use-context default --kubeconfig=kube-admin.kubeconfig</span><br></pre></td></tr></table></figure><h3 id="bootstrap-kubeconfig"><a href="#bootstrap-kubeconfig" class="headerlink" title="bootstrap.kubeconfig"></a>bootstrap.kubeconfig</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">echo "Create kubelet bootstrapping kubeconfig..."</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置集群参数</span></span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=kube-ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置客户端认证参数</span></span><br><span class="line">kubectl config set-credentials kubelet-bootstrap \</span><br><span class="line">  --token=$&#123;BOOTSTRAP_TOKEN&#125; \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置上下文参数</span></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kubelet-bootstrap \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置默认上下文</span></span><br><span class="line">kubectl config use-context default --kubeconfig=bootstrap.kubeconfig</span><br></pre></td></tr></table></figure><h3 id="清理证书CSR文件"><a href="#清理证书CSR文件" class="headerlink" title="清理证书CSR文件"></a>清理证书CSR文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 删除*.csr文件 ---'</span><br><span class="line">rm -rf *csr</span><br></pre></td></tr></table></figure><h2 id="修改文件权限"><a href="#修改文件权限" class="headerlink" title="修改文件权限"></a>修改文件权限</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">chown root:root *pem *kubeconfig *yaml *csv</span><br><span class="line">chmod 0444 *pem *kubeconfig *yaml *csv</span><br><span class="line">chmod 0400 *key.pem</span><br></pre></td></tr></table></figure><h2 id="检查生成的文件"><a href="#检查生成的文件" class="headerlink" title="检查生成的文件"></a>检查生成的文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">ls -l | grep -v json</span><br><span class="line">-r--r--r-- 1 root root  113 Dec  6 15:36 audit-policy.yaml</span><br><span class="line">-r--r--r-- 1 root root 2207 Dec  6 15:36 bootstrap.kubeconfig</span><br><span class="line">-r--r--r-- 1 root root  240 Dec  6 15:36 encryption.yaml</span><br><span class="line">-r-------- 1 root root 1675 Dec  6 15:36 etcd-ca-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1375 Dec  6 15:36 etcd-ca.pem</span><br><span class="line">-r-------- 1 root root 1679 Dec  6 15:36 etcd-client-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1424 Dec  6 15:36 etcd-client.pem</span><br><span class="line">-r-------- 1 root root 1679 Dec  6 15:36 etcd-server-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1468 Dec  6 15:36 etcd-server.pem</span><br><span class="line">-r-------- 1 root root 1679 Dec  6 15:36 front-proxy-ca-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1143 Dec  6 15:36 front-proxy-ca.pem</span><br><span class="line">-r-------- 1 root root 1675 Dec  6 15:36 front-proxy-client-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1188 Dec  6 15:36 front-proxy-client.pem</span><br><span class="line">-r-------- 1 root root 1679 Dec  6 15:36 kube-admin-key.pem</span><br><span class="line">-r--r--r-- 1 root root 6345 Dec  6 15:36 kube-admin.kubeconfig</span><br><span class="line">-r--r--r-- 1 root root 1419 Dec  6 15:36 kube-admin.pem</span><br><span class="line">-r-------- 1 root root 1675 Dec  6 15:36 kube-apiserver-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1688 Dec  6 15:36 kube-apiserver.pem</span><br><span class="line">-r-------- 1 root root 1679 Dec  6 15:36 kube-ca-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1387 Dec  6 15:36 kube-ca.pem</span><br><span class="line">-r-------- 1 root root 1679 Dec  6 15:36 kube-controller-manager-key.pem</span><br><span class="line">-r--r--r-- 1 root root 6449 Dec  6 15:36 kube-controller-manager.kubeconfig</span><br><span class="line">-r--r--r-- 1 root root 1476 Dec  6 15:36 kube-controller-manager.pem</span><br><span class="line">-r-------- 1 root root 1675 Dec  6 15:36 kube-proxy-key.pem</span><br><span class="line">-r--r--r-- 1 root root 6371 Dec  6 15:36 kube-proxy.kubeconfig</span><br><span class="line">-r--r--r-- 1 root root 1440 Dec  6 15:36 kube-proxy.pem</span><br><span class="line">-r-------- 1 root root 1675 Dec  6 15:36 kube-scheduler-key.pem</span><br><span class="line">-r--r--r-- 1 root root 6395 Dec  6 15:36 kube-scheduler.kubeconfig</span><br><span class="line">-r--r--r-- 1 root root 1452 Dec  6 15:36 kube-scheduler.pem</span><br><span class="line">-r-------- 1 root root 1675 Dec  6 15:36 sa-key.pem</span><br><span class="line">-r--r--r-- 1 root root 1432 Dec  6 15:36 sa.pem</span><br><span class="line">-r--r--r-- 1 root root   80 Dec  6 15:36 token.csv</span><br></pre></td></tr></table></figure><h1 id="kubernetes-master节点"><a href="#kubernetes-master节点" class="headerlink" title="kubernetes-master节点"></a>kubernetes-master节点</h1><p>本节介绍如何部署kubernetes master节点</p><h2 id="master节点说明"><a href="#master节点说明" class="headerlink" title="master节点说明"></a><strong>master节点说明</strong></h2><blockquote><ul><li>原则上，master节点不应该运行业务Pod，且不应该暴露到公网环境！！</li><li>边界节点，应该交由<code>worker</code>节点或者运行<code>Ingress</code>的节点来承担</li><li>以<code>kubeadm</code>部署为例，部署完成后，会给master节点添加<code>node-role.kubernetes.io/master=&#39;&#39;</code>标签（Labels）并且会对带有此标签的节点添加<code>node-role.kubernetes.io/master:NoSchedule</code>污点（taints），这样不能容忍此污点的Pod无法调度到master节点</li><li>本文中，在kubelet启动参数里，默认添加<code>node-role.kubernetes.io/node=&#39;&#39;</code>标签（Labels），且没有对master节点添加<code>node-role.kubernetes.io/master:NoSchedule</code>污点（taints）</li><li>生产环境中最好参照kubeadm，对master节点添加<code>node-role.kubernetes.io/master=&#39;&#39;</code>标签（Labels）和<code>node-role.kubernetes.io/master:NoSchedule</code>污点（taints）</li></ul></blockquote><p><strong>kube-apiserver</strong></p><blockquote><ul><li>以 REST APIs 提供 Kubernetes 资源的 CRUD,如授权、认证、存取控制与 API 注册等机制。</li><li>关闭默认非安全端口8080,在安全端口 6443 接收 https 请求</li><li>严格的认证和授权策略 (x509、token、RBAC)</li><li>开启 bootstrap token 认证，支持 kubelet TLS bootstrapping</li><li>使用 https 访问 kubelet、etcd，加密通信</li></ul></blockquote><p><strong>kube-controller-manager</strong></p><blockquote><ul><li>通过核心控制循环(Core Control Loop)监听 Kubernetes API<br>的资源来维护集群的状态，这些资源会被不同的控制器所管理，如 Replication Controller、Namespace<br>Controller 等等。而这些控制器会处理着自动扩展、滚动更新等等功能。</li><li>关闭非安全端口，在安全端口 10252 接收 https 请求</li><li>使用 kubeconfig 访问 kube-apiserver 的安全端口</li></ul></blockquote><p><strong>kube-scheduler</strong></p><blockquote><ul><li>负责将一个(或多个)容器依据调度策略分配到对应节点上让容器引擎(如 Docker)执行。</li><li>调度受到 QoS 要求、软硬性约束、亲和性(Affinity)等等因素影响。</li></ul></blockquote><p><strong>HAProxy</strong></p><blockquote><ul><li>提供多个 API Server 的负载均衡(Load Balance)</li><li>监听VIP的<code>8443</code>端口负载均衡到三台master节点的<code>6443</code>端口</li></ul></blockquote><p><strong>Keepalived</strong></p><blockquote><ul><li>提供虚拟IP位址(VIP),来让vip落在可用的master主机上供所有组件访问master节点</li><li>提供健康检查脚本用于切换VIP</li></ul></blockquote><h2 id="添加用户"><a href="#添加用户" class="headerlink" title="添加用户"></a>添加用户</h2><blockquote><ul><li>这里强迫症发作，指定了<code>UID</code>和<code>GID</code></li><li>不指定<code>UID</code>和<code>GID</code>也可以</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">echo '--- master节点添加用户 ---'</span><br><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    ssh $&#123;NODE&#125; /usr/sbin/groupadd -r -g 10000 kube</span><br><span class="line">    ssh $&#123;NODE&#125; /usr/sbin/groupadd -r -g 10001 etcd</span><br><span class="line">    ssh $&#123;NODE&#125; /usr/sbin/useradd -r -g kube -u 10000 -s /bin/false kube</span><br><span class="line">    ssh $&#123;NODE&#125; /usr/sbin/useradd -r -g etcd -u 10001 -s /bin/false etcd</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="创建目录"><a href="#创建目录" class="headerlink" title="创建目录"></a>创建目录</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">echo '--- master节点创建目录 ---'</span><br><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    echo "--- 创建目录 ---"</span><br><span class="line">    ssh $&#123;NODE&#125; /usr/bin/mkdir -p /etc/etcd/ssl \</span><br><span class="line">                                  /etc/kubernetes/pki \</span><br><span class="line">                                  /etc/kubernetes/manifests \</span><br><span class="line">                                  /var/lib/etcd \</span><br><span class="line">                                  /var/lib/kubelet \</span><br><span class="line">                                  /var/run/kubernetes \</span><br><span class="line">                                  /var/log/kube-audit \</span><br><span class="line">                                  /etc/cni/net.d \</span><br><span class="line">                                  /opt/cni/bin </span><br><span class="line">    echo "--- 修改目录权限 ---"</span><br><span class="line">    ssh $&#123;NODE&#125; /usr/bin/chmod 0755 /etc/etcd \</span><br><span class="line">                                    /etc/etcd/ssl \</span><br><span class="line">                                    /etc/kubernetes \</span><br><span class="line">                                    /etc/kubernetes/pki \</span><br><span class="line">                                    /var/lib/etcd \</span><br><span class="line">                                    /var/lib/kubelet \</span><br><span class="line">                                    /var/log/kube-audit \</span><br><span class="line">                                    /var/run/kubernetes \</span><br><span class="line">                                    /etc/cni/net.d \</span><br><span class="line">                                    /opt/cni/bin </span><br><span class="line">    echo "--- 修改目录属组 ---"</span><br><span class="line">    ssh $&#123;NODE&#125; chown -R etcd:etcd /etc/etcd/ /var/lib/etcd</span><br><span class="line">    ssh $&#123;NODE&#125; chown -R kube:kube /etc/kubernetes \</span><br><span class="line">                                   /var/lib/kubelet \</span><br><span class="line">                                   /var/log/kube-audit \</span><br><span class="line">                                   /var/run/kubernetes</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="分发证书文件和kubeconfig到master节点"><a href="#分发证书文件和kubeconfig到master节点" class="headerlink" title="分发证书文件和kubeconfig到master节点"></a>分发证书文件和kubeconfig到master节点</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "---- $NODE ----"</span><br><span class="line">    echo '---- 分发etcd证书 ----'</span><br><span class="line">    rsync -avpt /root/pki/etcd-ca-key.pem \</span><br><span class="line">                /root/pki/etcd-ca.pem \</span><br><span class="line">                /root/pki/etcd-client-key.pem \</span><br><span class="line">                /root/pki/etcd-client.pem \</span><br><span class="line">                /root/pki/etcd-server-key.pem \</span><br><span class="line">                /root/pki/etcd-server.pem \</span><br><span class="line">                $NODE:/etc/etcd/ssl/</span><br><span class="line">    echo '---- 分发kubeconfig文件 yaml文件 token.csv ----'</span><br><span class="line">    rsync -avpt /root/pki/kube-admin.kubeconfig \</span><br><span class="line">                /root/pki/kube-controller-manager.kubeconfig \</span><br><span class="line">                /root/pki/kube-scheduler.kubeconfig \</span><br><span class="line">                /root/pki/audit-policy.yaml \</span><br><span class="line">                /root/pki/encryption.yaml \</span><br><span class="line">                /root/pki/token.csv \</span><br><span class="line">                $NODE:/etc/kubernetes/</span><br><span class="line">    echo '---- 分发sa证书 kube证书 front-proxy证书 ----'</span><br><span class="line">    rsync -avpt /root/pki/etcd-ca.pem \</span><br><span class="line">                /root/pki/etcd-client-key.pem \</span><br><span class="line">                /root/pki/etcd-client.pem \</span><br><span class="line">                /root/pki/front-proxy-ca.pem \</span><br><span class="line">                /root/pki/front-proxy-client-key.pem \</span><br><span class="line">                /root/pki/front-proxy-client.pem \</span><br><span class="line">                /root/pki/kube-apiserver-key.pem \</span><br><span class="line">                /root/pki/kube-apiserver.pem \</span><br><span class="line">                /root/pki/kube-ca.pem \</span><br><span class="line">                /root/pki/kube-ca-key.pem \</span><br><span class="line">                /root/pki/sa-key.pem \</span><br><span class="line">                /root/pki/sa.pem \</span><br><span class="line">                $NODE:/etc/kubernetes/pki/</span><br><span class="line">    ssh $NODE chown -R etcd:etcd /etc/etcd</span><br><span class="line">    ssh $NODE chown -R kube:kube /etc/kubernetes</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="分发二进制文件"><a href="#分发二进制文件" class="headerlink" title="分发二进制文件"></a>分发二进制文件</h2><blockquote><ul><li>在<font color="red" size="3">k8s-m1</font>上操作</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 分发kubernetes和etcd二进制文件 ---'</span><br><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    rsync -avpt /root/software/kubernetes/server/bin/hyperkube \</span><br><span class="line">                /root/software/kubernetes/server/bin/kube-controller-manager \</span><br><span class="line">                /root/software/kubernetes/server/bin/kubectl \</span><br><span class="line">                /root/software/kubernetes/server/bin/apiextensions-apiserver \</span><br><span class="line">                /root/software/kubernetes/server/bin/kube-apiserver \</span><br><span class="line">                /root/software/kubernetes/server/bin/kubeadm \</span><br><span class="line">                /root/software/kubernetes/server/bin/kube-aggregator \</span><br><span class="line">                /root/software/kubernetes/server/bin/kube-scheduler \</span><br><span class="line">                /root/software/kubernetes/server/bin/cloud-controller-manager \</span><br><span class="line">                /root/software/kubernetes/server/bin/mounter \</span><br><span class="line">                /root/software/etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcdctl \</span><br><span class="line">                /root/software/etcd-$&#123;ETCD_VERSION&#125;-linux-amd64/etcd \</span><br><span class="line">                $NODE:/usr/local/bin/</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="部署配置Keepalived和HAProxy"><a href="#部署配置Keepalived和HAProxy" class="headerlink" title="部署配置Keepalived和HAProxy"></a>部署配置Keepalived和HAProxy</h2><blockquote><ul><li>在<font color="red" size="3">k8s-m1</font>上操作</li></ul></blockquote><h3 id="切换工作目录"><a href="#切换工作目录" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/master</span><br></pre></td></tr></table></figure><h3 id="安装Keepalived和HAProxy"><a href="#安装Keepalived和HAProxy" class="headerlink" title="安装Keepalived和HAProxy"></a>安装Keepalived和HAProxy</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "---- $NODE ----"</span><br><span class="line">    echo "---- 安装haproxy和keepalived ----"</span><br><span class="line">    ssh $NODE yum install keepalived haproxy -y</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="配置keepalived"><a href="#配置keepalived" class="headerlink" title="配置keepalived"></a>配置keepalived</h3><blockquote><ul><li>编辑<code>keepalived.conf</code>模板</li><li>替换<code>keepalived.conf</code>的字符串</li><li>编辑<code>check_haproxy.sh</code></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; keepalived.conf.example &lt;&lt;EOF</span><br><span class="line">vrrp_script haproxy-check &#123;</span><br><span class="line">    script "/bin/bash /etc/keepalived/check_haproxy.sh"</span><br><span class="line">    interval 3</span><br><span class="line">    weight -2</span><br><span class="line">    fall 10</span><br><span class="line">    rise 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance haproxy-vip &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    priority 101</span><br><span class="line">    interface &#123;&#123; VIP_IFACE &#125;&#125;</span><br><span class="line">    virtual_router_id 47</span><br><span class="line">    advert_int 3</span><br><span class="line"></span><br><span class="line">    unicast_peer &#123;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        &#123;&#123; VIP &#125;&#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    track_script &#123;</span><br><span class="line">        haproxy-check</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 替换字符</span></span><br><span class="line">sed -r -e "s#\&#123;\&#123; VIP \&#125;\&#125;#$&#123;VIP&#125;#" \</span><br><span class="line">       -e "s#\&#123;\&#123; VIP_IFACE \&#125;\&#125;#$&#123;VIP_IFACE&#125;#" \</span><br><span class="line">       -e '/unicast_peer/r '&lt;(xargs -n1&lt;&lt;&lt;$&#123;MasterArray[@]&#125; | sort | sed 's#^#\t#') \</span><br><span class="line">       keepalived.conf.example &gt; keepalived.conf</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; check_haproxy.sh &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash">!/bin/bash</span></span><br><span class="line">VIRTUAL_IP=$&#123;VIP&#125;</span><br><span class="line"></span><br><span class="line">errorExit() &#123;</span><br><span class="line">    echo "*** $*" 1&gt;&amp;2</span><br><span class="line">    exit 1</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">if ip addr | grep -q \$VIRTUAL_IP ; then</span><br><span class="line">    curl -s --max-time 2 --insecure https://\$&#123;VIRTUAL_IP&#125;:8443/ -o /dev/null || errorExit "Error GET https://\$&#123;VIRTUAL_IP&#125;:8443/"</span><br><span class="line">fi</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="配置haproxy"><a href="#配置haproxy" class="headerlink" title="配置haproxy"></a>配置haproxy</h3><blockquote><ul><li>编辑<code>haproxy.cfg</code>模板</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; haproxy.cfg.example &lt;&lt;EOF</span><br><span class="line">global</span><br><span class="line">  maxconn  2000</span><br><span class="line">  ulimit-n  16384</span><br><span class="line">  log  127.0.0.1 local0 err</span><br><span class="line">  stats timeout 30s</span><br><span class="line"></span><br><span class="line">defaults</span><br><span class="line">  log global</span><br><span class="line">  mode  http</span><br><span class="line">  option  httplog</span><br><span class="line">  timeout connect 5000</span><br><span class="line">  timeout client  50000</span><br><span class="line">  timeout server  50000</span><br><span class="line">  timeout http-request 15s</span><br><span class="line">  timeout http-keep-alive 15s</span><br><span class="line"></span><br><span class="line">frontend monitor-in</span><br><span class="line">  bind $&#123;VIP&#125;:33305</span><br><span class="line">  mode http</span><br><span class="line">  option httplog</span><br><span class="line">  monitor-uri /monitor</span><br><span class="line"></span><br><span class="line">listen stats</span><br><span class="line">  bind    $&#123;VIP&#125;:8006</span><br><span class="line">  mode    http</span><br><span class="line">  stats   enable</span><br><span class="line">  stats   hide-version</span><br><span class="line">  stats   uri       /stats</span><br><span class="line">  stats   refresh   30s</span><br><span class="line">  stats   realm     Haproxy\ Statistics</span><br><span class="line">  stats   auth      admin:admin</span><br><span class="line"></span><br><span class="line">frontend k8s-api</span><br><span class="line">  bind $&#123;VIP&#125;:8443</span><br><span class="line">  mode tcp</span><br><span class="line">  option tcplog</span><br><span class="line">  tcp-request inspect-delay 5s</span><br><span class="line">  default_backend k8s-api</span><br><span class="line"></span><br><span class="line">backend k8s-api</span><br><span class="line">  mode tcp</span><br><span class="line">  option tcplog</span><br><span class="line">  option tcp-check</span><br><span class="line">  balance roundrobin</span><br><span class="line">  default-server inter 10s downinter 5s rise 2 fall 2 slowstart 60s maxconn 250 maxqueue 256 weight 100</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 替换字符</span></span><br><span class="line">sed -e '$r '&lt;(paste &lt;( seq -f'  server k8s-api-%g'  $&#123;#MasterArray[@]&#125; ) &lt;( xargs -n1&lt;&lt;&lt;$&#123;MasterArray[@]&#125; | sort | sed 's#$#:6443  check#')) haproxy.cfg.example &gt; haproxy.cfg</span><br></pre></td></tr></table></figure><h3 id="分发配置文件到master节点"><a href="#分发配置文件到master节点" class="headerlink" title="分发配置文件到master节点"></a>分发配置文件到master节点</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "---- $NODE ----"</span><br><span class="line">	rsync -avpt haproxy.cfg $NODE:/etc/haproxy/</span><br><span class="line">	rsync -avpt keepalived.conf \</span><br><span class="line">	            check_haproxy.sh \</span><br><span class="line">	            $NODE:/etc/keepalived/</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="启动keepalived和haproxy"><a href="#启动keepalived和haproxy" class="headerlink" title="启动keepalived和haproxy"></a>启动keepalived和haproxy</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "---- $NODE ----"</span><br><span class="line">	ssh $NODE systemctl enable --now keepalived haproxy</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="验证VIP"><a href="#验证VIP" class="headerlink" title="验证VIP"></a>验证VIP</h3><blockquote><ul><li>需要大约十秒的时间等待keepalived和haproxy服务起来</li><li>这里由于后端的kube-apiserver服务还没启动，只测试是否能ping通VIP</li><li>如果VIP没起来，就要去确认一下各master节点的keepalived服务是否正常</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sleep 15</span><br><span class="line">ping -c 4 $VIP</span><br></pre></td></tr></table></figure><h2 id="部署etcd集群"><a href="#部署etcd集群" class="headerlink" title="部署etcd集群"></a>部署etcd集群</h2><blockquote><ul><li>每个etcd节点的配置都需要做对应更改</li><li>在<font color="red" size="3">k8s-m1</font>上操作</li></ul></blockquote><h3 id="配置etcd-service文件"><a href="#配置etcd-service文件" class="headerlink" title="配置etcd.service文件"></a>配置etcd.service文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Etcd Service</span><br><span class="line">Documentation=https://coreos.com/etcd/docs/latest/</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=etcd</span><br><span class="line">Type=notify</span><br><span class="line">ExecStart=/usr/local/bin/etcd --config-file=/etc/etcd/etcd.config.yaml</span><br><span class="line">Restart=on-failure</span><br><span class="line">RestartSec=10</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">Alias=etcd3.service</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="etcd-config-yaml模板"><a href="#etcd-config-yaml模板" class="headerlink" title="etcd.config.yaml模板"></a>etcd.config.yaml模板</h3><blockquote><ul><li>关于各个参数的说明可以看<a href="https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/configuration.md" target="_blank" rel="noopener">这里</a></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; etcd.config.yaml.example &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> This is the configuration file <span class="keyword">for</span> the etcd server.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Human-readable name <span class="keyword">for</span> this member.</span></span><br><span class="line">name: '&#123;HOSTNAME&#125;'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Path to the data directory.</span></span><br><span class="line">data-dir: '/var/lib/etcd/&#123;HOSTNAME&#125;.data/'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Path to the dedicated wal directory.</span></span><br><span class="line">wal-dir: '/var/lib/etcd/&#123;HOSTNAME&#125;.wal/'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Number of committed transactions to trigger a snapshot to disk.</span></span><br><span class="line">snapshot-count: 5000</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) of a heartbeat interval.</span></span><br><span class="line">heartbeat-interval: 100</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) <span class="keyword">for</span> an election to timeout.</span></span><br><span class="line">election-timeout: 1000</span><br><span class="line"><span class="meta">#</span><span class="bash"> Raise alarms when backend size exceeds the given quota. 0 means use the</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> default quota.</span></span><br><span class="line">quota-backend-bytes: 0</span><br><span class="line"><span class="meta">#</span><span class="bash"> List of comma separated URLs to listen on <span class="keyword">for</span> peer traffic.</span></span><br><span class="line">listen-peer-urls: 'https://&#123;PUBLIC_IP&#125;:2380'</span><br><span class="line"><span class="meta">#</span><span class="bash"> List of comma separated URLs to listen on <span class="keyword">for</span> client traffic.</span></span><br><span class="line">listen-client-urls: 'https://&#123;PUBLIC_IP&#125;:2379,http://127.0.0.1:2379'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Maximum number of snapshot files to retain (0 is unlimited).</span></span><br><span class="line">max-snapshots: 3</span><br><span class="line"><span class="meta">#</span><span class="bash"> Maximum number of wal files to retain (0 is unlimited).</span></span><br><span class="line">max-wals: 5</span><br><span class="line"><span class="meta">#</span><span class="bash"> Comma-separated white list of origins <span class="keyword">for</span> CORS (cross-origin resource sharing).</span></span><br><span class="line">cors:</span><br><span class="line"><span class="meta">#</span><span class="bash"> List of this member<span class="string">'s peer URLs to advertise to the rest of the cluster.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The URLs needed to be a comma-separated list.</span></span><br><span class="line">initial-advertise-peer-urls: 'https://&#123;PUBLIC_IP&#125;:2380'</span><br><span class="line"><span class="meta">#</span><span class="bash"> List of this member<span class="string">'s client URLs to advertise to the public.</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> The URLs needed to be a comma-separated list.</span></span><br><span class="line">advertise-client-urls: 'https://&#123;PUBLIC_IP&#125;:2379'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Discovery URL used to bootstrap the cluster.</span></span><br><span class="line">discovery:</span><br><span class="line"><span class="meta">#</span><span class="bash"> Valid values include <span class="string">'exit'</span>, <span class="string">'proxy'</span></span></span><br><span class="line">discovery-fallback: 'proxy'</span><br><span class="line"><span class="meta">#</span><span class="bash"> HTTP proxy to use <span class="keyword">for</span> traffic to discovery service.</span></span><br><span class="line">discovery-proxy:</span><br><span class="line"><span class="meta">#</span><span class="bash"> DNS domain used to bootstrap initial cluster.</span></span><br><span class="line">discovery-srv:</span><br><span class="line"><span class="meta">#</span><span class="bash"> Initial cluster configuration <span class="keyword">for</span> bootstrapping.</span></span><br><span class="line">initial-cluster: '$&#123;ETCD_INITIAL_CLUSTER&#125;'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Initial cluster token <span class="keyword">for</span> the etcd cluster during bootstrap.</span></span><br><span class="line">initial-cluster-token: 'etcd-k8s-cluster'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Initial cluster state (<span class="string">'new'</span> or <span class="string">'existing'</span>).</span></span><br><span class="line">initial-cluster-state: 'new'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Reject reconfiguration requests that would cause quorum loss.</span></span><br><span class="line">strict-reconfig-check: false</span><br><span class="line"><span class="meta">#</span><span class="bash"> Accept etcd V2 client requests</span></span><br><span class="line">enable-v2: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> Enable runtime profiling data via HTTP server</span></span><br><span class="line">enable-pprof: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> Valid values include <span class="string">'on'</span>, <span class="string">'readonly'</span>, <span class="string">'off'</span></span></span><br><span class="line">proxy: 'off'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) an endpoint will be held <span class="keyword">in</span> a failed state.</span></span><br><span class="line">proxy-failure-wait: 5000</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) of the endpoints refresh interval.</span></span><br><span class="line">proxy-refresh-interval: 30000</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) <span class="keyword">for</span> a dial to timeout.</span></span><br><span class="line">proxy-dial-timeout: 1000</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) <span class="keyword">for</span> a write to timeout.</span></span><br><span class="line">proxy-write-timeout: 5000</span><br><span class="line"><span class="meta">#</span><span class="bash"> Time (<span class="keyword">in</span> milliseconds) <span class="keyword">for</span> a <span class="built_in">read</span> to timeout.</span></span><br><span class="line">proxy-read-timeout: 0</span><br><span class="line">client-transport-security:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Path to the client server TLS cert file.</span></span><br><span class="line">  cert-file: '/etc/etcd/ssl/etcd-server.pem'</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Path to the client server TLS key file.</span></span><br><span class="line">  key-file: '/etc/etcd/ssl/etcd-server-key.pem'</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Enable client cert authentication.</span></span><br><span class="line">  client-cert-auth: true</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Path to the client server TLS trusted CA cert file.</span></span><br><span class="line">  trusted-ca-file: '/etc/etcd/ssl/etcd-ca.pem'</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Client TLS using generated certificates</span></span><br><span class="line">  auto-tls: true</span><br><span class="line">peer-transport-security:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Path to the peer server TLS cert file.</span></span><br><span class="line">  cert-file: '/etc/etcd/ssl/etcd-server.pem'</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Path to the peer server TLS key file.</span></span><br><span class="line">  key-file: '/etc/etcd/ssl/etcd-server-key.pem'</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Enable peer client cert authentication.</span></span><br><span class="line">  client-cert-auth: true</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Path to the peer server TLS trusted CA cert file.</span></span><br><span class="line">  trusted-ca-file: '/etc/etcd/ssl/etcd-ca.pem'</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Peer TLS using generated certificates.</span></span><br><span class="line">  auto-tls: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> Enable debug-level logging <span class="keyword">for</span> etcd.</span></span><br><span class="line">debug: false</span><br><span class="line">logger: 'zap'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Specify <span class="string">'stdout'</span> or <span class="string">'stderr'</span> to skip journald logging even when running under systemd.</span></span><br><span class="line">log-outputs: [default]</span><br><span class="line"><span class="meta">#</span><span class="bash"> Force to create a new one member cluster.</span></span><br><span class="line">force-new-cluster: false</span><br><span class="line">auto-compaction-mode: 'periodic'</span><br><span class="line">auto-compaction-retention: '1'</span><br><span class="line"><span class="meta">#</span><span class="bash"> Set level of detail <span class="keyword">for</span> exported metrics, specify <span class="string">'extensive'</span> to include histogram metrics.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> default is <span class="string">'basic'</span></span></span><br><span class="line">metrics: 'basic'</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="分发配置文件"><a href="#分发配置文件" class="headerlink" title="分发配置文件"></a>分发配置文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 根据节点信息替换文本，分发到各etcd节点</span></span><br><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE $&#123;MasterArray[$NODE]&#125; ---"</span><br><span class="line">    sed -e "s/&#123;HOSTNAME&#125;/$NODE/g" \</span><br><span class="line">        -e "s/&#123;PUBLIC_IP&#125;/$&#123;MasterArray[$NODE]&#125;/g" \</span><br><span class="line">        etcd.config.yaml.example &gt; etcd.config.yaml.$&#123;NODE&#125;</span><br><span class="line">    rsync -avpt etcd.config.yaml.$&#123;NODE&#125; $&#123;NODE&#125;:/etc/etcd/etcd.config.yaml</span><br><span class="line">    rsync -avpt etcd.service $&#123;NODE&#125;:/usr/lib/systemd/system/etcd.service</span><br><span class="line">    ssh $&#123;NODE&#125; systemctl daemon-reload</span><br><span class="line">    ssh $&#123;NODE&#125; chown -R etcd:etcd /etc/etcd</span><br><span class="line">    rm -rf etcd.config.yaml.$&#123;NODE&#125;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="启动etcd集群"><a href="#启动etcd集群" class="headerlink" title="启动etcd集群"></a>启动etcd集群</h3><blockquote><ul><li>etcd 进程首次启动时会等待其它节点的 etcd 加入集群，命令 systemctl start etcd 会卡住一段时间，为正常现象</li><li>启动之后可以通过<code>etcdctl</code>命令查看集群状态</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE $&#123;MasterArray[$NODE]&#125; ---"</span><br><span class="line">    ssh $NODE systemctl enable etcd</span><br><span class="line">    ssh $NODE systemctl start etcd &amp;</span><br><span class="line">done</span><br></pre></td></tr></table></figure><blockquote><ul><li>为方便维护，可使用alias简化etcdctl命令</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">cat &gt;&gt; /root/.bashrc &lt;&lt;EOF</span><br><span class="line">alias etcdctl2="export ETCDCTL_API=2;etcdctl --ca-file '/etc/etcd/ssl/etcd-ca.pem' --cert-file '/etc/etcd/ssl/etcd-client.pem' --key-file '/etc/etcd/ssl/etcd-client-key.pem' --endpoints $&#123;ETCD_SERVERS&#125;"</span><br><span class="line">alias etcdctl3="export ETCDCTL_API=3;etcdctl --cacert=/etc/etcd/ssl/etcd-ca.pem --cert=/etc/etcd/ssl/etcd-client.pem --key=/etc/etcd/ssl/etcd-client-key.pem --endpoints=$&#123;ETCD_SERVERS&#125;"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="验证etcd集群状态"><a href="#验证etcd集群状态" class="headerlink" title="验证etcd集群状态"></a>验证etcd集群状态</h3><blockquote><ul><li>etcd提供v2和v3两套API，kubernetes使用v3</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 应用上面定义的<span class="built_in">alias</span></span></span><br><span class="line">source /root/.bashrc</span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用v2 API访问etcd的集群状态</span></span><br><span class="line">etcdctl2 cluster-health</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">member 222fd3b0bb4a5931 is healthy: got healthy result from https://172.16.80.203:2379</span><br><span class="line">member 8349ef180b115a83 is healthy: got healthy result from https://172.16.80.201:2379</span><br><span class="line">member f525d2d797a7c465 is healthy: got healthy result from https://172.16.80.202:2379</span><br><span class="line">cluster is healthy</span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用v2 API访问etcd成员列表</span></span><br><span class="line">etcdctl2 member list</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">222fd3b0bb4a5931: name=k8s-m3 peerURLs=https://172.16.80.203:2380 clientURLs=https://172.16.80.203:2379 isLeader=false</span><br><span class="line">8349ef180b115a83: name=k8s-m1 peerURLs=https://172.16.80.201:2380 clientURLs=https://172.16.80.201:2379 isLeader=false</span><br><span class="line">f525d2d797a7c465: name=k8s-m2 peerURLs=https://172.16.80.202:2380 clientURLs=https://172.16.80.202:2379 isLeader=true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用v3 API访问etcd的endpoint状态</span></span><br><span class="line">etcdctl3 endpoint health</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">https://172.16.80.201:2379 is healthy: successfully committed proposal: took = 2.879402ms</span><br><span class="line">https://172.16.80.203:2379 is healthy: successfully committed proposal: took = 6.708566ms</span><br><span class="line">https://172.16.80.202:2379 is healthy: successfully committed proposal: took = 7.187607ms</span><br><span class="line"><span class="meta">#</span><span class="bash"> 使用v3 API访问etcd成员列表</span></span><br><span class="line">etcdctl3 member list --write-out=table</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">+------------------+---------+--------+----------------------------+----------------------------+</span><br><span class="line">|        ID        | STATUS  |  NAME  |         PEER ADDRS         |        CLIENT ADDRS        |</span><br><span class="line">+------------------+---------+--------+----------------------------+----------------------------+</span><br><span class="line">| 222fd3b0bb4a5931 | started | k8s-m3 | https://172.16.80.203:2380 | https://172.16.80.203:2379 |</span><br><span class="line">| 8349ef180b115a83 | started | k8s-m1 | https://172.16.80.201:2380 | https://172.16.80.201:2379 |</span><br><span class="line">| f525d2d797a7c465 | started | k8s-m2 | https://172.16.80.202:2380 | https://172.16.80.202:2379 |</span><br><span class="line">+------------------+---------+--------+----------------------------+----------------------------+</span><br></pre></td></tr></table></figure><h2 id="Master组件服务"><a href="#Master组件服务" class="headerlink" title="Master组件服务"></a>Master组件服务</h2><h3 id="master组件配置模板"><a href="#master组件配置模板" class="headerlink" title="master组件配置模板"></a>master组件配置模板</h3><h4 id="kube-apiserver-conf"><a href="#kube-apiserver-conf" class="headerlink" title="kube-apiserver.conf"></a>kube-apiserver.conf</h4><blockquote><ul><li><p><code>--allow-privileged=true</code>启用容器特权模式</p></li><li><p><code>--apiserver-count=3</code>指定集群运行模式，其它节点处于阻塞状态</p></li><li><p><code>--audit-policy-file=/etc/kubernetes/audit-policy.yaml</code> 基于audit-policy.yaml文件定义的内容启动审计功能</p></li><li><p><code>--authorization-mode=Node,RBAC</code>开启 Node 和 RBAC 授权模式，拒绝未授权的请求</p></li><li><p><code>--disable-admission-plugins=</code>和<code>--enable-admission-plugins</code>禁用和启用准入控制插件。</p></li></ul><p>准入控制插件会在请求通过认证和授权之后、对象被持久化之前拦截到达apiserver的请求。</p><p>准入控制插件依次执行，因此需要注意顺序。</p><p>如果插件序列中任何一个拒绝了请求，则整个请求将立刻被拒绝并返回错误给客户端。</p><p>关于admission-plugins官方文档里面有推荐配置，这里直接采用官方配置，注意针对不同kubernetes版本都会有不一样的配置，具体可以看<a href="https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/#is-there-a-recommended-set-of-admission-controllers-to-use" target="_blank" rel="noopener">这里</a></p><ul><li><code>--enable-bootstrap-token-auth=true</code>启用 kubelet bootstrap 的 token 认证</li><li><code>--experimental-encryption-provider-config=/etc/kubernetes/encryption.yaml</code>启用加密特性将Secret数据加密存储到etcd</li><li><code>--insecure-port=0</code>关闭监听非安全端口8080</li><li><code>--runtime-config=api/all=true</code>启用所有版本的 APIs</li><li><code>--service-cluster-ip-range=10.96.0.0/12</code>指定 Service Cluster IP 地址段</li><li><code>--service-node-port-range=30000-32767</code>指定 NodePort 的端口范围</li><li><code>--token-auth-file=/etc/kubernetes/token.csv</code>保存bootstrap的token信息</li><li><code>--target-ram-mb</code>配置缓存大小，参考值为<code>节点数*60</code></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-apiserver.conf.example &lt;&lt;EOF</span><br><span class="line">KUBE_APISERVER_ARGS=" \\</span><br><span class="line">--advertise-address=&#123;PUBLIC_IP&#125;  \\</span><br><span class="line">--allow-privileged=true  \\</span><br><span class="line">--apiserver-count=3 \\</span><br><span class="line">--audit-log-maxage=30  \\</span><br><span class="line">--audit-log-maxbackup=3  \\</span><br><span class="line">--audit-log-maxsize=1000  \\</span><br><span class="line">--audit-log-path=/var/log/kube-audit/audit.log  \\</span><br><span class="line">--audit-policy-file=/etc/kubernetes/audit-policy.yaml  \\</span><br><span class="line">--authorization-mode=Node,RBAC  \\</span><br><span class="line">--bind-address=0.0.0.0 \\</span><br><span class="line">--client-ca-file=/etc/kubernetes/pki/kube-ca.pem  \\</span><br><span class="line">--disable-admission-plugins=PersistentVolumeLabel \\</span><br><span class="line">--enable-admission-plugins=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,DefaultTolerationSeconds,MutatingAdmissionWebhook,ValidatingAdmissionWebhook,ResourceQuota,PodPreset  \\</span><br><span class="line">--enable-aggregator-routing=true \\</span><br><span class="line">--enable-bootstrap-token-auth=true  \\</span><br><span class="line">--enable-garbage-collector=true \\</span><br><span class="line">--etcd-compaction-interval=1h \\</span><br><span class="line">--etcd-cafile=/etc/kubernetes/pki/etcd-ca.pem  \\</span><br><span class="line">--etcd-certfile=/etc/kubernetes/pki/etcd-client.pem  \\</span><br><span class="line">--etcd-keyfile=/etc/kubernetes/pki/etcd-client-key.pem  \\</span><br><span class="line">--etcd-servers=$ETCD_SERVERS  \\</span><br><span class="line">--experimental-encryption-provider-config=/etc/kubernetes/encryption.yaml  \\</span><br><span class="line">--event-ttl=1h  \\</span><br><span class="line">--feature-gates=PodShareProcessNamespace=true,ExpandPersistentVolumes=true \\</span><br><span class="line">--insecure-port=0  \\</span><br><span class="line">--kubelet-client-certificate=/etc/kubernetes/pki/kube-apiserver.pem  \\</span><br><span class="line">--kubelet-client-key=/etc/kubernetes/pki/kube-apiserver-key.pem  \\</span><br><span class="line">--kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname  \\</span><br><span class="line">--logtostderr=true  \\</span><br><span class="line">--max-mutating-requests-inflight=500  \\</span><br><span class="line">--max-requests-inflight=1500  \\</span><br><span class="line">--proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem  \\</span><br><span class="line">--proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem  \\</span><br><span class="line">--requestheader-allowed-names=aggregator  \\</span><br><span class="line">--requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem  \\</span><br><span class="line">--requestheader-extra-headers-prefix=X-Remote-Extra-  \\</span><br><span class="line">--requestheader-group-headers=X-Remote-Group  \\</span><br><span class="line">--requestheader-username-headers=X-Remote-User  \\</span><br><span class="line">--runtime-config=api/all=true  \\</span><br><span class="line">--secure-port=6443  \\</span><br><span class="line">--service-account-key-file=/etc/kubernetes/pki/sa.pem  \\</span><br><span class="line">--service-cluster-ip-range=10.96.0.0/12  \\</span><br><span class="line">--service-node-port-range=30000-32767 \\</span><br><span class="line">--storage-backend=etcd3 \\</span><br><span class="line">--target-ram-mb=300 \\</span><br><span class="line">--tls-cert-file=/etc/kubernetes/pki/kube-apiserver.pem  \\</span><br><span class="line">--tls-private-key-file=/etc/kubernetes/pki/kube-apiserver-key.pem  \\</span><br><span class="line">--token-auth-file=/etc/kubernetes/token.csv \\</span><br><span class="line">--v=2  \\</span><br><span class="line">"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="kube-controller-manager-conf"><a href="#kube-controller-manager-conf" class="headerlink" title="kube-controller-manager.conf"></a>kube-controller-manager.conf</h4><blockquote><ul><li><code>--allocate-node-cidrs=true</code>在cloud provider上分配和设置pod的CIDR</li><li><code>--cluster-cidr</code>集群内的pod的CIDR范围，需要 <code>--allocate-node-cidrs</code>设为true</li><li><code>--experimental-cluster-signing-duration=8670h0m0s</code>指定 TLS Bootstrap 证书的有效期</li><li><code>--feature-gates=RotateKubeletServerCertificate=true</code>开启 kublet server 证书的自动更新特性</li><li><code>--horizontal-pod-autoscaler-use-rest-clients=true</code>能够使用自定义资源（Custom Metrics）进行自动水平扩展</li><li><code>--leader-elect=true</code>集群运行模式，启用选举功能，被选为 leader 的节点负责处理工作，其它节点为阻塞状态</li><li><code>--node-cidr-mask-size=24</code>集群中node cidr的掩码</li><li><code>--service-cluster-ip-range=10.96.0.0/16</code>指定 Service Cluster IP 网段，必须和 kube-apiserver 中的同名参数一致</li><li><code>--terminated-pod-gc-threshold</code>exit状态的pod超过多少会触发gc</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-controller-manager.conf.example &lt;&lt;EOF</span><br><span class="line">KUBE_CONTROLLER_MANAGER_ARGS=" \\</span><br><span class="line">--address=0.0.0.0 \\</span><br><span class="line">--allocate-node-cidrs=true \\</span><br><span class="line">--cluster-cidr=$POD_NET_CIDR \\</span><br><span class="line">--cluster-signing-cert-file=/etc/kubernetes/pki/kube-ca.pem \\</span><br><span class="line">--cluster-signing-key-file=/etc/kubernetes/pki/kube-ca-key.pem \\</span><br><span class="line">--concurrent-service-syncs=10 \\</span><br><span class="line">--concurrent-serviceaccount-token-syncs=20 \\</span><br><span class="line">--controllers=*,bootstrapsigner,tokencleaner \\</span><br><span class="line">--enable-garbage-collector=true \\</span><br><span class="line">--experimental-cluster-signing-duration=8670h0m0s \\</span><br><span class="line">--feature-gates=RotateKubeletServerCertificate=true,ExpandPersistentVolumes=true \\</span><br><span class="line">--horizontal-pod-autoscaler-sync-period=10s \\</span><br><span class="line">--horizontal-pod-autoscaler-use-rest-clients=true \\</span><br><span class="line">--kubeconfig=/etc/kubernetes/kube-controller-manager.kubeconfig \\</span><br><span class="line">--leader-elect=true \\</span><br><span class="line">--logtostderr=true \\</span><br><span class="line">--node-cidr-mask-size=24 \\</span><br><span class="line">--node-monitor-grace-period=40s \\</span><br><span class="line">--node-monitor-period=5s \\</span><br><span class="line">--pod-eviction-timeout=2m0s \\</span><br><span class="line">--root-ca-file=/etc/kubernetes/pki/kube-ca.pem \\</span><br><span class="line">--service-account-private-key-file=/etc/kubernetes/pki/sa-key.pem \\</span><br><span class="line">--service-cluster-ip-range=$SVC_CLUSTER_CIDR \\</span><br><span class="line">--terminated-pod-gc-threshold=12500 \\</span><br><span class="line">--use-service-account-credentials=true \\</span><br><span class="line">--v=2 \\</span><br><span class="line">"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="kube-scheduler-conf"><a href="#kube-scheduler-conf" class="headerlink" title="kube-scheduler.conf"></a>kube-scheduler.conf</h4><blockquote><ul><li><code>--leader-elect=true</code>集群运行模式，启用选举功能，被选为 leader 的节点负责处理工作，其它节点为阻塞状态</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-scheduler.conf.example &lt;&lt;EOF</span><br><span class="line">KUBE_SCHEDULER_ARGS="\\</span><br><span class="line">--address=0.0.0.0 \\</span><br><span class="line">--algorithm-provider=DefaultProvider \\</span><br><span class="line">--kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \\</span><br><span class="line">--leader-elect=true \\</span><br><span class="line">--logtostderr=true \\</span><br><span class="line">--v=2 \\</span><br><span class="line">"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="systemd服务文件"><a href="#systemd服务文件" class="headerlink" title="systemd服务文件"></a>systemd服务文件</h3><h4 id="kube-apiserver-service"><a href="#kube-apiserver-service" class="headerlink" title="kube-apiserver.service"></a>kube-apiserver.service</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-apiserver.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line">After=etcd.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=kube</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-apiserver.conf</span><br><span class="line">ExecStart=/usr/local/bin/kube-apiserver \$KUBE_APISERVER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">Type=notify</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="kube-controller-manager-service"><a href="#kube-controller-manager-service" class="headerlink" title="kube-controller-manager.service"></a>kube-controller-manager.service</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-controller-manager.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=kube</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-controller-manager.conf</span><br><span class="line">ExecStart=/usr/local/bin/kube-controller-manager \$KUBE_CONTROLLER_MANAGER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="kube-scheduler-service"><a href="#kube-scheduler-service" class="headerlink" title="kube-scheduler.service"></a>kube-scheduler.service</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-scheduler.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler Plugin</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">User=kube</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-scheduler.conf</span><br><span class="line">ExecStart=/usr/local/bin/kube-scheduler \$KUBE_SCHEDULER_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="分发配置文件到各master节点"><a href="#分发配置文件到各master节点" class="headerlink" title="分发配置文件到各master节点"></a>分发配置文件到各master节点</h3><blockquote><ul><li>根据master节点的信息替换配置文件里面的字段</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE $&#123;MasterArray[$NODE]&#125; ---"</span><br><span class="line">    rsync -avpt kube*service $NODE:/usr/lib/systemd/system/</span><br><span class="line">    sed -e "s/&#123;PUBLIC_IP&#125;/$&#123;MasterArray[$NODE]&#125;/g" kube-apiserver.conf.example &gt; kube-apiserver.conf.$&#123;NODE&#125;</span><br><span class="line">    rsync -avpt kube-apiserver.conf.$&#123;NODE&#125; $NODE:/etc/kubernetes/kube-apiserver.conf</span><br><span class="line">    rsync -avpt kube-controller-manager.conf.example $NODE:/etc/kubernetes/kube-controller-manager.conf</span><br><span class="line">    rsync -avpt kube-scheduler.conf.example $NODE:/etc/kubernetes/kube-scheduler.conf</span><br><span class="line">    rm -rf *conf.$&#123;NODE&#125;</span><br><span class="line">    ssh $NODE systemctl daemon-reload</span><br><span class="line">    ssh $NODE chown -R kube:kube /etc/kubernetes</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="启动kubernetes服务"><a href="#启动kubernetes服务" class="headerlink" title="启动kubernetes服务"></a>启动kubernetes服务</h3><blockquote><ul><li>可以先在<font color="red" size="3">k8s-m1</font>上面启动服务，确认正常之后再在其他master节点启动</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">systemctl enable --now kube-apiserver.service</span><br><span class="line">systemctl enable --now kube-controller-manager.service</span><br><span class="line">systemctl enable --now kube-scheduler.service</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">kubectl --kubeconfig=/etc/kubernetes/kube-admin.kubeconfig get cs</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME                 STATUS    MESSAGE             ERROR</span><br><span class="line">controller-manager   Healthy   ok                  </span><br><span class="line">scheduler            Healthy   ok                  </span><br><span class="line">etcd-2               Healthy   &#123;"health":"true"&#125;   </span><br><span class="line">etcd-0               Healthy   &#123;"health":"true"&#125;   </span><br><span class="line">etcd-1               Healthy   &#123;"health":"true"&#125;</span><br><span class="line"></span><br><span class="line">kubectl --kubeconfig=/etc/kubernetes/kube-admin.kubeconfig get endpoints</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME         ENDPOINTS            AGE</span><br><span class="line">kubernetes   172.16.80.201:6443   27s</span><br></pre></td></tr></table></figure><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE $&#123;MasterArray[$NODE]&#125; ---"</span><br><span class="line">    ssh $NODE "systemctl enable --now kube-apiserver"</span><br><span class="line">    ssh $NODE "systemctl enable --now kube-controller-manager"</span><br><span class="line">    ssh $NODE "systemctl enable --now kube-scheduler"</span><br><span class="line">done</span><br></pre></td></tr></table></figure><blockquote><ul><li>三台master节点的<code>kube-apiserver</code>、<code>kube-controller-manager</code>、<code>kube-scheduler</code>服务启动成功后可以测试一下</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl --kubeconfig=/etc/kubernetes/kube-admin.kubeconfig get endpoints</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME         ENDPOINTS                                                  AGE</span><br><span class="line">kubernetes   172.16.80.201:6443,172.16.80.202:6443,172.16.80.203:6443   12m</span><br></pre></td></tr></table></figure><h3 id="设置kubectl"><a href="#设置kubectl" class="headerlink" title="设置kubectl"></a>设置kubectl</h3><blockquote><ul><li>kubectl命令默认会加载<code>~/.kube/config</code>文件，如果文件不存在则连接<code>http://127.0.0.1:8080</code>，这显然不符合预期，这里使用之前生成的kube-admin.kubeconfig</li><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE $&#123;MasterArray[$NODE]&#125; ---"</span><br><span class="line">    ssh $NODE mkdir -p /root/.kube</span><br><span class="line">    rsync -avpt /root/pki/kube-admin.kubeconfig $NODE:/root/.kube/config</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h3 id="设置命令补全"><a href="#设置命令补全" class="headerlink" title="设置命令补全"></a>设置命令补全</h3><blockquote><ul><li>设置<code>kubectl</code> 命令自动补全</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!MasterArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE $&#123;MasterArray[$NODE]&#125; ---"</span><br><span class="line">    echo "--- kubectl命令自动补全 ---"</span><br><span class="line">    ssh $NODE kubectl completion bash &gt;&gt; /etc/bash_completion.d/kubectl</span><br><span class="line">    echo "--- kubeadm命令自动补全 ---"</span><br><span class="line">    ssh $NODE kubeadm completion bash &gt;&gt; /etc/bash_completion.d/kubeadm</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">source /etc/bash_completion.d/kubectl</span><br></pre></td></tr></table></figure><h3 id="设置kubelet的bootstrap启动所需的RBAC"><a href="#设置kubelet的bootstrap启动所需的RBAC" class="headerlink" title="设置kubelet的bootstrap启动所需的RBAC"></a>设置kubelet的bootstrap启动所需的RBAC</h3><blockquote><ul><li><p>当集群开启了 TLS 认证后，每个节点的 kubelet 组件都要使用由 apiserver 使用的 CA 签发的有效证书才能与<br>apiserver 通讯；此时如果节点多起来，为每个节点单独签署证书将是一件非常繁琐的事情；TLS bootstrapping 功能就是让 kubelet 先使用一个预定的低权限用户连接到 apiserver，然后向 apiserver 申请证书，kubelet 的证书由 apiserver 动态签署；</p></li><li><p>在其中一个master节点上执行就可以，以<font color="red"><strong>k8s-m1</strong></font>为例</p></li></ul></blockquote><h4 id="创建工作目录-1"><a href="#创建工作目录-1" class="headerlink" title="创建工作目录"></a>创建工作目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/tls-bootstrap</span><br><span class="line">cd /root/yaml/tls-bootstrap/</span><br></pre></td></tr></table></figure><h4 id="kubelet-bootstrap-rbac-yaml"><a href="#kubelet-bootstrap-rbac-yaml" class="headerlink" title="kubelet-bootstrap-rbac.yaml"></a>kubelet-bootstrap-rbac.yaml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建yaml文件</span></span><br><span class="line">cat &gt; kubelet-bootstrap-rbac.yaml &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 给予 kubelet-bootstrap 用户进行 node-bootstrapper 的权限</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: kubelet-bootstrap</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:node-bootstrapper</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: User</span><br><span class="line">  name: kubelet-bootstrap</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="tls-bootstrap-clusterrole-yaml"><a href="#tls-bootstrap-clusterrole-yaml" class="headerlink" title="tls-bootstrap-clusterrole.yaml"></a>tls-bootstrap-clusterrole.yaml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建yaml文件</span></span><br><span class="line">cat &gt; tls-bootstrap-clusterrole.yaml &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> A ClusterRole <span class="built_in">which</span> instructs the CSR approver to approve a node requesting a</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> serving cert matching its client cert.</span></span><br><span class="line">kind: ClusterRole</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">metadata:</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeserver</span><br><span class="line">rules:</span><br><span class="line">- apiGroups: ["certificates.k8s.io"]</span><br><span class="line">  resources: ["certificatesigningrequests/selfnodeserver"]</span><br><span class="line">  verbs: ["create"]</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="node-client-auto-approve-csr-yaml"><a href="#node-client-auto-approve-csr-yaml" class="headerlink" title="node-client-auto-approve-csr.yaml"></a>node-client-auto-approve-csr.yaml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建yaml文件</span></span><br><span class="line">cat &gt; node-client-auto-approve-csr.yaml &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 自动批准 system:bootstrappers 组用户 TLS bootstrapping 首次申请证书的 CSR 请求</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: node-client-auto-approve-csr</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:nodeclient</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:bootstrappers</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="node-client-auto-renew-crt-yaml"><a href="#node-client-auto-renew-crt-yaml" class="headerlink" title="node-client-auto-renew-crt.yaml"></a>node-client-auto-renew-crt.yaml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建yaml文件</span></span><br><span class="line">cat &gt; node-client-auto-renew-crt.yaml &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 自动批准 system:nodes 组用户更新 kubelet 自身与 apiserver 通讯证书的 CSR 请求</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: node-client-auto-renew-crt</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:nodes</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="node-server-auto-renew-crt-yaml"><a href="#node-server-auto-renew-crt-yaml" class="headerlink" title="node-server-auto-renew-crt.yaml"></a>node-server-auto-renew-crt.yaml</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建yaml文件</span></span><br><span class="line">cat &gt; node-server-auto-renew-crt.yaml &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 自动批准 system:nodes 组用户更新 kubelet 10250 api 端口证书的 CSR 请求</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: node-server-auto-renew-crt</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:certificates.k8s.io:certificatesigningrequests:selfnodeserver</span><br><span class="line">subjects:</span><br><span class="line">- apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: Group</span><br><span class="line">  name: system:nodes</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="创建tls-bootstrap-rbac"><a href="#创建tls-bootstrap-rbac" class="headerlink" title="创建tls-bootstrap-rbac"></a>创建tls-bootstrap-rbac</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f .</span><br></pre></td></tr></table></figure><h3 id="设置kube-apiserver获取node信息的权限"><a href="#设置kube-apiserver获取node信息的权限" class="headerlink" title="设置kube-apiserver获取node信息的权限"></a>设置kube-apiserver获取node信息的权限</h3><h4 id="说明-2"><a href="#说明-2" class="headerlink" title="说明"></a>说明</h4><p>本文部署的<code>kubelet</code>关闭了匿名访问，因此需要额外为<code>kube-apiserver</code>添加权限用于访问kubelet的信息</p><p>若没添加此<code>RBAC</code>，则<code>kubectl</code>在执行<code>logs</code>、<code>exec</code>等指令的时候会提示<code>401 Forbidden</code></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system logs calico-node-pc8lq </span><br><span class="line">Error from server (Forbidden): Forbidden (user=kube-apiserver, verb=get, resource=nodes, subresource=proxy) ( pods/log calico-node-pc8lq)</span><br></pre></td></tr></table></figure><p>参考文档：<a href="https://jimmysong.io/kubernetes-handbook/guide/kubelet-authentication-authorization.html" target="_blank" rel="noopener">Kublet的认证授权</a></p><h4 id="创建yaml文件"><a href="#创建yaml文件" class="headerlink" title="创建yaml文件"></a>创建yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /root/yaml/apiserver-to-kubelet-rbac.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: "true"</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">rules:</span><br><span class="line">  - apiGroups:</span><br><span class="line">      - ""</span><br><span class="line">    resources:</span><br><span class="line">      - nodes/proxy</span><br><span class="line">      - nodes/stats</span><br><span class="line">      - nodes/log</span><br><span class="line">      - nodes/spec</span><br><span class="line">      - nodes/metrics</span><br><span class="line">    verbs:</span><br><span class="line">      - "*"</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: system:kube-apiserver</span><br><span class="line">  namespace: ""</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:kube-apiserver-to-kubelet</span><br><span class="line">subjects:</span><br><span class="line">  - apiGroup: rbac.authorization.k8s.io</span><br><span class="line">    kind: User</span><br><span class="line">    name: kube-apiserver</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="创建RBAC"><a href="#创建RBAC" class="headerlink" title="创建RBAC"></a>创建RBAC</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f /root/yaml/apiserver-to-kubelet-rbac.yaml</span><br></pre></td></tr></table></figure><h1 id="kubernetes-worker节点"><a href="#kubernetes-worker节点" class="headerlink" title="kubernetes worker节点"></a>kubernetes worker节点</h1><h2 id="worker节点说明"><a href="#worker节点说明" class="headerlink" title="worker节点说明"></a><strong>worker节点说明</strong></h2><blockquote><ul><li>安装Docker-ce，配置与master节点一致即可</li><li>安装cni-plugins、kubelet、kube-proxy</li><li>关闭防火墙和SELINUX</li><li>kubelet和kube-proxy运行需要root权限</li><li>这里是以k8s-m1、k8s-m2、k8s-m3作为Work节点加入集群</li></ul></blockquote><p><strong>kubelet</strong></p><blockquote><ul><li>管理容器生命周期、节点状态监控</li><li>目前 kubelet 支持三种数据源来获取节点Pod信息：<ul><li>本地文件</li><li>通过 url 从网络上某个地址来获取信息</li><li>API Server：从 kubernetes master 节点获取信息</li></ul></li><li>使用kubeconfig与kube-apiserver通信</li><li>这里启用<code>TLS-Bootstrap</code>实现kubelet证书动态签署证书，并自动生成kubeconfig</li></ul></blockquote><p><strong>kube-proxy</strong></p><blockquote><ul><li>Kube-proxy是实现Service的关键插件，kube-proxy会在每台节点上执行，然后监听API Server的Service与Endpoint资源物件的改变，然后来依据变化调用相应的组件来实现网路的转发</li><li>kube-proxy可以使用<code>userspace</code>（基本已废弃）、<code>iptables</code>（默认方式）和<code>ipvs</code>来实现数据报文的转发</li><li>这里使用的是性能更好、适合大规模使用的<code>ipvs</code></li><li>使用kubeconfig与kube-apiserver通信</li></ul></blockquote><h2 id="切换工作目录-1"><a href="#切换工作目录-1" class="headerlink" title="切换工作目录"></a>切换工作目录</h2><blockquote><ul><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/worker</span><br></pre></td></tr></table></figure><h2 id="worker组件配置模板"><a href="#worker组件配置模板" class="headerlink" title="worker组件配置模板"></a>worker组件配置模板</h2><h3 id="kubelet-conf"><a href="#kubelet-conf" class="headerlink" title="kubelet.conf"></a>kubelet.conf</h3><blockquote><ul><li><code>--bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig</code>指定bootstrap启动时使用的kubeconfig</li><li><code>--network-plugin=cni</code>定义网络插件，Pod生命周期使用此网络插件</li><li><code>--node-labels=node-role.kubernetes.io/node=&#39;&#39;</code>kubelet注册当前Node时设置的Label，以key=value的格式表示，多个labe以逗号分隔</li><li><code>--pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.1</code>Pod的pause镜像</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kubelet.conf &lt;&lt;EOF</span><br><span class="line">KUBELET_ARGS=" \\</span><br><span class="line">--bootstrap-kubeconfig=/etc/kubernetes/bootstrap.kubeconfig \\</span><br><span class="line">--cert-dir=/etc/kubernetes/ssl \\</span><br><span class="line">--config=/etc/kubernetes/kubelet.config.file \\</span><br><span class="line">--cni-conf-dir=/etc/cni/net.d \\</span><br><span class="line">--cni-bin-dir=/opt/cni/bin \\</span><br><span class="line">--kubeconfig=/etc/kubernetes/kubelet.kubeconfig \\</span><br><span class="line">--logtostderr=true \\</span><br><span class="line">--network-plugin=cni \\</span><br><span class="line">--node-labels=node-role.kubernetes.io/node='' \\</span><br><span class="line">--pod-infra-container-image=gcrxio/pause:3.1 \\</span><br><span class="line">--v=2 \\</span><br><span class="line">"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kubelet-config-file"><a href="#kubelet-config-file" class="headerlink" title="kubelet.config.file"></a>kubelet.config.file</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kubelet.config.file &lt;&lt;EOF</span><br><span class="line">apiVersion: kubelet.config.k8s.io/v1beta1</span><br><span class="line">kind: KubeletConfiguration</span><br><span class="line">address: 0.0.0.0</span><br><span class="line">authentication:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> 匿名访问</span></span><br><span class="line">  anonymous:</span><br><span class="line">    enabled: false</span><br><span class="line">  webhook:</span><br><span class="line">    cacheTTL: 2m0s</span><br><span class="line">    enabled: true</span><br><span class="line">  x509:</span><br><span class="line">    # 这里写kubernetes-ca证书的路径</span><br><span class="line">    clientCAFile: /etc/kubernetes/pki/kube-ca.pem</span><br><span class="line">authorization:</span><br><span class="line">  mode: Webhook</span><br><span class="line">  webhook:</span><br><span class="line">    cacheAuthorizedTTL: 5m0s</span><br><span class="line">    cacheUnauthorizedTTL: 30s</span><br><span class="line"><span class="meta">#</span><span class="bash"> cgroups的驱动，可选systemd和cgroupfs</span></span><br><span class="line">cgroupDriver: cgroupfs</span><br><span class="line">cgroupsPerQOS: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 指定Pod的DNS服务器IP地址</span></span><br><span class="line">clusterDNS:</span><br><span class="line">- 10.96.0.10</span><br><span class="line"><span class="meta">#</span><span class="bash"> 集群的域名</span></span><br><span class="line">clusterDomain: cluster.local</span><br><span class="line">containerLogMaxFiles: 5</span><br><span class="line">containerLogMaxSize: 10Mi</span><br><span class="line">contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">cpuCFSQuota: true</span><br><span class="line">cpuManagerPolicy: none</span><br><span class="line">cpuManagerReconcilePeriod: 10s</span><br><span class="line">enableControllerAttachDetach: true</span><br><span class="line">enableDebuggingHandlers: true</span><br><span class="line">enforceNodeAllocatable:</span><br><span class="line">- pods</span><br><span class="line">eventBurst: 10</span><br><span class="line">eventRecordQPS: 5</span><br><span class="line"><span class="meta">#</span><span class="bash"> 达到某些阈值之后，kubelet会驱逐Pod</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> A <span class="built_in">set</span> of eviction thresholds (e.g. memory.available&lt;1Gi) that <span class="keyword">if</span> met would trigger a pod eviction.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> (default imagefs.available&lt;15%,memory.available&lt;100Mi,nodefs.available&lt;10%,nodefs.inodesFree&lt;5%)</span></span><br><span class="line">evictionHard:</span><br><span class="line">  imagefs.available: 15%</span><br><span class="line">  memory.available: 1000Mi</span><br><span class="line">  nodefs.available: 10%</span><br><span class="line">  nodefs.inodesFree: 10%</span><br><span class="line">evictionPressureTransitionPeriod: 5m0s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 检测到系统已启用swap分区时kubelet会启动失败</span></span><br><span class="line">failSwapOn: false</span><br><span class="line"><span class="meta">#</span><span class="bash"> 定义feature gates</span></span><br><span class="line">featureGates:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> kubelet 在证书即将到期时会自动发起一个 renew 自己证书的 CSR 请求</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> 其实rotate证书已经默认开启，这里显示定义是为了方便查看</span></span><br><span class="line">  RotateKubeletClientCertificate: true</span><br><span class="line">  RotateKubeletServerCertificate: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 检查kubelet配置文件变更的间隔</span></span><br><span class="line">fileCheckFrequency: 20s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 允许endpoint在尝试访问自己的服务时会被负载均衡分发到自身</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 可选值<span class="string">"promiscuous-bridge"</span>, <span class="string">"hairpin-veth"</span> and <span class="string">"none"</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 默认值为promiscuous-bridge</span></span><br><span class="line">hairpinMode: promiscuous-bridge</span><br><span class="line">healthzBindAddress: 127.0.0.1</span><br><span class="line">healthzPort: 10248</span><br><span class="line">httpCheckFrequency: 20s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里定义容器镜像触发回收空间的上限值和下限值</span></span><br><span class="line">imageGCHighThresholdPercent: 85</span><br><span class="line">imageGCLowThresholdPercent: 80</span><br><span class="line">imageMinimumGCAge: 2m0s</span><br><span class="line">iptablesDropBit: 15</span><br><span class="line">iptablesMasqueradeBit: 14</span><br><span class="line">kubeAPIBurst: 10</span><br><span class="line">kubeAPIQPS: 5</span><br><span class="line">makeIPTablesUtilChains: true</span><br><span class="line"><span class="meta">#</span><span class="bash"> kubelet进程最大能打开的文件数量，默认是1000000</span></span><br><span class="line">maxOpenFiles: 1000000</span><br><span class="line"><span class="meta">#</span><span class="bash"> 当前节点kubelet所能运行的最大Pod数量</span></span><br><span class="line">maxPods: 110</span><br><span class="line"><span class="meta">#</span><span class="bash"> node状态上报间隔</span></span><br><span class="line">nodeStatusUpdateFrequency: 10s</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">podPidsLimit: -1</span><br><span class="line"><span class="meta">#</span><span class="bash"> kubelet服务端口</span></span><br><span class="line">port: 10250</span><br><span class="line">registryBurst: 10</span><br><span class="line">registryPullQPS: 5</span><br><span class="line"><span class="meta">#</span><span class="bash"> 指定域名解析文件</span></span><br><span class="line">resolvConf: /etc/resolv.conf</span><br><span class="line">rotateCertificates: true</span><br><span class="line">runtimeRequestTimeout: 2m0s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 拉镜像时，同一时间只拉取一个镜像</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> We recommend *not* changing the default value on nodes that run docker daemon with version &lt; 1.9 or an Aufs storage backend. Issue <span class="comment">#10959 has more details. (default true)</span></span></span><br><span class="line">serializeImagePulls: true</span><br><span class="line">staticPodPath: /etc/kubernetes/manifests</span><br><span class="line">streamingConnectionIdleTimeout: 4h0m0s</span><br><span class="line">syncFrequency: 1m0s</span><br><span class="line">volumeStatsAggPeriod: 1m0s</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-proxy-conf"><a href="#kube-proxy-conf" class="headerlink" title="kube-proxy.conf"></a>kube-proxy.conf</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-proxy.conf &lt;&lt;EOF</span><br><span class="line">KUBE_PROXY_ARGS=" \\</span><br><span class="line">--config=/etc/kubernetes/kube-proxy.config.file \\</span><br><span class="line">--v=2 \\</span><br><span class="line">"</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-proxy-config-file"><a href="#kube-proxy-config-file" class="headerlink" title="kube-proxy.config.file"></a>kube-proxy.config.file</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-proxy.config.file &lt;&lt;EOF</span><br><span class="line">apiVersion: kubeproxy.config.k8s.io/v1alpha1</span><br><span class="line">kind: KubeProxyConfiguration</span><br><span class="line">bindAddress: 0.0.0.0</span><br><span class="line">clientConnection:</span><br><span class="line">  acceptContentTypes: ""</span><br><span class="line">  burst: 10</span><br><span class="line">  contentType: application/vnd.kubernetes.protobuf</span><br><span class="line">  kubeconfig: /etc/kubernetes/kube-proxy.kubeconfig</span><br><span class="line">  qps: 5</span><br><span class="line"><span class="meta">#</span><span class="bash"> 集群中pod的CIDR范围，从这个范围以外发送到服务集群IP的流量将被伪装，从POD发送到外部LoadBalanceIP的流量将被定向到各自的集群IP</span></span><br><span class="line">clusterCIDR: "10.244.0.0/16"</span><br><span class="line">configSyncPeriod: 15m0s</span><br><span class="line">conntrack:</span><br><span class="line">  max: null</span><br><span class="line"><span class="meta">  #</span><span class="bash"> 每个核心最大能跟踪的NAT连接数，默认32768</span></span><br><span class="line">  maxPerCore: 32768</span><br><span class="line">  min: 131072</span><br><span class="line">  tcpCloseWaitTimeout: 1h0m0s</span><br><span class="line">  tcpEstablishedTimeout: 24h0m0s</span><br><span class="line">enableProfiling: false</span><br><span class="line">healthzBindAddress: 0.0.0.0:10256</span><br><span class="line">hostnameOverride: ""</span><br><span class="line">iptables:</span><br><span class="line"><span class="meta">  #</span><span class="bash"> SNAT所有通过服务集群ip发送的通信</span></span><br><span class="line">  masqueradeAll: false</span><br><span class="line">  masqueradeBit: 14</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">ipvs:</span><br><span class="line">  excludeCIDRs: null</span><br><span class="line">  minSyncPeriod: 0s</span><br><span class="line"><span class="meta">  #</span><span class="bash"> ipvs调度类型，默认是rr</span></span><br><span class="line">  scheduler: "rr"</span><br><span class="line">  syncPeriod: 30s</span><br><span class="line">metricsBindAddress: 127.0.0.1:10249</span><br><span class="line">mode: "ipvs"</span><br><span class="line">nodePortAddresses: null</span><br><span class="line">oomScoreAdj: -999</span><br><span class="line">portRange: ""</span><br><span class="line">resourceContainer: /kube-proxy</span><br><span class="line">udpIdleTimeout: 250ms</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="systemd服务文件-1"><a href="#systemd服务文件-1" class="headerlink" title="systemd服务文件"></a>systemd服务文件</h2><h3 id="kubelet-service"><a href="#kubelet-service" class="headerlink" title="kubelet.service"></a>kubelet.service</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kubelet.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">WorkingDirectory=/var/lib/kubelet</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kubelet.conf</span><br><span class="line">ExecStart=/usr/local/bin/kubelet \$KUBELET_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">KillMode=process</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="kube-proxy-service"><a href="#kube-proxy-service" class="headerlink" title="kube-proxy.service"></a>kube-proxy.service</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; kube-proxy.service &lt;&lt;EOF</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kube-Proxy Server</span><br><span class="line">Documentation=https://github.com/GoogleCloudPlatform/kubernetes</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/etc/kubernetes/kube-proxy.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> 这里启动时使用ipvsadm将TCP的keepalive时间设置，默认是900</span></span><br><span class="line">ExecStartPre=/usr/sbin/ipvsadm --set 900 120 300 </span><br><span class="line">ExecStart=/usr/local/bin/kube-proxy \$KUBE_PROXY_ARGS</span><br><span class="line">Restart=on-failure</span><br><span class="line">LimitNOFILE=65536</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h2 id="分发证书和kubeconfig文件"><a href="#分发证书和kubeconfig文件" class="headerlink" title="分发证书和kubeconfig文件"></a>分发证书和kubeconfig文件</h2><blockquote><ul><li>在<font color="red">k8s-m1</font>上操作</li><li>在worker节点建立对应的目录</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!WorkerArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    echo "--- 创建目录 ---"</span><br><span class="line">    ssh $NODE mkdir -p /opt/cni/bin \</span><br><span class="line">                       /etc/cni/net.d \</span><br><span class="line">                       /etc/kubernetes/pki \</span><br><span class="line">                       /etc/kubernetes/manifests \</span><br><span class="line">                       /var/lib/kubelet</span><br><span class="line">    rsync -avpt /root/pki/kube-proxy.kubeconfig \</span><br><span class="line">                /root/pki/bootstrap.kubeconfig \</span><br><span class="line">                $NODE:/etc/kubernetes/</span><br><span class="line">    rsync -avpt /root/pki/kube-ca.pem \</span><br><span class="line">                /root/pki/front-proxy-ca.pem \</span><br><span class="line">                $NODE:/etc/kubernetes/pki/</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="分发二进制文件-1"><a href="#分发二进制文件-1" class="headerlink" title="分发二进制文件"></a>分发二进制文件</h2><blockquote><ul><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!WorkerArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    echo "--- 分发kubernetes二进制文件 ---"</span><br><span class="line">    rsync -avpt /root/software/kubernetes/server/bin/kubelet \</span><br><span class="line">                /root/software/kubernetes/server/bin/kube-proxy \</span><br><span class="line">                $NODE:/usr/local/bin/</span><br><span class="line">    echo "--- 分发CNI-Plugins ---"</span><br><span class="line">    rsync -avpt /root/software/cni-plugins/* $NODE:/opt/cni/bin/</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="分发配置文件和服务文件"><a href="#分发配置文件和服务文件" class="headerlink" title="分发配置文件和服务文件"></a>分发配置文件和服务文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!WorkerArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    rsync -avpt kubelet.conf kubelet.config.file kube-proxy.conf kube-proxy.config.file $NODE:/etc/kubernetes/</span><br><span class="line">    rsync -avpt kubelet.service kube-proxy.service $NODE:/usr/lib/systemd/system/</span><br><span class="line">    ssh $NODE systemctl daemon-reload</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">for NODE in "$&#123;!WorkerArray[@]&#125;";do</span><br><span class="line">    echo "--- $NODE ---"</span><br><span class="line">    ssh $NODE systemctl enable --now docker.service kubelet.service kube-proxy.service</span><br><span class="line">done</span><br></pre></td></tr></table></figure><h2 id="获取节点信息"><a href="#获取节点信息" class="headerlink" title="获取节点信息"></a>获取节点信息</h2><blockquote><ul><li>此时由于未按照网络插件，所以节点状态为<font color="red"><code>NotReady</code></font></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl get node -o wide</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">NAME      STATUS     ROLES     AGE       VERSION   INTERNAL-IP     EXTERNAL-IP   OS-IMAGE                KERNEL-VERSION              CONTAINER-RUNTIME</span><br><span class="line">k8s-m1    NotReady   node      12s       v1.11.5   172.16.80.201   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-957.1.3.el7.x86_64   docker://18.3.1</span><br><span class="line">k8s-m2    NotReady   node      12s       v1.11.5   172.16.80.202   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-957.1.3.el7.x86_64   docker://18.3.1</span><br><span class="line">k8s-m3    NotReady   node      12s       v1.11.5   172.16.80.203   &lt;none&gt;        CentOS Linux 7 (Core)   3.10.0-957.1.3.el7.x86_64   docker://18.3.1</span><br></pre></td></tr></table></figure><h1 id="kubernetes-Core-Addons"><a href="#kubernetes-Core-Addons" class="headerlink" title="kubernetes Core Addons"></a>kubernetes Core Addons</h1><h2 id="网络组件部署（二选其一）"><a href="#网络组件部署（二选其一）" class="headerlink" title="网络组件部署（二选其一）"></a>网络组件部署（二选其一）</h2><blockquote><ul><li>只要符合CNI规范的网络组件都可以给kubernetes使用</li><li>网络组件清单可以在这里看到<a href="https://kubernetes.io/docs/concepts/cluster-administration/addons/" target="_blank" rel="noopener">Network Plugins</a></li><li>这里只列举<code>kube-flannel</code>和<code>calico</code>，flannel和calico的区别可以自己去找资料</li><li><font color="red">网络组件只能选一个来部署</font></li><li>本文使用<code>kube-flannel</code>部署网络组件，<code>calico</code>已测试可用</li><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><h3 id="创建工作目录-2"><a href="#创建工作目录-2" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/network-plugin/&#123;kube-flannel,calico&#125;</span><br></pre></td></tr></table></figure><h3 id="kube-flannel"><a href="#kube-flannel" class="headerlink" title="kube-flannel"></a>kube-flannel</h3><h4 id="说明-3"><a href="#说明-3" class="headerlink" title="说明"></a>说明</h4><blockquote><ul><li>kube-flannel基于VXLAN的方式创建容器二层网络，使用端口<font color="red"><code>8472/UDP</code></font>通信</li><li>flannel 第一次启动时，从 etcd 获取 Pod 网段信息，为本节点分配一个未使用的 /24 段地址，然后创建 flannel.1（也可能是其它名称，如 flannel1 等） 接口。</li><li>官方提供yaml文件部署为<code>DeamonSet</code></li><li>若需要使用<code>NetworkPolicy</code>功能，可以关注这个项目<a href="https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/flannel" target="_blank" rel="noopener">canal</a></li></ul></blockquote><h4 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h4><p><img src="https://jimmysong.io/kubernetes-handbook/images/flannel-networking.png" alt=""></p><h4 id="切换工作目录-2"><a href="#切换工作目录-2" class="headerlink" title="切换工作目录"></a>切换工作目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/network-plugin/kube-flannel</span><br></pre></td></tr></table></figure><h4 id="下载yaml文件"><a href="#下载yaml文件" class="headerlink" title="下载yaml文件"></a>下载yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml</span><br></pre></td></tr></table></figure><blockquote><ul><li><p>官方yaml文件包含多个平台的daemonset，包括amd64、arm64、arm、ppc64le、s390x</p></li><li><p>这里以amd64作为例子，其他的可以自行根据需要修改或者直接删除不需要的daemonset</p></li><li><p>官方yaml文件已经配置好容器网络为<code>10.244.0.0/16</code>，这里需要跟<code>kube-controller-manager.conf</code>里面的<code>--cluster-cidr</code>匹配</p></li><li><p>如果在<code>kube-controller-manager.conf</code>里面把<code>--cluster-cidr</code>改成了其他地址段，例如<code>192.168.0.0/16</code>，用以下命令替换<code>kube-flannel.yaml</code>相应的字段</p></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -e 's,"Network": "10.244.0.0/16","Network": "192.168.0.0/16," -i kube-flannel.yml</span><br></pre></td></tr></table></figure><blockquote><ul><li><p>如果服务器有多个网卡，需要指定网卡用于flannel通信，以网卡ens33为例</p><ul><li>在<code>args</code>下面添加一行<font color="red"><code>- --iface=ens33</code></font></li></ul></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">containers:</span><br><span class="line">- name: kube-flannel</span><br><span class="line">  image: quay.io/coreos/flannel:v0.10.0-amd64</span><br><span class="line">  command:</span><br><span class="line">  - /opt/bin/flanneld</span><br><span class="line">  args:</span><br><span class="line">  - --ip-masq</span><br><span class="line">  - --kube-subnet-mgr</span><br><span class="line">  - --iface=ens33</span><br></pre></td></tr></table></figure><h4 id="修改backend"><a href="#修改backend" class="headerlink" title="修改backend"></a>修改backend</h4><blockquote><ul><li>flannel支持多种后端实现，可选值为<code>VXLAN</code>、<code>host-gw</code>、<code>UDP</code></li><li>从性能上，<code>host-gw</code>是最好的，<code>VXLAN</code>和<code>UDP</code>次之</li><li>默认值是<code>VXLAN</code>，这里以修改为<code>host-gw</code>为例，位置大概在75行左右</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">net-conf.json:</span> <span class="string">|</span></span><br><span class="line"><span class="string">  &#123;</span></span><br><span class="line"><span class="string">    "Network": "10.244.0.0/16",</span></span><br><span class="line"><span class="string">    "Backend": &#123;</span></span><br><span class="line"><span class="string">      "Type": "host-gw"</span></span><br><span class="line"><span class="string">    &#125;</span></span><br><span class="line"><span class="string">  &#125;</span></span><br></pre></td></tr></table></figure><h4 id="部署kube-flannel"><a href="#部署kube-flannel" class="headerlink" title="部署kube-flannel"></a>部署kube-flannel</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f kube-flannel.yml</span><br></pre></td></tr></table></figure><h4 id="检查部署情况"><a href="#检查部署情况" class="headerlink" title="检查部署情况"></a>检查部署情况</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get pod -l k8s-app=flannel</span><br><span class="line">NAME                    READY     STATUS    RESTARTS   AGE</span><br><span class="line">kube-flannel-ds-27jwl   2/2       Running   0          59s</span><br><span class="line">kube-flannel-ds-4fgv6   2/2       Running   0          59s</span><br><span class="line">kube-flannel-ds-mvrt7   2/2       Running   0          59s</span><br></pre></td></tr></table></figure><blockquote><ul><li>如果等很久都没Running，可能是quay.io对你来说太慢了</li><li>可以替换一下镜像，重新apply</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed -e 's,quay.io/coreos/,zhangguanzhang/quay.io.coreos.,g' -i kube-flannel.yml</span><br><span class="line">kubectl apply -f kube-flannel.yaml</span><br></pre></td></tr></table></figure><h3 id="Calico"><a href="#Calico" class="headerlink" title="Calico"></a>Calico</h3><h4 id="说明-4"><a href="#说明-4" class="headerlink" title="说明"></a>说明</h4><blockquote><ul><li>Calico 是一款纯 Layer 3 的网络，节点之间基于BGP协议来通信。</li><li>这里以<code>calico-v3.4.0</code>来作为示例</li><li><a href="https://docs.projectcalico.org/v3.3/getting-started/kubernetes/installation/calico" target="_blank" rel="noopener">部署文档</a></li></ul></blockquote><h4 id="架构图-1"><a href="#架构图-1" class="headerlink" title="架构图"></a>架构图</h4><p><img src="https://docs.projectcalico.org/images/calico-arch-gen-v3.2.svg" alt=""></p><h4 id="切换工作目录-3"><a href="#切换工作目录-3" class="headerlink" title="切换工作目录"></a>切换工作目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/network-plugin/calico</span><br></pre></td></tr></table></figure><h4 id="下载yaml文件-1"><a href="#下载yaml文件-1" class="headerlink" title="下载yaml文件"></a>下载yaml文件</h4><blockquote><ul><li>这里使用kubernetes API来保存网络信息</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://docs.projectcalico.org/v3.4/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calico-networking/1.7/calico.yaml</span><br><span class="line">wget https://docs.projectcalico.org/v3.4/getting-started/kubernetes/installation/hosted/kubernetes-datastore/calicoctl.yaml</span><br></pre></td></tr></table></figure><blockquote><ul><li>官方yaml文件默认配置容器网络为<code>192.168.0.0/16</code>，这里需要跟<code>kube-controller-manager.conf</code>里面的<code>--cluster-cidr</code>匹配，需要替换相应字段</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -e "s,192.168.0.0/16,$&#123;POD_NET_CIDR&#125;,g" -i calico.yaml</span><br></pre></td></tr></table></figure><blockquote><ul><li>官方yaml文件定义calicoctl为Pod，而不是deployment，所以需要调整一下</li><li>修改<code>kind: Pod</code>为<code>kind: Deployment</code>并补充其他字段</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Deployment</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">1</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      k8s-app:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">      namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        k8s-app:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      tolerations:</span></span><br><span class="line"><span class="attr">      - effect:</span> <span class="string">NoSchedule</span></span><br><span class="line"><span class="attr">        key:</span> <span class="string">node-role.kubernetes.io/master</span></span><br><span class="line"><span class="attr">      - effect:</span> <span class="string">NoSchedule</span></span><br><span class="line"><span class="attr">        key:</span> <span class="string">node.cloudprovider.kubernetes.io/uninitialized</span></span><br><span class="line"><span class="attr">        value:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">      hostNetwork:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">      serviceAccountName:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">calicoctl</span></span><br><span class="line"><span class="attr">        image:</span> <span class="string">quay.io/calico/ctl:v3.4.0</span></span><br><span class="line"><span class="attr">        command:</span> <span class="string">["/bin/sh",</span> <span class="string">"-c"</span><span class="string">,</span> <span class="string">"while true; do sleep 3600; done"</span><span class="string">]</span></span><br><span class="line"><span class="attr">        tty:</span> <span class="literal">true</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">DATASTORE_TYPE</span></span><br><span class="line"><span class="attr">          value:</span> <span class="string">kubernetes</span></span><br></pre></td></tr></table></figure><h4 id="部署Calico"><a href="#部署Calico" class="headerlink" title="部署Calico"></a>部署Calico</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f /root/yaml/network-plugin/calico/</span><br></pre></td></tr></table></figure><h4 id="检查部署情况-1"><a href="#检查部署情况-1" class="headerlink" title="检查部署情况"></a>检查部署情况</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get pod -l k8s-app=calico-node</span><br><span class="line">NAME                READY     STATUS    RESTARTS   AGE</span><br><span class="line">calico-node-fjcj4   2/2       Running   0          6m</span><br><span class="line">calico-node-tzppt   2/2       Running   0          6m</span><br><span class="line">calico-node-zdq64   2/2       Running   0          6m</span><br><span class="line"></span><br><span class="line">kubectl get pod -n kube-system -l k8s-app=calicoctl</span><br><span class="line">NAME                         READY     STATUS    RESTARTS   AGE</span><br><span class="line">calicoctl-58df8955f6-sp8q9   0/1       Running   0          38s</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">kubectl -n kube-system exec -it calicoctl-58df8955f6-sp8q9 -- /calicoctl get node -o wide</span><br><span class="line">NAME     ASN         IPV4               IPV6   </span><br><span class="line">k8s-m1   (unknown)   172.16.80.201/24          </span><br><span class="line">k8s-m2   (unknown)   172.16.80.202/24          </span><br><span class="line">k8s-m3   (unknown)   172.16.80.203/24</span><br><span class="line"></span><br><span class="line">kubectl -n kube-system exec -it calicoctl-58df8955f6-sp8q9 -- /calicoctl get profiles -o wide</span><br><span class="line">NAME              LABELS   </span><br><span class="line">kns.default       map[]    </span><br><span class="line">kns.kube-public   map[]    </span><br><span class="line">kns.kube-system   map[]</span><br></pre></td></tr></table></figure><blockquote><ul><li>如果镜像pull不下来，可以替换一下</li><li>替换完重新apply</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sed -e 's,quay.io/calico/,zhangguanzhang/quay.io.calico.,g' -i *yaml</span><br><span class="line">kubectl apply -f .</span><br></pre></td></tr></table></figure><h3 id="检查节点状态"><a href="#检查节点状态" class="headerlink" title="检查节点状态"></a>检查节点状态</h3><blockquote><ul><li>网络组件部署完成之后，可以看到node状态已经为<code>Ready</code></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">kubectl get node </span><br><span class="line">NAME      STATUS    ROLES     AGE       VERSION</span><br><span class="line">k8s-m1    Ready     node      1d        v1.11.5</span><br><span class="line">k8s-m2    Ready     node      1d        v1.11.5</span><br><span class="line">k8s-m3    Ready     node      1d        v1.11.5</span><br></pre></td></tr></table></figure><h2 id="服务发现组件部署"><a href="#服务发现组件部署" class="headerlink" title="服务发现组件部署"></a>服务发现组件部署</h2><blockquote><ul><li>kubernetes从v1.11之后，已经使用CoreDNS取代原来的KUBE DNS作为服务发现的组件</li><li>CoreDNS 是由 CNCF 维护的开源 DNS 方案，前身是 SkyDNS</li><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><h3 id="创建工作目录-3"><a href="#创建工作目录-3" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/coredns</span><br></pre></td></tr></table></figure><blockquote><ul><li>切换工作目录</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/coredns</span><br></pre></td></tr></table></figure><h3 id="CoreDNS"><a href="#CoreDNS" class="headerlink" title="CoreDNS"></a>CoreDNS</h3><h4 id="创建yaml文件-1"><a href="#创建yaml文件-1" class="headerlink" title="创建yaml文件"></a>创建yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; coredns.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - ""</span><br><span class="line">  resources:</span><br><span class="line">  - endpoints</span><br><span class="line">  - services</span><br><span class="line">  - pods</span><br><span class="line">  - namespaces</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: "true"</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:coredns</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  Corefile: |</span><br><span class="line">    .:53 &#123;</span><br><span class="line">        errors</span><br><span class="line">        log</span><br><span class="line">        health</span><br><span class="line">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span><br><span class="line">          pods insecure</span><br><span class="line">          upstream</span><br><span class="line">          fallthrough in-addr.arpa ip6.arpa</span><br><span class="line">        &#125;</span><br><span class="line">        prometheus :9153</span><br><span class="line">        proxy . /etc/resolv.conf</span><br><span class="line">        cache 30</span><br><span class="line">        reload</span><br><span class="line">        loadbalance</span><br><span class="line">    &#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/name: "CoreDNS"</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-dns</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io/critical-pod: ""</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kube-dns</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: coredns</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      # 使用podAntiAffinity</span><br><span class="line">      # CoreDNS的Pod不会被调度到同一台宿主机</span><br><span class="line">      affinity:</span><br><span class="line">        podAntiAffinity: </span><br><span class="line">          preferredDuringSchedulingIgnoredDuringExecution:</span><br><span class="line">          - weight: 100</span><br><span class="line">            podAffinityTerm:</span><br><span class="line">              labelSelector:</span><br><span class="line">                matchExpressions:</span><br><span class="line">                - key: k8s-app </span><br><span class="line">                  operator: In </span><br><span class="line">                  values:</span><br><span class="line">                  - kube-dns</span><br><span class="line">              topologyKey: kubernetes.io/hostname</span><br><span class="line">      tolerations:</span><br><span class="line">      - key: CriticalAddonsOnly</span><br><span class="line">        operator: Exists</span><br><span class="line">      - effect: NoSchedule</span><br><span class="line">        key: node-role.kubernetes.io/master</span><br><span class="line">      containers:</span><br><span class="line">      - name: coredns</span><br><span class="line">        image: gcrxio/coredns:1.2.6</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        args: [ "-conf", "/etc/coredns/Corefile" ]</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /health</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 60</span><br><span class="line">          timeoutSeconds: 10</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          failureThreshold: 5</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns</span><br><span class="line">          protocol: UDP</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns-tcp</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 9153</span><br><span class="line">          name: metrics</span><br><span class="line">          protocol: TCP</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 200Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 70Mi</span><br><span class="line">        securityContext:</span><br><span class="line">          allowPrivilegeEscalation: false</span><br><span class="line">          capabilities:</span><br><span class="line">            add:</span><br><span class="line">            - NET_BIND_SERVICE</span><br><span class="line">            drop:</span><br><span class="line">            - all</span><br><span class="line">          readOnlyRootFilesystem: true</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          mountPath: /etc/coredns</span><br><span class="line">          readOnly: true</span><br><span class="line">        - name: host-time</span><br><span class="line">          mountPath: /etc/localtime</span><br><span class="line">      dnsPolicy: Default</span><br><span class="line">      volumes:</span><br><span class="line">      - name: host-time</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /etc/localtime</span><br><span class="line">      - name: config-volume</span><br><span class="line">        configMap:</span><br><span class="line">          name: coredns</span><br><span class="line">          items:</span><br><span class="line">          - key: Corefile</span><br><span class="line">            path: Corefile</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-dns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    prometheus.io/port: "9153"</span><br><span class="line">    prometheus.io/scrape: "true"</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/cluster-service: "true"</span><br><span class="line">    kubernetes.io/name: "CoreDNS"</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">  clusterIP: $&#123;POD_DNS_SERVER_IP&#125;</span><br><span class="line">  ports:</span><br><span class="line">  - name: dns</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: UDP</span><br><span class="line">  - name: dns-tcp</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: TCP</span><br><span class="line">  - name: metrics</span><br><span class="line">    port: 9153</span><br><span class="line">    protocol: TCP</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h4 id="修改yaml文件"><a href="#修改yaml文件" class="headerlink" title="修改yaml文件"></a>修改yaml文件</h4><blockquote><ul><li>yaml文件里面定义了<code>clusterIP</code>这里需要与<code>kubelet.config.file</code>里面定义的<code>cluster-dns</code>一致</li><li>如果kubelet.conf里面的<code>--cluster-dns</code>改成别的，例如<code>x.x.x.x</code>，这里也要做相应变动，不然Pod找不到DNS，无法正常工作</li><li>这里定义静态的hosts解析，这样Pod可以通过hostname来访问到各节点主机</li><li>用下面的命令根据<code>HostArray</code>的信息生成静态的hosts解析</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sed -e '57r '&lt;(\</span><br><span class="line">    echo '        hosts &#123;'; \</span><br><span class="line">    for NODE in "$&#123;!HostArray[@]&#125;";do \</span><br><span class="line">        echo "          $&#123;HostArray[$NODE]&#125; $NODE"; \</span><br><span class="line">    done;\</span><br><span class="line">    echo '          fallthrough'; \</span><br><span class="line">    echo '        &#125;';) \</span><br><span class="line">-i coredns.yaml</span><br></pre></td></tr></table></figure><blockquote><ul><li>上面的命令的作用是，通过<code>HostArray</code>的信息生成hosts解析配置，顺序是打乱的，可以手工调整顺序</li><li>也可以手动修改<code>coredns.yaml</code>文件来添加对应字段</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ConfigMap</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">coredns</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">data:</span></span><br><span class="line"><span class="attr">  Corefile:</span> <span class="string">|</span></span><br><span class="line"><span class="string">    .:53 &#123;</span></span><br><span class="line"><span class="string">        errors</span></span><br><span class="line"><span class="string">        log</span></span><br><span class="line"><span class="string">        health</span></span><br><span class="line"><span class="string">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span></span><br><span class="line"><span class="string">          pods insecure</span></span><br><span class="line"><span class="string">          upstream</span></span><br><span class="line"><span class="string">          fallthrough in-addr.arpa ip6.arpa</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        hosts &#123;</span></span><br><span class="line"><span class="string">          172.16.80.202 k8s-m2</span></span><br><span class="line"><span class="string">          172.16.80.203 k8s-m3</span></span><br><span class="line"><span class="string">          172.16.80.201 k8s-m1</span></span><br><span class="line"><span class="string">          fallthrough in-addr.arpa ip6.arpa</span></span><br><span class="line"><span class="string">        &#125;</span></span><br><span class="line"><span class="string">        prometheus :9153</span></span><br><span class="line"><span class="string">        proxy . /etc/resolv.conf</span></span><br><span class="line"><span class="string">        cache 30</span></span><br><span class="line"><span class="string">        reload</span></span><br><span class="line"><span class="string">        loadbalance</span></span><br><span class="line"><span class="string">    &#125;</span></span><br></pre></td></tr></table></figure><h4 id="部署CoreDNS"><a href="#部署CoreDNS" class="headerlink" title="部署CoreDNS"></a>部署CoreDNS</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f coredns.yaml</span><br></pre></td></tr></table></figure><h4 id="检查部署状态"><a href="#检查部署状态" class="headerlink" title="检查部署状态"></a>检查部署状态</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get pod -l k8s-app=kube-dns</span><br><span class="line">NAME                       READY     STATUS    RESTARTS   AGE</span><br><span class="line">coredns-5566c96697-6gzzc   1/1       Running   0          45s</span><br><span class="line">coredns-5566c96697-q5slk   1/1       Running   0          45s</span><br></pre></td></tr></table></figure><h3 id="验证集群DNS服务"><a href="#验证集群DNS服务" class="headerlink" title="验证集群DNS服务"></a>验证集群DNS服务</h3><blockquote><ul><li>创建一个deployment测试DNS解析</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 创建一个基于busybox的deployment</span></span><br><span class="line">cat &gt; /root/yaml/busybox-deployment.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    app: busybox</span><br><span class="line">  name: busybox</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  replicas: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      app: busybox</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        app: busybox</span><br><span class="line">    spec:</span><br><span class="line">      containers:</span><br><span class="line">      - name: busybox</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        image: busybox:1.26</span><br><span class="line">        command:</span><br><span class="line">        - sleep</span><br><span class="line">        - "3600"</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 基于文件创建deployment</span></span><br><span class="line">kubectl apply -f /root/yaml/busybox-deployment.yaml</span><br></pre></td></tr></table></figure><blockquote><ul><li>检查deployment部署情况</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pod</span><br><span class="line">NAME                       READY     STATUS    RESTARTS   AGE</span><br><span class="line">busybox-7b9bfb5658-872gj   1/1       Running   0          6s</span><br></pre></td></tr></table></figure><blockquote><ul><li>验证集群DNS解析</li><li>上一个命令获取到pod名字为<code>busybox-7b9bfb5658-872gj</code></li><li>通过kubectl命令连接到Pod运行<code>nslookup</code>命令测试使用域名来访问kube-apiserver和各节点主机</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">echo "--- 通过CoreDNS访问kubernetes ---"</span><br><span class="line">kubectl exec -it busybox-7b9bfb5658-4cz94 -- nslookup kubernetes</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line">Name:      kubernetes</span><br><span class="line">Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">echo "--- 通过CoreDNS访问k8s-m1 ---"</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">kubectl exec -it busybox-7b9bfb5658-4cz94 -- nslookup k8s-m1</span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line">Name:      k8s-m1</span><br><span class="line">Address 1: 172.16.80.201 k8s-m1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">echo "--- 通过CoreDNS访问k8s-m2 ---"</span><br><span class="line">kubectl exec -it busybox-7b9bfb5658-4cz94 -- nslookup k8s-m2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line">Name:      k8s-n2</span><br><span class="line">Address 1: 172.16.80.202 k8s-m2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">echo "--- 通过CoreDNS访问并不存在的k8s-n3 ---"</span><br><span class="line">kubectl exec -it busybox-7b9bfb5658-4cz94 -- nslookup k8s-n3</span><br><span class="line"><span class="meta">#</span><span class="bash"> 示例输出</span></span><br><span class="line">Server:    10.96.0.10</span><br><span class="line">Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local</span><br><span class="line">nslookup: can't resolve 'k8s-n3'</span><br></pre></td></tr></table></figure><h2 id="Metrics-Server"><a href="#Metrics-Server" class="headerlink" title="Metrics Server"></a>Metrics Server</h2><blockquote><ul><li><a href="https://github.com/kubernetes-incubator/metrics-server" target="_blank" rel="noopener">Metrics Server</a><br>是实现了 Metrics API 的元件,其目标是取代 Heapster 作位 Pod 与 Node 提供资源的 Usage<br>metrics,该元件会从每个 Kubernetes 节点上的 Kubelet 所公开的 Summary API 中收集 Metrics</li><li>Horizontal Pod Autoscaler（HPA）控制器用于实现基于CPU使用率进行自动Pod伸缩的功能。</li><li>HPA控制器基于Master的kube-controller-manager服务启动参数–horizontal-pod-autoscaler-sync-period定义是时长（默认30秒）,周期性监控目标Pod的CPU使用率,并在满足条件时对ReplicationController或Deployment中的Pod副本数进行调整,以符合用户定义的平均Pod<br>CPU使用率。</li><li>在新版本的kubernetes中 Pod CPU使用率不在来源于heapster,而是来自于metrics-server</li><li>官网原话是 The –horizontal-pod-autoscaler-use-rest-clients is true or unset. Setting this to false switches to Heapster-based autoscaling, which is deprecated.</li><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><h3 id="额外参数"><a href="#额外参数" class="headerlink" title="额外参数"></a>额外参数</h3><blockquote><ul><li>设置kube-apiserver参数，这里在配置kube-apiserver阶段已经加进去了</li><li>front-proxy证书，在证书生成阶段已经完成且已分发</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">--requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem</span><br><span class="line">--proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.pem</span><br><span class="line">--proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client-key.pem</span><br><span class="line">--requestheader-allowed-names=aggregator</span><br><span class="line">--requestheader-group-headers=X-Remote-Group</span><br><span class="line">--requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class="line">--requestheader-username-headers=X-Remote-User</span><br></pre></td></tr></table></figure><h3 id="创建工作目录-4"><a href="#创建工作目录-4" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/metrics-server</span><br></pre></td></tr></table></figure><h3 id="切换工作目录-4"><a href="#切换工作目录-4" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/metrics-server</span><br></pre></td></tr></table></figure><h3 id="下载yaml文件-2"><a href="#下载yaml文件-2" class="headerlink" title="下载yaml文件"></a>下载yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes-incubator/metrics-server/master/deploy/1.8%2B/aggregated-metrics-reader.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes-incubator/metrics-server/master/deploy/1.8%2B/auth-delegator.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes-incubator/metrics-server/master/deploy/1.8%2B/auth-reader.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes-incubator/metrics-server/master/deploy/1.8%2B/metrics-apiservice.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes-incubator/metrics-server/master/deploy/1.8%2B/metrics-server-service.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes-incubator/metrics-server/master/deploy/1.8%2B/resource-reader.yaml</span><br></pre></td></tr></table></figure><h3 id="创建metrics-server-deployment-yaml"><a href="#创建metrics-server-deployment-yaml" class="headerlink" title="创建metrics-server-deployment.yaml"></a>创建metrics-server-deployment.yaml</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; metrics-server-deployment.yaml &lt;&lt;EOF</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: metrics-server</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: metrics-server</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: metrics-server</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      name: metrics-server</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: metrics-server</span><br><span class="line">    spec:</span><br><span class="line">      serviceAccountName: metrics-server</span><br><span class="line">      volumes:</span><br><span class="line">      # mount in tmp so we can safely use from-scratch images and/or read-only containers</span><br><span class="line">      - name: ca-ssl</span><br><span class="line">        hostPath:</span><br><span class="line">          path: /etc/kubernetes/pki</span><br><span class="line">      containers:</span><br><span class="line">      - name: metrics-server</span><br><span class="line">        image: gcrxio/metrics-server-amd64:v0.3.1</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        command:</span><br><span class="line">        - /metrics-server</span><br><span class="line">        - --metric-resolution=30s</span><br><span class="line">        - --kubelet-port=10250</span><br><span class="line">        - --kubelet-preferred-address-types=InternalDNS,InternalIP,ExternalDNS,ExternalIP,Hostname</span><br><span class="line">        - --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.pem</span><br><span class="line">        - --requestheader-username-headers=X-Remote-User </span><br><span class="line">        - --requestheader-group-headers=X-Remote-Group </span><br><span class="line">        - --requestheader-extra-headers-prefix=X-Remote-Extra-</span><br><span class="line">        - --kubelet-insecure-tls</span><br><span class="line">        - -v=2</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: ca-ssl</span><br><span class="line">          mountPath: /etc/kubernetes/pki</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure><h3 id="部署metrics-server"><a href="#部署metrics-server" class="headerlink" title="部署metrics-server"></a>部署metrics-server</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f .</span><br></pre></td></tr></table></figure><h3 id="查看pod状态"><a href="#查看pod状态" class="headerlink" title="查看pod状态"></a>查看pod状态</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get pod -l k8s-app=metrics-server</span><br><span class="line">NAME                                  READY     STATUS    RESTARTS   AGE</span><br><span class="line">pod/metrics-server-86bd9d7667-5hbn6   1/1       Running   0          1m</span><br></pre></td></tr></table></figure><h3 id="验证metrics"><a href="#验证metrics" class="headerlink" title="验证metrics"></a>验证metrics</h3><blockquote><ul><li>完成后,等待一段时间(约 30s - 1m)收集 Metrics</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 请求metrics api的结果</span></span><br><span class="line">kubectl get --raw /apis/metrics.k8s.io/v1beta1</span><br><span class="line">&#123;"kind":"APIResourceList","apiVersion":"v1","groupVersion":"metrics.k8s.io/v1beta1","resources":[&#123;"name":"nodes","singularName":"","namespaced":false,"kind":"NodeMetrics","verbs":["get","list"]&#125;,&#123;"name":"pods","singularName":"","namespaced":true,"kind":"PodMetrics","verbs":["get","list"]&#125;]&#125;</span><br><span class="line"></span><br><span class="line">kubectl get apiservice|grep metrics</span><br><span class="line">v1beta1.metrics.k8s.io                  2018-12-09T08:17:26Z</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 获取节点性能信息</span></span><br><span class="line">kubectl top node</span><br><span class="line">NAME      CPU(cores)   CPU%      MEMORY(bytes)   MEMORY%   </span><br><span class="line">k8s-m1    113m         2%        1080Mi          14%       </span><br><span class="line">k8s-m2    133m         3%        1086Mi          14%       </span><br><span class="line">k8s-m3    100m         2%        1029Mi          13%</span><br></pre></td></tr></table></figure><h1 id="至此集群已具备基本功能"><a href="#至此集群已具备基本功能" class="headerlink" title="至此集群已具备基本功能"></a>至此集群已具备基本功能</h1><blockquote><p>下面的Extra Addons就是一些额外的功能</p></blockquote><h1 id="kubernetes-Extra-Addons"><a href="#kubernetes-Extra-Addons" class="headerlink" title="kubernetes Extra Addons"></a>kubernetes Extra Addons</h1><h2 id="Dashboard"><a href="#Dashboard" class="headerlink" title="Dashboard"></a>Dashboard</h2><blockquote><ul><li>Dashboard 是kubernetes社区提供的GUI界面，用于图形化管理kubernetes集群，同时可以看到资源报表。</li><li>官方提供yaml文件直接部署，但是需要更改<code>image</code>以便国内部署</li><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><h3 id="创建工作目录-5"><a href="#创建工作目录-5" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/kubernetes-dashboard</span><br></pre></td></tr></table></figure><h3 id="切换工作目录-5"><a href="#切换工作目录-5" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/kubernetes-dashboard</span><br></pre></td></tr></table></figure><h3 id="获取yaml文件"><a href="#获取yaml文件" class="headerlink" title="获取yaml文件"></a>获取yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.1/src/deploy/recommended/kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure><h3 id="修改镜像地址"><a href="#修改镜像地址" class="headerlink" title="修改镜像地址"></a>修改镜像地址</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -e 's,k8s.gcr.io/kubernetes-dashboard-amd64,gcrxio/kubernetes-dashboard-amd64,g' -i kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure><h3 id="创建kubernetes-Dashboard"><a href="#创建kubernetes-Dashboard" class="headerlink" title="创建kubernetes-Dashboard"></a>创建kubernetes-Dashboard</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f kubernetes-dashboard.yaml</span><br></pre></td></tr></table></figure><h3 id="创建ServiceAccount-RBAC"><a href="#创建ServiceAccount-RBAC" class="headerlink" title="创建ServiceAccount RBAC"></a>创建ServiceAccount RBAC</h3><blockquote><ul><li>官方的yaml文件，ServiceAccount绑定的RBAC权限很低，很多资源无法查看</li><li>需要创建一个用于管理全局的ServiceAccount</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; cluster-admin.yaml &lt;&lt;EOF</span><br><span class="line">---</span><br><span class="line"><span class="meta">#</span><span class="bash"> 在kube-system中创建名为admin-user的ServiceAccount</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"><span class="meta">#</span><span class="bash"> 将admin-user和cluster-admin绑定在一起</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> cluster-admin是kubernetes内置的clusterrole，具有集群管理员权限</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 其他内置的clusterrole可以通过kubectl get clusterrole查看</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: admin-user</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: admin-user</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl apply -f cluster-admin.yaml</span><br></pre></td></tr></table></figure><h3 id="获取ServiceAccount的Token"><a href="#获取ServiceAccount的Token" class="headerlink" title="获取ServiceAccount的Token"></a>获取ServiceAccount的Token</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system describe secret $(kubectl -n kube-system get secret | grep admin-user | awk '&#123;print $1&#125;')</span><br></pre></td></tr></table></figure><h3 id="查看部署情况"><a href="#查看部署情况" class="headerlink" title="查看部署情况"></a>查看部署情况</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl get all -n kube-system --selector k8s-app=kubernetes-dashboard</span><br></pre></td></tr></table></figure><h3 id="访问Dashboard"><a href="#访问Dashboard" class="headerlink" title="访问Dashboard"></a>访问Dashboard</h3><blockquote><ul><li>kubernetes-dashborad的svc默认是<code>clusterIP</code>，需要修改为<code>nodePort</code>才能被外部访问</li><li>随机分配<code>NodePort</code>，分配范围由<code>kube-apiserver</code>的<code>--service-node-port-range</code>参数指定</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl patch -n kube-system svc kubernetes-dashboard -p '&#123;"spec":&#123;"type":"NodePort"&#125;&#125;'</span><br></pre></td></tr></table></figure><blockquote><ul><li>修改完之后，通过以下命令获取访问kubernetes-Dashboard的端口</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get svc --selector k8s-app=kubernetes-dashboard</span><br><span class="line">NAME                   TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)         AGE</span><br><span class="line">kubernetes-dashboard   NodePort   10.106.183.192   &lt;none&gt;        443:30216/TCP   12s</span><br></pre></td></tr></table></figure><blockquote><ul><li>可以看到已经将节点的<code>30216</code>端口暴露出来</li></ul></blockquote><blockquote><ul><li><p>IP地址不固定，只要运行了kube-proxy组件，都会在节点上添加<code>30216</code>端口规则用于转发请求到Pod</p><p><a href="https://172.16.80.200:30216" target="_blank" rel="noopener">https://172.16.80.200:30216</a></p><p><a href="https://172.16.80.201:30216" target="_blank" rel="noopener">https://172.16.80.201:30216</a></p><p><a href="https://172.16.80.202:30216" target="_blank" rel="noopener">https://172.16.80.202:30216</a></p><p><a href="https://172.16.80.203:30216" target="_blank" rel="noopener">https://172.16.80.203:30216</a></p></li><li><p>登录Dashboard，上面已经获取了token，这里只需要把token的值填入输入框，点击<code>SIGN IN</code>即可登录</p></li></ul></blockquote><h3 id="Dashboard-UI预览图"><a href="#Dashboard-UI预览图" class="headerlink" title="Dashboard UI预览图"></a>Dashboard UI预览图</h3><p><img src="https://raw.githubusercontent.com/kubernetes/dashboard/v1.10.0/docs/dashboard-ui.png" alt=""></p><h2 id="Ingress-Controller"><a href="#Ingress-Controller" class="headerlink" title="Ingress Controller"></a>Ingress Controller</h2><blockquote><ul><li>Ingress 是 Kubernetes 中的一个抽象资源，其功能是通过 Web Server 的 Virtual Host<br>概念以域名(Domain Name)方式转发到內部 Service，这避免了使用 Service 中的 NodePort 与<br>LoadBalancer 类型所带來的限制(如 Port 数量上限)，而实现 Ingress 功能则是通过 Ingress Controller<br>来达成，它会负责监听 Kubernetes API 中的 Ingress 与 Service 资源，并在发生资源变化时，根据资源预期的结果来设置 Web Server。</li><li>Ingress Controller 有许多实现可以选择，这里只是列举一小部分<ul><li><a href="https://github.com/kubernetes/ingress-nginx" target="_blank" rel="noopener">Ingress NGINX</a>：Kubernetes 官方维护的方案，<font color="red">本次安装使用此方案</font></li><li><a href="https://github.com/nginxinc/kubernetes-ingress" target="_blank" rel="noopener">kubernetes-ingress</a>：由nginx社区维护的方案，使用社区版nginx和nginx-plus</li><li><a href="https://github.com/containous/traefik" target="_blank" rel="noopener">treafik</a>：一款开源的反向代理与负载均衡工具。它最大的优点是能够与常见的微服务系统直接整合，可以实现自动化动态配置</li></ul></li><li>在<font color="red">k8s-m1</font>上操作</li></ul></blockquote><h3 id="创建工作目录-6"><a href="#创建工作目录-6" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/ingress/ingress-nginx</span><br></pre></td></tr></table></figure><h3 id="切换工作目录-6"><a href="#切换工作目录-6" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/ingress/ingress-nginx</span><br></pre></td></tr></table></figure><h3 id="下载yaml文件-3"><a href="#下载yaml文件-3" class="headerlink" title="下载yaml文件"></a>下载yaml文件</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.20.0/deploy/mandatory.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/ingress-nginx/nginx-0.20.0/deploy/provider/baremetal/service-nodeport.yaml</span><br></pre></td></tr></table></figure><h3 id="修改镜像地址-1"><a href="#修改镜像地址-1" class="headerlink" title="修改镜像地址"></a>修改镜像地址</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sed -e 's,k8s.gcr.io/,zhangguanzhang/gcr.io.google_containers.,g' \</span><br><span class="line">    -e 's,quay.io/kubernetes-ingress-controller/,zhangguanzhang/quay.io.kubernetes-ingress-controller.,g' \</span><br><span class="line">    -i mandatory.yaml</span><br></pre></td></tr></table></figure><h3 id="创建ingress-nginx"><a href="#创建ingress-nginx" class="headerlink" title="创建ingress-nginx"></a>创建ingress-nginx</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f .</span><br></pre></td></tr></table></figure><h3 id="检查部署情况-2"><a href="#检查部署情况-2" class="headerlink" title="检查部署情况"></a>检查部署情况</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n ingress-nginx get pod</span><br></pre></td></tr></table></figure><h3 id="访问ingress"><a href="#访问ingress" class="headerlink" title="访问ingress"></a>访问ingress</h3><blockquote><ul><li>默认的backend会返回404</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n ingress-nginx get svc</span><br><span class="line">NAME            TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE</span><br><span class="line">ingress-nginx   NodePort   10.96.250.140   &lt;none&gt;        80:32603/TCP,443:30083/TCP   1m</span><br><span class="line"></span><br><span class="line">curl http://172.16.80.200:32603</span><br><span class="line">default backend - 404</span><br><span class="line"></span><br><span class="line">curl -k https://172.16.80.200:30083</span><br><span class="line">default backend - 404</span><br></pre></td></tr></table></figure><blockquote><font color="red"><strong>注意</strong></font><ul><li><p>这里部署之后，是<code>deployment</code>，且通过<code>nodePort</code>暴露服务</p></li><li><p>也可以修改yaml文件，将<code>Ingress-nginx</code>部署为<code>DaemonSet</code></p><ul><li>使用<code>labels</code>和<code>nodeSelector</code>来指定运行ingress-nginx的节点</li><li>使用<code>hostNetwork=true</code>来共享主机网络命名空间，或者使用<code>hostPort</code>指定主机端口映射</li><li>如果使用<code>hostNetwork</code>共享宿主机网络栈或者<code>hostPort</code>映射宿主机端口，记得要看看有没有端口冲突，否则无法启动</li><li>修改监听端口可以在<code>ingress-nginx</code>启动命令中添加<code>--http-port=8180</code>和<code>--https-port=8543</code>，还有下面的端口定义也相应变更即可</li></ul></li></ul></blockquote><h3 id="创建kubernetes-Dashboard的Ingress"><a href="#创建kubernetes-Dashboard的Ingress" class="headerlink" title="创建kubernetes-Dashboard的Ingress"></a>创建kubernetes-Dashboard的Ingress</h3><blockquote><ul><li>kubernetes-Dashboard默认是开启了HTTPS访问的</li><li>ingress-nginx需要以HTTPS的方式反向代理kubernetes-Dashboard</li><li>以HTTP方式访问kubernetes-Dashboard的时候会被重定向到HTTPS</li><li>需要创建HTTPS证书，用于访问ingress-nginx的HTTPS端口</li></ul></blockquote><h4 id="创建HTTPS证书"><a href="#创建HTTPS证书" class="headerlink" title="创建HTTPS证书"></a>创建HTTPS证书</h4><blockquote><ul><li>这里的<code>CN=域名/O=域名</code>需要跟后面的ingress主机名匹配</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">openssl req -x509 \</span><br><span class="line">            -nodes \</span><br><span class="line">            -days 3650 \</span><br><span class="line">            -newkey rsa:2048 \</span><br><span class="line">            -keyout tls.key \</span><br><span class="line">            -out tls.crt \</span><br><span class="line">            -subj "/CN=dashboard.k8s.local/O=dashboard.k8s.local"</span><br></pre></td></tr></table></figure><h4 id="创建secret对象"><a href="#创建secret对象" class="headerlink" title="创建secret对象"></a>创建secret对象</h4><blockquote><ul><li>这里将HTTPS证书创建为kubernetes的secret对象<code>dashboard-tls</code></li><li>ingress创建的时候需要加载这个作为HTTPS证书</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system create secret tls dashboard-tls --key ./tls.key --cert ./tls.crt</span><br></pre></td></tr></table></figure><h4 id="创建dashboard-ingress-yaml"><a href="#创建dashboard-ingress-yaml" class="headerlink" title="创建dashboard-ingress.yaml"></a>创建dashboard-ingress.yaml</h4><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">Ingress</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">dashboard-ingress</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  annotations:</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/ssl-passthrough:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">nginx.ingress.kubernetes.io/secure-backends:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  tls:</span></span><br><span class="line"><span class="attr">  - hosts:</span></span><br><span class="line"><span class="bullet">    -</span> <span class="string">dashboard.k8s.local</span></span><br><span class="line"><span class="attr">    secretName:</span> <span class="string">dashboard-tls</span></span><br><span class="line"><span class="attr">  rules:</span></span><br><span class="line"><span class="attr">  - host:</span> <span class="string">dashboard.k8s.local</span></span><br><span class="line"><span class="attr">    http:</span></span><br><span class="line"><span class="attr">      paths:</span></span><br><span class="line"><span class="attr">        - path:</span> <span class="string">/</span></span><br><span class="line"><span class="attr">          backend:</span></span><br><span class="line"><span class="attr">            serviceName:</span> <span class="string">kubernetes-dashboard</span></span><br><span class="line"><span class="attr">            servicePort:</span> <span class="number">443</span></span><br></pre></td></tr></table></figure><h4 id="创建ingress"><a href="#创建ingress" class="headerlink" title="创建ingress"></a>创建ingress</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f dashboard-ingress.yaml</span><br></pre></td></tr></table></figure><h4 id="检查ingress"><a href="#检查ingress" class="headerlink" title="检查ingress"></a>检查ingress</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get ingress</span><br><span class="line">NAME                HOSTS                 ADDRESS         PORTS     AGE</span><br><span class="line">dashboard-ingress   dashboard.k8s.local                   80, 443   16m</span><br></pre></td></tr></table></figure><h4 id="访问kubernetes-Dashboard"><a href="#访问kubernetes-Dashboard" class="headerlink" title="访问kubernetes-Dashboard"></a>访问kubernetes-Dashboard</h4><ul><li>修改主机hosts静态域名解析，以本文为例在hosts文件里添加<code>172.16.80.200 dashboard.k8s.local</code></li><li>使用<code>https://dashboard.k8s.local:30083</code>访问kubernetesDashboard了</li><li>添加了TLS之后，访问HTTP会被跳转到HTTPS端口，这里比较坑爹，没法自定义跳转HTTPS的端口</li><li>此处使用的是自签名证书，浏览器会提示不安全，请忽略</li><li>建议搭配<code>external-DNS</code>和<code>LoadBalancer</code>一起食用，效果更佳</li></ul><p><img src="/2018/12/08/./二进制部署 kubernetes v1.11.x 高可用集群\访问kubernetes-dashboard-ingress.png" alt=""></p><h2 id="Helm"><a href="#Helm" class="headerlink" title="Helm"></a>Helm</h2><blockquote><ul><li><a href="http://helm.sh/" target="_blank" rel="noopener">Helm</a>是一个kubernetes应用的包管理工具，用来管理<a href="https://github.com/kubernetes/charts" target="_blank" rel="noopener">charts</a>——预先配置好的安装包资源，有点类似于Ubuntu的APT和CentOS中的yum。</li><li>Helm chart是用来封装kubernetes原生应用程序的yaml文件，可以在你部署应用的时候自定义应用程序的一些metadata，便与应用程序的分发。</li><li>Helm和charts的主要作用：<ul><li>应用程序封装</li><li>版本管理</li><li>依赖检查</li><li>便于应用程序分发</li></ul></li></ul></blockquote><h3 id="环境要求"><a href="#环境要求" class="headerlink" title="环境要求"></a>环境要求</h3><blockquote><ul><li>kubernetes v1.6及以上的版本，启用RBAC</li><li>集群可以访问到chart仓库</li><li>helm客户端主机能访问kubernetes集群</li></ul></blockquote><h3 id="安装客户端"><a href="#安装客户端" class="headerlink" title="安装客户端"></a>安装客户端</h3><blockquote><p>安装方式二选一，需要<font color="red">科学上网</font></p></blockquote><h4 id="直接脚本安装"><a href="#直接脚本安装" class="headerlink" title="直接脚本安装"></a>直接脚本安装</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 使用脚本安装，默认是最新版 ---'</span><br><span class="line">curl https://raw.githubusercontent.com/helm/helm/master/scripts/get | bash</span><br></pre></td></tr></table></figure><h4 id="下载二进制文件安装"><a href="#下载二进制文件安装" class="headerlink" title="下载二进制文件安装"></a>下载二进制文件安装</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">echo '--- 下载二进制文件安装 ---'</span><br><span class="line">wget https://storage.googleapis.com/kubernetes-helm/helm-v2.12.0-linux-amd64.tar.gz</span><br><span class="line">tar xzf helm-v2.12.0-linux-amd64.tar.gz linux-amd64/helm</span><br><span class="line">mv linux-amd64/helm /usr/local/bin/</span><br><span class="line">rm -rf linux-amd64</span><br></pre></td></tr></table></figure><h3 id="创建工作目录-7"><a href="#创建工作目录-7" class="headerlink" title="创建工作目录"></a>创建工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir /root/yaml/helm/</span><br></pre></td></tr></table></figure><h3 id="切换工作目录-7"><a href="#切换工作目录-7" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/helm</span><br></pre></td></tr></table></figure><h3 id="创建RBAC规则"><a href="#创建RBAC规则" class="headerlink" title="创建RBAC规则"></a>创建RBAC规则</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; /root/yaml/helm/helm-rbac.yaml &lt;&lt;EOF</span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建名为tiller的ServiceAccount</span></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: tiller</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line"><span class="meta">#</span><span class="bash"> 给tiller绑定cluster-admin权限</span></span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1beta1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  name: tiller-cluster-rule</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: cluster-admin</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: tiller</span><br><span class="line">  namespace: kube-system</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl apply -f /root/yaml/helm/helm-rbac.yaml</span><br></pre></td></tr></table></figure><h3 id="安装服务端"><a href="#安装服务端" class="headerlink" title="安装服务端"></a>安装服务端</h3><blockquote><ul><li>这里指定了helm的stable repo国内镜像地址</li><li>具体说明请看<a href="https://github.com/BurdenBear/kube-charts-mirror" target="_blank" rel="noopener">这里</a></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">helm init --tiller-image gcrxio/tiller:v2.12.0 \</span><br><span class="line">          --service-account tiller \</span><br><span class="line">          --stable-repo-url http://mirror.azure.cn/kubernetes/charts/</span><br></pre></td></tr></table></figure><h3 id="检查安装情况"><a href="#检查安装情况" class="headerlink" title="检查安装情况"></a>检查安装情况</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get pod -l app=helm,name=tiller</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME                             READY     STATUS    RESTARTS   AGE</span><br><span class="line">tiller-deploy-84fc6cd5f9-nz4m7   1/1       Running   0          1m</span><br><span class="line"></span><br><span class="line">helm version</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">Client: &amp;version.Version&#123;SemVer:"v2.12.0", GitCommit:"d325d2a9c179b33af1a024cdb5a4472b6288016a", GitTreeState:"clean"&#125;</span><br><span class="line">Server: &amp;version.Version&#123;SemVer:"v2.12.0", GitCommit:"d325d2a9c179b33af1a024cdb5a4472b6288016a", GitTreeState:"clean"&#125;</span><br></pre></td></tr></table></figure><h3 id="添加命令行补全"><a href="#添加命令行补全" class="headerlink" title="添加命令行补全"></a>添加命令行补全</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">helm completion bash  &gt; /etc/bash_completion.d/helm</span><br><span class="line">source /etc/bash_completion.d/helm</span><br></pre></td></tr></table></figure><h2 id="Rook（测试用途）"><a href="#Rook（测试用途）" class="headerlink" title="Rook（测试用途）"></a>Rook（<font color="red">测试用途</font>）</h2><h3 id="说明-5"><a href="#说明-5" class="headerlink" title="说明"></a>说明</h3><blockquote><ul><li><a href="https://github.com/rook/rook" target="_blank" rel="noopener">Rook</a>是一款云原生环境下的开源分布式存储编排系统，目前已进入CNCF孵化。Rook的官方网站是<a href="https://rook.io" target="_blank" rel="noopener">https://rook.io</a></li><li>Rook将分布式存储软件转变为自我管理，自我缩放和自我修复的存储服务。它通过自动化部署，引导、配置、供应、扩展、升级、迁移、灾难恢复、监控和资源管理来实现。 Rook使用基础的云原生容器管理、调度和编排平台提供的功能来履行其职责。</li><li>Rook利用扩展点深入融入云原生环境，为调度、生命周期管理、资源管理、安全性、监控和用户体验提供无缝体验。</li><li>Ceph Custom Resource Definition（CRD）已经在Rook v0.8版本升级到Beta</li><li>其他特性请查看项目文档</li><li><font color="red"><strong>这里只用作测试环境中提供StorageClass和持久化存储</strong></font></li><li><font color="red"><strong>请慎重考虑是否部署在生产环境中</strong></font></li></ul></blockquote><h3 id="Rook与kubernetes的集成"><a href="#Rook与kubernetes的集成" class="headerlink" title="Rook与kubernetes的集成"></a>Rook与kubernetes的集成</h3><p><img src="https://rook.io/docs/rook/v0.8/media/rook-architecture.png" alt=""></p><h3 id="Rook架构图"><a href="#Rook架构图" class="headerlink" title="Rook架构图"></a>Rook架构图</h3><p><img src="https://rook.io/docs/rook/v0.8/media/kubernetes.png" alt=""></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><ul><li>这里以<code>Rook v0.8.3</code>作为示例</li><li>这里默认使用<code>/var/lib/rook/osd*</code>目录来运行OSD</li><li>需要<font color="red">最少3个节点</font>，否则无足够的节点启动集群</li><li>可以使用<code>yaml文件</code>部署和使用<code>helm chart</code>部署，这里使用<code>yaml文件</code>部署</li></ul><h4 id="创建工作目录-8"><a href="#创建工作目录-8" class="headerlink" title="创建工作目录"></a>创建工作目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/rook/</span><br></pre></td></tr></table></figure><h4 id="进入工作目录"><a href="#进入工作目录" class="headerlink" title="进入工作目录"></a>进入工作目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd /root/yaml/rook/</span><br></pre></td></tr></table></figure><h4 id="下载yaml文件-4"><a href="#下载yaml文件-4" class="headerlink" title="下载yaml文件"></a>下载yaml文件</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> operator实现自定义API用于管理rook-ceph</span></span><br><span class="line">wget https://raw.githubusercontent.com/rook/rook/v0.8.3/cluster/examples/kubernetes/ceph/operator.yaml</span><br><span class="line"><span class="meta">#</span><span class="bash"> cluster用于部署rook-ceph集群</span></span><br><span class="line">wget https://raw.githubusercontent.com/rook/rook/v0.8.3/cluster/examples/kubernetes/ceph/cluster.yaml</span><br></pre></td></tr></table></figure><h4 id="部署operator"><a href="#部署operator" class="headerlink" title="部署operator"></a>部署operator</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f operator.yaml</span><br></pre></td></tr></table></figure><h4 id="检查operator安装情况"><a href="#检查operator安装情况" class="headerlink" title="检查operator安装情况"></a>检查operator安装情况</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n rook-ceph-system get all</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME                                      READY     STATUS    RESTARTS   AGE</span><br><span class="line">pod/rook-ceph-agent-4qwvd                 1/1       Running   0          11m</span><br><span class="line">pod/rook-ceph-agent-v5ghj                 1/1       Running   0          11m</span><br><span class="line">pod/rook-ceph-agent-zv8s6                 1/1       Running   0          11m</span><br><span class="line">pod/rook-ceph-operator-745f756bd8-9gdpk   1/1       Running   0          12m</span><br><span class="line">pod/rook-discover-44lx5                   1/1       Running   0          11m</span><br><span class="line">pod/rook-discover-4d6mn                   1/1       Running   0          11m</span><br><span class="line">pod/rook-discover-mvqfv                   1/1       Running   0          11m</span><br><span class="line"></span><br><span class="line">NAME                             DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">daemonset.apps/rook-ceph-agent   3         3         3         3            3           &lt;none&gt;          11m</span><br><span class="line">daemonset.apps/rook-discover     3         3         3         3            3           &lt;none&gt;          11m</span><br><span class="line"></span><br><span class="line">NAME                                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/rook-ceph-operator   1         1         1            1           12m</span><br><span class="line"></span><br><span class="line">NAME                                            DESIRED   CURRENT   READY     AGE</span><br><span class="line">replicaset.apps/rook-ceph-operator-745f756bd8   1         1         1         12m</span><br></pre></td></tr></table></figure><h4 id="部署cluster"><a href="#部署cluster" class="headerlink" title="部署cluster"></a>部署cluster</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f cluster.yaml</span><br></pre></td></tr></table></figure><h4 id="检查cluster部署情况"><a href="#检查cluster部署情况" class="headerlink" title="检查cluster部署情况"></a>检查cluster部署情况</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n rook-ceph get all</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME                                      READY     STATUS      RESTARTS   AGE</span><br><span class="line">pod/rook-ceph-mgr-a-7944d8d79b-pvrsf      1/1       Running     0          10m</span><br><span class="line">pod/rook-ceph-mon0-ll7fc                  1/1       Running     0          11m</span><br><span class="line">pod/rook-ceph-mon1-cd2gb                  1/1       Running     0          11m</span><br><span class="line">pod/rook-ceph-mon2-vlmfc                  1/1       Running     0          10m</span><br><span class="line">pod/rook-ceph-osd-id-0-745486df7b-4dxdc   1/1       Running     0          10m</span><br><span class="line">pod/rook-ceph-osd-id-1-85fdf4cd64-ftmc4   1/1       Running     0          10m</span><br><span class="line">pod/rook-ceph-osd-id-2-6bc4fbb457-295pn   1/1       Running     0          10m</span><br><span class="line">pod/rook-ceph-osd-prepare-k8s-m1-klv5j    0/1       Completed   0          10m</span><br><span class="line">pod/rook-ceph-osd-prepare-k8s-m2-dt2pl    0/1       Completed   0          10m</span><br><span class="line">pod/rook-ceph-osd-prepare-k8s-m3-ndqpl    0/1       Completed   0          10m</span><br><span class="line"></span><br><span class="line">NAME                                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">service/rook-ceph-mgr                      ClusterIP   10.100.158.219   &lt;none&gt;        9283/TCP         10m</span><br><span class="line">service/rook-ceph-mgr-dashboard            ClusterIP   10.107.141.138   &lt;none&gt;        7000/TCP         10m</span><br><span class="line">service/rook-ceph-mgr-dashboard-external   NodePort    10.99.89.12      &lt;none&gt;        7000:30660/TCP   10m</span><br><span class="line">service/rook-ceph-mon0                     ClusterIP   10.100.50.229    &lt;none&gt;        6790/TCP         11m</span><br><span class="line">service/rook-ceph-mon1                     ClusterIP   10.110.105.207   &lt;none&gt;        6790/TCP         11m</span><br><span class="line">service/rook-ceph-mon2                     ClusterIP   10.103.223.166   &lt;none&gt;        6790/TCP         10m</span><br><span class="line"></span><br><span class="line">NAME                                 DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/rook-ceph-mgr-a      1         1         1            1           10m</span><br><span class="line">deployment.apps/rook-ceph-osd-id-0   1         1         1            1           10m</span><br><span class="line">deployment.apps/rook-ceph-osd-id-1   1         1         1            1           10m</span><br><span class="line">deployment.apps/rook-ceph-osd-id-2   1         1         1            1           10m</span><br><span class="line"></span><br><span class="line">NAME                                            DESIRED   CURRENT   READY     AGE</span><br><span class="line">replicaset.apps/rook-ceph-mgr-a-7944d8d79b      1         1         1         10m</span><br><span class="line">replicaset.apps/rook-ceph-mon0                  1         1         1         11m</span><br><span class="line">replicaset.apps/rook-ceph-mon1                  1         1         1         11m</span><br><span class="line">replicaset.apps/rook-ceph-mon2                  1         1         1         10m</span><br><span class="line">replicaset.apps/rook-ceph-osd-id-0-745486df7b   1         1         1         10m</span><br><span class="line">replicaset.apps/rook-ceph-osd-id-1-85fdf4cd64   1         1         1         10m</span><br><span class="line">replicaset.apps/rook-ceph-osd-id-2-6bc4fbb457   1         1         1         10m</span><br><span class="line"></span><br><span class="line">NAME                                     DESIRED   SUCCESSFUL   AGE</span><br><span class="line">job.batch/rook-ceph-osd-prepare-k8s-m1   1         1            10m</span><br><span class="line">job.batch/rook-ceph-osd-prepare-k8s-m2   1         1            10m</span><br><span class="line">job.batch/rook-ceph-osd-prepare-k8s-m3   1         1            10m</span><br></pre></td></tr></table></figure><h4 id="检查ceph集群状态"><a href="#检查ceph集群状态" class="headerlink" title="检查ceph集群状态"></a>检查ceph集群状态</h4><blockquote><ul><li>上面命令已经获取ceph-mon0节点的pod名<code>rook-ceph-mon0-ll7fc</code>，以此pod为例运行以下命令</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n rook-ceph exec -it rook-ceph-mon0-ll7fc -- ceph -s</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">  cluster:</span><br><span class="line">    id:     1fcee02c-fd98-4b13-bfed-de7b6605a237</span><br><span class="line">    health: HEALTH_OK</span><br><span class="line"> </span><br><span class="line">  services:</span><br><span class="line">    mon: 3 daemons, quorum rook-ceph-mon0,rook-ceph-mon2,rook-ceph-mon1</span><br><span class="line">    mgr: a(active)</span><br><span class="line">    osd: 3 osds: 3 up, 3 in</span><br><span class="line"> </span><br><span class="line">  data:</span><br><span class="line">    pools:   1 pools, 100 pgs</span><br><span class="line">    objects: 0 objects, 0 bytes</span><br><span class="line">    usage:   22767 MB used, 96979 MB / 116 GB avail</span><br><span class="line">    pgs:     100 active+clean</span><br></pre></td></tr></table></figure><h3 id="暴露ceph-mgr的dashboard"><a href="#暴露ceph-mgr的dashboard" class="headerlink" title="暴露ceph-mgr的dashboard"></a>暴露ceph-mgr的dashboard</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/rook/rook/v0.8.3/cluster/examples/kubernetes/ceph/dashboard-external.yaml</span><br><span class="line">kubectl apply -f dashboard-external.yaml</span><br></pre></td></tr></table></figure><h3 id="访问已暴露的dashboard"><a href="#访问已暴露的dashboard" class="headerlink" title="访问已暴露的dashboard"></a>访问已暴露的dashboard</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n rook-ceph get svc</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME                               TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">rook-ceph-mgr                      ClusterIP   10.100.158.219   &lt;none&gt;        9283/TCP         12m</span><br><span class="line">rook-ceph-mgr-dashboard            ClusterIP   10.107.141.138   &lt;none&gt;        7000/TCP         12m</span><br><span class="line">rook-ceph-mgr-dashboard-external   NodePort    10.99.89.12      &lt;none&gt;        7000:30660/TCP   11m</span><br><span class="line">rook-ceph-mon0                     ClusterIP   10.100.50.229    &lt;none&gt;        6790/TCP         13m</span><br><span class="line">rook-ceph-mon1                     ClusterIP   10.110.105.207   &lt;none&gt;        6790/TCP         13m</span><br><span class="line">rook-ceph-mon2                     ClusterIP   10.103.223.166   &lt;none&gt;        6790/TCP         12m</span><br></pre></td></tr></table></figure><blockquote><ul><li>可以见到这里暴露<code>30660</code>端口，通过此端口可以访问Dashboard</li></ul></blockquote><h3 id="添加StorageClass"><a href="#添加StorageClass" class="headerlink" title="添加StorageClass"></a>添加StorageClass</h3><blockquote><ul><li>添加<code>多副本</code>存储池</li><li>注释部分是创建<code>纠删码</code>存储池</li><li>添加<code>StorageClass</code>指定使用<code>多副本</code>存储池，格式化为<code>xfs</code></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">cat &gt; rbd-storageclass.yaml &lt;&lt;EOF</span><br><span class="line">apiVersion: ceph.rook.io/v1beta1</span><br><span class="line">kind: Pool</span><br><span class="line">metadata:</span><br><span class="line">  name: replicapool</span><br><span class="line">  namespace: rook-ceph</span><br><span class="line">spec:</span><br><span class="line">  replicated:</span><br><span class="line">    size: 3</span><br><span class="line"><span class="meta">  #</span><span class="bash"> For an erasure-coded pool, comment out the replication size above and uncomment the following settings.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> Make sure you have enough OSDs to support the replica size or erasure code chunks.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">erasureCoded:</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">  dataChunks: 2</span></span><br><span class="line"><span class="meta">  #</span><span class="bash">  codingChunks: 1</span></span><br><span class="line">---</span><br><span class="line">apiVersion: storage.k8s.io/v1</span><br><span class="line">kind: StorageClass</span><br><span class="line">metadata:</span><br><span class="line">   name: rook-ceph-block</span><br><span class="line">provisioner: ceph.rook.io/block</span><br><span class="line">parameters:</span><br><span class="line">  pool: replicapool</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Specify the namespace of the rook cluster from <span class="built_in">which</span> to create volumes.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> If not specified, it will use `rook` as the default namespace of the cluster.</span></span><br><span class="line"><span class="meta">  #</span><span class="bash"> This is also the namespace <span class="built_in">where</span> the cluster will be</span></span><br><span class="line">  clusterNamespace: rook-ceph</span><br><span class="line"><span class="meta">  #</span><span class="bash"> Specify the filesystem <span class="built_in">type</span> of the volume. If not specified, it will use `ext4`.</span></span><br><span class="line">  fstype: xfs</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">kubectl apply -f rbd-storageclass.yaml</span><br></pre></td></tr></table></figure><blockquote><ul><li>还可以添加<code>cephFS</code>和<code>object</code>类型的存储池，然后创建对应的<code>StorageClass</code></li></ul></blockquote><p>具体可以看<a href="https://raw.githubusercontent.com/rook/rook/v0.8.3/cluster/examples/kubernetes/ceph/filesystem.yaml" target="_blank" rel="noopener">filesystem.yaml</a>和<a href="https://raw.githubusercontent.com/rook/rook/v0.8.3/cluster/examples/kubernetes/ceph/object.yaml" target="_blank" rel="noopener">object.yaml</a></p><h3 id="检查StorageClass"><a href="#检查StorageClass" class="headerlink" title="检查StorageClass"></a>检查StorageClass</h3><blockquote><ul><li>创建sc时，会在<code>rook-ceph</code>上创建对应的Pool</li><li>这里以<code>rbd-storageclass.yaml</code>为例</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">kubectl get sc</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME              PROVISIONER          AGE</span><br><span class="line">rook-ceph-block   ceph.rook.io/block   15m</span><br><span class="line"></span><br><span class="line">kubectl describe sc rook-ceph-block </span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">Name:            rook-ceph-block</span><br><span class="line">IsDefaultClass:  No</span><br><span class="line">Annotations:     kubectl.kubernetes.io/last-applied-configuration=&#123;"apiVersion":"storage.k8s.io/v1","kind":"StorageClass","metadata":&#123;"annotations":&#123;&#125;,"name":"rook-ceph-block","namespace":""&#125;,"parameters":&#123;"clusterNamespace":"rook-ceph","fstype":"xfs","pool":"replicapool"&#125;,"provisioner":"ceph.rook.io/block"&#125;</span><br><span class="line"></span><br><span class="line">Provisioner:           ceph.rook.io/block</span><br><span class="line">Parameters:            clusterNamespace=rook-ceph,fstype=xfs,pool=replicapool</span><br><span class="line">AllowVolumeExpansion:  &lt;unset&gt;</span><br><span class="line">MountOptions:          &lt;none&gt;</span><br><span class="line">ReclaimPolicy:         Delete</span><br><span class="line">VolumeBindingMode:     Immediate</span><br><span class="line">Events:                &lt;none&gt;</span><br><span class="line"></span><br><span class="line">kubectl -n rook-ceph exec -it rook-ceph-mon0-ll7fc -- ceph df</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">GLOBAL:</span><br><span class="line">    SIZE     AVAIL      RAW USED     %RAW USED </span><br><span class="line">    116G     96979M       22767M         19.01 </span><br><span class="line">POOLS:</span><br><span class="line">    NAME            ID     USED     %USED     MAX AVAIL     OBJECTS </span><br><span class="line">    replicapool     1         0         0        29245M           0</span><br></pre></td></tr></table></figure><h3 id="卸载Rook-ceph"><a href="#卸载Rook-ceph" class="headerlink" title="卸载Rook-ceph"></a>卸载Rook-ceph</h3><blockquote><ul><li>这里提供卸载的操作步骤，请按需操作！</li></ul></blockquote><h4 id="删除StorageClass"><a href="#删除StorageClass" class="headerlink" title="删除StorageClass"></a>删除StorageClass</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f rbd-storageclass.yaml</span><br></pre></td></tr></table></figure><h4 id="删除Rook-Ceph-Cluster"><a href="#删除Rook-Ceph-Cluster" class="headerlink" title="删除Rook-Ceph-Cluster"></a>删除Rook-Ceph-Cluster</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f cluster.yaml</span><br></pre></td></tr></table></figure><h4 id="删除Rook-Operator"><a href="#删除Rook-Operator" class="headerlink" title="删除Rook-Operator"></a>删除Rook-Operator</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl delete -f operator.yaml</span><br></pre></td></tr></table></figure><h4 id="清理目录"><a href="#清理目录" class="headerlink" title="清理目录"></a>清理目录</h4><blockquote><ul><li><font color="red">注意！</font>这里是所有运行rook-ceph集群的节点都需要做清理</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf /var/lib/rook</span><br></pre></td></tr></table></figure><h2 id="Prometheus-Operator"><a href="#Prometheus-Operator" class="headerlink" title="Prometheus Operator"></a>Prometheus Operator</h2><h3 id="说明-6"><a href="#说明-6" class="headerlink" title="说明"></a>说明</h3><blockquote><ul><li>Prometheus Operator 是 CoreOS 开发的基于 Prometheus 的 Kubernetes 监控方案，也可能是目前功能最全面的开源方案。</li><li>Prometheus Operator 通过 Grafana 展示监控数据，预定义了一系列的 Dashboard</li><li>要求kubernetes版本大于等于<code>1.8.0</code></li><li><a href="https://github.com/coreos/prometheus-operator" target="_blank" rel="noopener">CoreOS/Prometheus-Operator项目地址</a></li></ul></blockquote><h3 id="Prometheus"><a href="#Prometheus" class="headerlink" title="Prometheus"></a>Prometheus</h3><blockquote><ul><li>Prometheus 是一套开源的系统监控报警框架，启发于 Google 的 borgmon 监控系统，作为社区开源项目进行开发，并成为CNCF第二个毕业的项目（第一个是kubernetes）</li><li>特点<ul><li>强大的多维度数据模型</li><li>灵活而强大的查询语句（PromQL）</li><li>易于管理，高效</li><li>使用 pull 模式采集时间序列数据，这样不仅有利于本机测试而且可以避免有问题的服务器推送坏的 metrics。</li><li>可以采用 push gateway 的方式把时间序列数据推送至 Prometheus server 端</li><li>可以通过服务发现或者静态配置去获取监控的 targets</li><li>有多种可视化图形界面</li><li>易于伸缩</li></ul></li></ul></blockquote><h4 id="Prometheus组成架构"><a href="#Prometheus组成架构" class="headerlink" title="Prometheus组成架构"></a>Prometheus组成架构</h4><blockquote><ul><li><strong>Prometheus Server</strong>: 用于收集和存储时间序列数据</li><li><strong>Client Library</strong>: 客户端库，为需要监控的服务生成相应的 metrics 并暴露给<br>Prometheus server</li><li><strong>Push Gateway</strong>: 主要用于短期的 jobs。 jobs 可以直接向 Prometheus server 端推送它们的<br>metrics。这种方式主要用于服务层面的 metrics。</li><li><strong>Exporters</strong>: 用于暴露已有的第三方服务的 metrics 给 Prometheus。</li><li><strong>Alertmanager</strong>: 从 Prometheus server 端接收到 alerts<br>后，会进行去除重复数据，分组，并路由到对收的接受方式，发出报警。</li></ul></blockquote><h4 id="架构图-2"><a href="#架构图-2" class="headerlink" title="架构图"></a>架构图</h4><p><img src="https://prometheus.io/assets/architecture.png" alt=""></p><h3 id="Operator架构"><a href="#Operator架构" class="headerlink" title="Operator架构"></a>Operator架构</h3><blockquote><ul><li><p><strong>Operator</strong></p><p>即 Prometheus Operator，在 Kubernetes 中以 Deployment 运行。其职责是部署和管理<br>Prometheus Server，根据 ServiceMonitor 动态更新 Prometheus Server 的监控对象。</p></li><li><p><strong>Prometheus Server</strong></p><p>Prometheus Server 会作为 Kubernetes 应用部署到集群中。为了更好地在 Kubernetes 中管理 Prometheus，CoreOS 的开发人员专门定义了一个命名为 <code>Prometheus</code> 类型的 Kubernetes 定制化资源。我们可以把 <code>Prometheus</code>看作是一种特殊的 Deployment，它的用途就是专门部署 Prometheus Server。</p></li><li><p><strong>Service</strong></p><p>这里的<br>Service 就是 Cluster 中的 Service 资源，也是 Prometheus 要监控的对象，在 Prometheus 中叫做<br>Target。每个监控对象都有一个对应的 Service。比如要监控 Kubernetes Scheduler，就得有一个与 Scheduler<br>对应的 Service。当然，Kubernetes 集群默认是没有这个 Service 的，Prometheus Operator<br>会负责创建。</p></li><li><p><strong>ServiceMonitor</strong></p><p>Operator<br>能够动态更新 Prometheus 的 Target 列表，ServiceMonitor 就是 Target 的抽象。比如想监控<br>Kubernetes Scheduler，用户可以创建一个与 Scheduler Service 相映射的 ServiceMonitor<br>对象。Operator 则会发现这个新的 ServiceMonitor，并将 Scheduler 的 Target 添加到 Prometheus<br>的监控列表中。</p><p>ServiceMonitor 也是 Prometheus Operator 专门开发的一种 Kubernetes 定制化资源类型。</p></li><li><p><strong>Alertmanager</strong></p><p>除了 Prometheus 和 ServiceMonitor，Alertmanager 是 Operator 开发的第三种 Kubernetes 定制化资源。我们可以把 <code>Alertmanager</code> 看作是一种特殊的 Deployment，它的用途就是专门部署 Alertmanager 组件。</p></li></ul></blockquote><p><img src="https://github.com/coreos/prometheus-operator/raw/release-0.26/Documentation/user-guides/images/architecture.png" alt=""></p><h3 id="部署Prometheus-Operator"><a href="#部署Prometheus-Operator" class="headerlink" title="部署Prometheus-Operator"></a>部署Prometheus-Operator</h3><h4 id="切换工作目录-8"><a href="#切换工作目录-8" class="headerlink" title="切换工作目录"></a>切换工作目录</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkdir -p /root/yaml/prometheus-operator</span><br><span class="line">cd /root/yaml/prometheus-operator</span><br></pre></td></tr></table></figure><h4 id="添加coreos源"><a href="#添加coreos源" class="headerlink" title="添加coreos源"></a>添加coreos源</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 添加coreos源</span></span><br><span class="line">helm repo add coreos https://s3-eu-west-1.amazonaws.com/coreos-charts/stable/</span><br></pre></td></tr></table></figure><h4 id="创建命名空间"><a href="#创建命名空间" class="headerlink" title="创建命名空间"></a>创建命名空间</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create namespace monitoring</span><br></pre></td></tr></table></figure><h4 id="部署prometheus-operator"><a href="#部署prometheus-operator" class="headerlink" title="部署prometheus-operator"></a>部署prometheus-operator</h4><blockquote><ul><li>这里通过<code>--set</code>指定了image的地址</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">helm install coreos/prometheus-operator \</span><br><span class="line">    --name coreos-prometheus-operator \</span><br><span class="line">    --namespace monitoring \</span><br><span class="line">    --set global.hyperkube.repository=zhangguanzhang/quay.io.coreos.hyperkube \</span><br><span class="line">    --set image.repository=zhangguanzhang/quay.io.coreos.prometheus-operator \</span><br><span class="line">    --set prometheusConfigReloader.repository=zhangguanzhang/quay.io.coreos.prometheus-config-reloader \</span><br><span class="line">    --set rbacEnable=true</span><br></pre></td></tr></table></figure><h4 id="部署kube-prometheus"><a href="#部署kube-prometheus" class="headerlink" title="部署kube-prometheus"></a>部署kube-prometheus</h4><blockquote><ul><li>通过运行<code>helm</code>命令安装时，指定一些变量来达到自定义配置的目的</li><li>定义<code>grafana</code>初始admin密码为<code>password</code>，默认值是<code>admin</code></li><li>定义<code>alertmanager</code>和<code>prometheus</code>使用名为<code>rook-ceph-block</code>的<code>StorageClass</code>，访问模式为<code>ReadWriteOnce</code>，大小<code>5Gi</code>，默认是<code>50Gi</code></li><li>定义<code>grafana</code>、<code>alertmanager</code>、<code>prometheus</code>的<code>Service</code>类型为<code>NodePort</code>，默认是<code>ClusterIP</code></li><li>这里的<code>--set</code>可以定义很多变量，具体可以在<a href="https://github.com/coreos/prometheus-operator/tree/master/helm" target="_blank" rel="noopener">这里</a>，查看里面每个文件夹的<code>values.yaml</code></li><li>这里<font color="red">配置的变量</font>请自己根据情况修改</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">helm install coreos/kube-prometheus \</span><br><span class="line">    --name kube-prometheus \</span><br><span class="line">    --namespace monitoring \</span><br><span class="line">    --set alertmanager.image.repository="zhangguanzhang/quay.io.prometheus.alertmanager" \</span><br><span class="line">    --set alertmanager.service.type="NodePort" \</span><br><span class="line">    --set alertmanager.storageSpec.volumeClaimTemplate.spec.storageClassName="rook-ceph-block" \</span><br><span class="line">    --set alertmanager.storageSpec.volumeClaimTemplate.spec.accessModes[0]="ReadWriteOnce" \</span><br><span class="line">    --set alertmanager.storageSpec.volumeClaimTemplate.spec.resources.requests.storage="5Gi" \</span><br><span class="line">    --set grafana.adminPassword="password" \</span><br><span class="line">    --set grafana.service.type="NodePort" \</span><br><span class="line">    --set prometheus.image.repository="zhangguanzhang/quay.io.prometheus.prometheus" \</span><br><span class="line">    --set prometheus.service.type="NodePort" \</span><br><span class="line">    --set prometheus.storageSpec.volumeClaimTemplate.spec.storageClassName="rook-ceph-block" \</span><br><span class="line">    --set prometheus.storageSpec.volumeClaimTemplate.spec.accessModes[0]="ReadWriteOnce" \</span><br><span class="line">    --set prometheus.storageSpec.volumeClaimTemplate.spec.resources.requests.storage="5Gi" \</span><br><span class="line">    --set prometheus.deployCoreDNS=true \</span><br><span class="line">    --set prometheus.deployKubeDNS=false \</span><br><span class="line">    --set prometheus.deployKubeEtcd=true \</span><br><span class="line">    --set exporter-kube-controller-manager.endpoints[0]="172.16.80.201" \</span><br><span class="line">    --set exporter-kube-controller-manager.endpoints[1]="172.16.80.202" \</span><br><span class="line">    --set exporter-kube-controller-manager.endpoints[2]="172.16.80.203" \</span><br><span class="line">    --set exporter-kube-etcd.etcdPort=2379 \</span><br><span class="line">    --set exporter-kube-etcd.scheme="https" \</span><br><span class="line">    --set exporter-kube-etcd.endpoints[0]="172.16.80.201" \</span><br><span class="line">    --set exporter-kube-etcd.endpoints[1]="172.16.80.202" \</span><br><span class="line">    --set exporter-kube-etcd.endpoints[2]="172.16.80.203" \</span><br><span class="line">    --set exporter-kube-scheduler.endpoints[0]="172.16.80.201" \</span><br><span class="line">    --set exporter-kube-scheduler.endpoints[1]="172.16.80.202" \</span><br><span class="line">    --set exporter-kube-scheduler.endpoints[2]="172.16.80.203" \</span><br><span class="line">    --set exporter-kube-state.kube_state_metrics.image.repository="gcrxio/kube-state-metrics" \</span><br><span class="line">    --set exporter-kube-state.addon_resizer.image.repository="gcrxio/addon-resizer"</span><br></pre></td></tr></table></figure><h4 id="检查部署情况-3"><a href="#检查部署情况-3" class="headerlink" title="检查部署情况"></a>检查部署情况</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n monitoring get all</span><br><span class="line"><span class="meta">#</span><span class="bash"> 输出示例</span></span><br><span class="line">NAME                                                       READY     STATUS    RESTARTS   AGE</span><br><span class="line">pod/alertmanager-kube-prometheus-0                         2/2       Running   0          43m</span><br><span class="line">pod/kube-prometheus-exporter-kube-state-66b8849c9b-cq5pp   2/2       Running   0          42m</span><br><span class="line">pod/kube-prometheus-exporter-node-p6z67                    1/1       Running   0          43m</span><br><span class="line">pod/kube-prometheus-exporter-node-qnmjt                    1/1       Running   0          43m</span><br><span class="line">pod/kube-prometheus-exporter-node-vr4sp                    1/1       Running   0          43m</span><br><span class="line">pod/kube-prometheus-grafana-f869c754-x5x7n                 2/2       Running   0          43m</span><br><span class="line">pod/prometheus-kube-prometheus-0                           3/3       Running   1          43m</span><br><span class="line">pod/prometheus-operator-5db9df7ffc-dxtqh                   1/1       Running   0          49m</span><br><span class="line"></span><br><span class="line">NAME                                          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)             AGE</span><br><span class="line">service/alertmanager-operated                 ClusterIP   None             &lt;none&gt;        9093/TCP,6783/TCP   43m</span><br><span class="line">service/kube-prometheus                       NodePort    10.97.183.252    &lt;none&gt;        9090:30900/TCP      43m</span><br><span class="line">service/kube-prometheus-alertmanager          NodePort    10.105.140.173   &lt;none&gt;        9093:30903/TCP      43m</span><br><span class="line">service/kube-prometheus-exporter-kube-state   ClusterIP   10.108.236.146   &lt;none&gt;        80/TCP              43m</span><br><span class="line">service/kube-prometheus-exporter-node         ClusterIP   10.96.14.75      &lt;none&gt;        9100/TCP            43m</span><br><span class="line">service/kube-prometheus-grafana               NodePort    10.109.4.170     &lt;none&gt;        80:30164/TCP        43m</span><br><span class="line">service/prometheus-operated                   ClusterIP   None             &lt;none&gt;        9090/TCP            43m</span><br><span class="line"></span><br><span class="line">NAME                                           DESIRED   CURRENT   READY     UP-TO-DATE   AVAILABLE   NODE SELECTOR   AGE</span><br><span class="line">daemonset.apps/kube-prometheus-exporter-node   3         3         3         3            3           &lt;none&gt;          43m</span><br><span class="line"></span><br><span class="line">NAME                                                  DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE</span><br><span class="line">deployment.apps/kube-prometheus-exporter-kube-state   1         1         1            1           43m</span><br><span class="line">deployment.apps/kube-prometheus-grafana               1         1         1            1           43m</span><br><span class="line">deployment.apps/prometheus-operator                   1         1         1            1           49m</span><br><span class="line"></span><br><span class="line">NAME                                                             DESIRED   CURRENT   READY     AGE</span><br><span class="line">replicaset.apps/kube-prometheus-exporter-kube-state-658f46b8dd   0         0         0         43m</span><br><span class="line">replicaset.apps/kube-prometheus-exporter-kube-state-66b8849c9b   1         1         1         42m</span><br><span class="line">replicaset.apps/kube-prometheus-grafana-f869c754                 1         1         1         43m</span><br><span class="line">replicaset.apps/prometheus-operator-5db9df7ffc                   1         1         1         49m</span><br><span class="line"></span><br><span class="line">NAME                                            DESIRED   CURRENT   AGE</span><br><span class="line">statefulset.apps/alertmanager-kube-prometheus   1         1         43m</span><br><span class="line">statefulset.apps/prometheus-kube-prometheus     1         1         43m</span><br></pre></td></tr></table></figure><h3 id="访问Prometheus-Operator"><a href="#访问Prometheus-Operator" class="headerlink" title="访问Prometheus-Operator"></a>访问Prometheus-Operator</h3><blockquote><ul><li>部署时已经定义alertmanager、prometheus、grafana的Service为NodePort</li><li>根据检查部署的情况，得知<ul><li><code>kube-prometheus</code>的<code>NodePort</code>为<code>30900</code></li><li><code>kube-prometheus-alertmanager</code>的<code>NodePort</code>为<code>30903</code></li><li><code>kube-prometheus-grafana</code>的<code>NodePort</code>为<code>30164</code></li></ul></li><li>直接通过这些端口访问即可</li><li>grafana已内嵌了基础的Dashboard模板，以<code>admin</code>用户登录即可见</li></ul></blockquote><h2 id="EFK"><a href="#EFK" class="headerlink" title="EFK"></a>EFK</h2><h3 id="说明-7"><a href="#说明-7" class="headerlink" title="说明"></a>说明</h3><blockquote><ul><li>官方提供简单的<code>fluentd-elasticsearch</code>样例，可以作为测试用途</li><li>已经包含在<code>kubernetes</code>项目当中<a href="https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/fluentd-elasticsearch" target="_blank" rel="noopener">链接</a></li><li>这里使用<code>kubernetes-server-linux-amd64.tar.gz</code>里面的<code>kubernetes-src.tar.gz</code>提供的Addons</li><li>修改<code>elasticsearch</code>使用<code>rook-ceph</code>提供的<code>StorageClass</code>作为持久化存储，默认是使用<code>emptyDir</code></li></ul></blockquote><h3 id="注意"><a href="#注意" class="headerlink" title="注意"></a><font color="red">注意</font></h3><blockquote><ul><li>EFK集群部署之后，<code>kibana</code>和<code>elasticsearch</code>初始化过程会极大的消耗服务器资源</li><li>请保证你的环境能撑的住！！！！</li><li>配置不够，服务器真的会失去响应</li><li>实测3节点4C 16G SSD硬盘，CPU持续十几分钟的满载</li></ul></blockquote><h3 id="解压源代码"><a href="#解压源代码" class="headerlink" title="解压源代码"></a>解压源代码</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">tar xzf kubernetes-server-linux-amd64.tar.gz kubernetes/kubernetes-src.tar.gz</span><br><span class="line">cd kubernetes</span><br><span class="line">tar xzf kubernetes/kubernetes-src.tar.gz</span><br><span class="line">tar xzf kubernetes-src.tar.gz \</span><br><span class="line">cluster/addons/fluentd-elasticsearch/es-service.yaml \</span><br><span class="line">cluster/addons/fluentd-elasticsearch/es-statefulset.yaml \</span><br><span class="line">cluster/addons/fluentd-elasticsearch/fluentd-es-configmap.yaml \</span><br><span class="line">cluster/addons/fluentd-elasticsearch/fluentd-es-ds.yaml \</span><br><span class="line">cluster/addons/fluentd-elasticsearch/kibana-deployment.yaml \</span><br><span class="line">cluster/addons/fluentd-elasticsearch/kibana-service.yaml</span><br></pre></td></tr></table></figure><h3 id="切换工作目录-9"><a href="#切换工作目录-9" class="headerlink" title="切换工作目录"></a>切换工作目录</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">cd cluster/addons/fluentd-elasticsearch/</span><br></pre></td></tr></table></figure><h3 id="修改yaml文件-1"><a href="#修改yaml文件-1" class="headerlink" title="修改yaml文件"></a>修改yaml文件</h3><blockquote><ul><li>删除es-statefuleset.yaml里面的字段，位置大概在100行左右</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">volumes:</span></span><br><span class="line"><span class="attr">  - name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">    emptyDir:</span> <span class="string">&#123;&#125;</span></span><br></pre></td></tr></table></figure><blockquote><ul><li>添加<code>volumeClaimTemplates</code>字段，声明使用<code>rook-ceph</code>提供的<code>StorageClass</code>，大小5Gi</li><li>位置在<code>StatefulSet.spec</code>，大概67行左右</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">volumeClaimTemplates:</span></span><br><span class="line"><span class="attr">- metadata:</span></span><br><span class="line"><span class="attr">    name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  spec:</span></span><br><span class="line"><span class="attr">    accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line"><span class="attr">    storageClassName:</span> <span class="string">"rook-ceph-block"</span></span><br><span class="line"><span class="attr">    resources:</span></span><br><span class="line"><span class="attr">      requests:</span></span><br><span class="line"><span class="attr">        storage:</span> <span class="number">5</span><span class="string">Gi</span></span><br></pre></td></tr></table></figure><blockquote><ul><li>修改后，<code>es-statefulset.yaml</code>内容如下</li></ul></blockquote><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># RBAC authn and authz</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="attr">rules:</span></span><br><span class="line"><span class="attr">- apiGroups:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">""</span></span><br><span class="line"><span class="attr">  resources:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"services"</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"namespaces"</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"endpoints"</span></span><br><span class="line"><span class="attr">  verbs:</span></span><br><span class="line"><span class="bullet">  -</span> <span class="string">"get"</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">ClusterRoleBinding</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">rbac.authorization.k8s.io/v1</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="attr">subjects:</span></span><br><span class="line"><span class="attr">- kind:</span> <span class="string">ServiceAccount</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">roleRef:</span></span><br><span class="line"><span class="attr">  kind:</span> <span class="string">ClusterRole</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  apiGroup:</span> <span class="string">""</span></span><br><span class="line"><span class="meta">---</span></span><br><span class="line"><span class="comment"># Elasticsearch deployment itself</span></span><br><span class="line"><span class="attr">apiVersion:</span> <span class="string">apps/v1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">StatefulSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">  labels:</span></span><br><span class="line"><span class="attr">    k8s-app:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">    version:</span> <span class="string">v5.6.4</span></span><br><span class="line">    <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line">    <span class="string">addonmanager.kubernetes.io/mode:</span> <span class="string">Reconcile</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  serviceName:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">  replicas:</span> <span class="number">2</span></span><br><span class="line"><span class="attr">  selector:</span></span><br><span class="line"><span class="attr">    matchLabels:</span></span><br><span class="line"><span class="attr">      k8s-app:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">      version:</span> <span class="string">v5.6.4</span></span><br><span class="line"><span class="attr">  volumeClaimTemplates:</span></span><br><span class="line"><span class="attr">  - metadata:</span></span><br><span class="line"><span class="attr">      name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      accessModes:</span> <span class="string">[</span> <span class="string">"ReadWriteOnce"</span> <span class="string">]</span></span><br><span class="line"><span class="attr">      storageClassName:</span> <span class="string">rook-ceph-block</span></span><br><span class="line"><span class="attr">      resources:</span></span><br><span class="line"><span class="attr">        requests:</span></span><br><span class="line"><span class="attr">          storage:</span> <span class="number">5</span><span class="string">Gi</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        k8s-app:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">        version:</span> <span class="string">v5.6.4</span></span><br><span class="line">        <span class="string">kubernetes.io/cluster-service:</span> <span class="string">"true"</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      serviceAccountName:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - image:</span> <span class="string">gcrxio/elasticsearch:v5.6.4</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">        resources:</span></span><br><span class="line">          <span class="comment"># need more cpu upon initialization, therefore burstable class</span></span><br><span class="line"><span class="attr">          limits:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">1000</span><span class="string">m</span></span><br><span class="line"><span class="attr">          requests:</span></span><br><span class="line"><span class="attr">            cpu:</span> <span class="number">100</span><span class="string">m</span></span><br><span class="line"><span class="attr">        ports:</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">9200</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">db</span></span><br><span class="line"><span class="attr">          protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">        - containerPort:</span> <span class="number">9300</span></span><br><span class="line"><span class="attr">          name:</span> <span class="string">transport</span></span><br><span class="line"><span class="attr">          protocol:</span> <span class="string">TCP</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">          mountPath:</span> <span class="string">/data</span></span><br><span class="line"><span class="attr">        env:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">"NAMESPACE"</span></span><br><span class="line"><span class="attr">          valueFrom:</span></span><br><span class="line"><span class="attr">            fieldRef:</span></span><br><span class="line"><span class="attr">              fieldPath:</span> <span class="string">metadata.namespace</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">      - name:</span> <span class="string">elasticsearch-logging</span></span><br><span class="line"><span class="attr">        emptyDir:</span> <span class="string">&#123;&#125;</span></span><br><span class="line">      <span class="comment"># Elasticsearch requires vm.max_map_count to be at least 262144.</span></span><br><span class="line">      <span class="comment"># If your OS already sets up this number to a higher value, feel free</span></span><br><span class="line">      <span class="comment"># to remove this init container.</span></span><br><span class="line"><span class="attr">      initContainers:</span></span><br><span class="line"><span class="attr">      - image:</span> <span class="attr">alpine:3.6</span></span><br><span class="line"><span class="attr">        command:</span> <span class="string">["/sbin/sysctl",</span> <span class="string">"-w"</span><span class="string">,</span> <span class="string">"vm.max_map_count=262144"</span><span class="string">]</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">elasticsearch-logging-init</span></span><br><span class="line"><span class="attr">        securityContext:</span></span><br><span class="line"><span class="attr">          privileged:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><blockquote><ul><li>注释<code>kibana-deployment.yaml</code>定义的环境变量</li><li>大概在35行左右</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> - name: SERVER_BASEPATH</span></span><br><span class="line"><span class="meta">#</span><span class="bash">   value: /api/v1/namespaces/kube-system/services/kibana-logging/proxy</span></span><br></pre></td></tr></table></figure><h3 id="修改镜像地址-2"><a href="#修改镜像地址-2" class="headerlink" title="修改镜像地址"></a>修改镜像地址</h3><blockquote><ul><li>默认yaml定义的镜像地址是<code>k8s.gcr.io</code>，需要科学上网</li><li>变更成<code>gcrxio</code></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sed -e 's,k8s.gcr.io,gcrxio,g' -i *yaml</span><br></pre></td></tr></table></figure><h3 id="给节点打Label"><a href="#给节点打Label" class="headerlink" title="给节点打Label"></a>给节点打Label</h3><blockquote><ul><li><code>fluentd-es-ds.yaml</code>有<code>nodeSelector</code>字段定义了运行在带有<code>beta.kubernetes.io/fluentd-ds-ready: &quot;true&quot;</code>标签的节点上</li><li>这里为了方便，直接给所有节点都打上标签</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl label node --all beta.kubernetes.io/fluentd-ds-ready=true</span><br></pre></td></tr></table></figure><h3 id="部署EFK"><a href="#部署EFK" class="headerlink" title="部署EFK"></a>部署EFK</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl apply -f .</span><br></pre></td></tr></table></figure><h3 id="查看部署情况-1"><a href="#查看部署情况-1" class="headerlink" title="查看部署情况"></a>查看部署情况</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get pod -l k8s-app=elasticsearch-logging</span><br><span class="line">NAME                      READY     STATUS    RESTARTS   AGE</span><br><span class="line">elasticsearch-logging-0   1/1       Running   1          10m</span><br><span class="line">elasticsearch-logging-1   1/1       Running   0          10m</span><br><span class="line"></span><br><span class="line">kubectl -n kube-system get pod -l k8s-app=kibana-logging</span><br><span class="line">NAME                             READY     STATUS    RESTARTS   AGE</span><br><span class="line">kibana-logging-56fb9d765-l95kj   1/1       Running   1          37m</span><br><span class="line"></span><br><span class="line">kubectl -n kube-system get pod -l k8s-app=fluentd-es</span><br><span class="line">NAME                      READY     STATUS    RESTARTS   AGE</span><br><span class="line">fluentd-es-v2.0.4-2mwz7   1/1       Running   0          3m</span><br><span class="line">fluentd-es-v2.0.4-7mk4d   1/1       Running   0          3m</span><br><span class="line">fluentd-es-v2.0.4-zqtpc   1/1       Running   0          3m</span><br><span class="line"></span><br><span class="line">kubectl -n kube-system get svc -l k8s-app=elasticsearch-logging</span><br><span class="line">NAME                    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">elasticsearch-logging   ClusterIP   10.111.107.21   &lt;none&gt;        9200/TCP   39m</span><br><span class="line"></span><br><span class="line">kubectl -n kube-system get svc -l k8s-app=kibana-logging</span><br><span class="line">NAME             TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)    AGE</span><br><span class="line">kibana-logging   ClusterIP   10.96.170.77   &lt;none&gt;        5601/TCP   39m</span><br></pre></td></tr></table></figure><h3 id="访问EFK"><a href="#访问EFK" class="headerlink" title="访问EFK"></a>访问EFK</h3><blockquote><ul><li>修改<code>elasticsearch</code>和<code>kibana</code>的<code>svc</code>为<code>nodePort</code></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">kubectl patch -n kube-system svc elasticsearch-logging -p '&#123;"spec":&#123;"type":"NodePort"&#125;&#125;'</span><br><span class="line">kubectl patch -n kube-system svc kibana-logging -p '&#123;"spec":&#123;"type":"NodePort"&#125;&#125;'</span><br></pre></td></tr></table></figure><blockquote><ul><li>查看分配的<code>nodePort</code></li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">kubectl -n kube-system get svc -l k8s-app=elasticsearch-logging</span><br><span class="line">NAME                    TYPE       CLUSTER-IP      EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">elasticsearch-logging   NodePort   10.111.107.21   &lt;none&gt;        9200:30542/TCP   42m</span><br><span class="line"></span><br><span class="line">kubectl -n kube-system get svc -l k8s-app=kibana-logging</span><br><span class="line">NAME             TYPE       CLUSTER-IP     EXTERNAL-IP   PORT(S)          AGE</span><br><span class="line">kibana-logging   NodePort   10.96.170.77   &lt;none&gt;        5601:30998/TCP   42m</span><br></pre></td></tr></table></figure><blockquote><ul><li>可以看到端口分别为<code>30542</code>和<code>30998</code></li></ul></blockquote><h3 id="在github上获取yaml文件"><a href="#在github上获取yaml文件" class="headerlink" title="在github上获取yaml文件"></a>在github上获取yaml文件</h3><blockquote><ul><li>如果不想用<code>kubernetes-src.tar.gz</code>里面的Addons</li><li>可以直接下载github上面的文件，也是一样的</li></ul></blockquote><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">wget https://raw.githubusercontent.com/kubernetes/kubernetes/$&#123;KUBERNETES_VERSION&#125;/cluster/addons/fluentd-elasticsearch/es-service.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/kubernetes/$&#123;KUBERNETES_VERSION&#125;/cluster/addons/fluentd-elasticsearch/es-statefulset.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/kubernetes/$&#123;KUBERNETES_VERSION&#125;/cluster/addons/fluentd-elasticsearch/fluentd-es-configmap.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/kubernetes/$&#123;KUBERNETES_VERSION&#125;/cluster/addons/fluentd-elasticsearch/fluentd-es-ds.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/kubernetes/$&#123;KUBERNETES_VERSION&#125;/cluster/addons/fluentd-elasticsearch/kibana-deployment.yaml</span><br><span class="line">wget https://raw.githubusercontent.com/kubernetes/kubernetes/$&#123;KUBERNETES_VERSION&#125;/cluster/addons/fluentd-elasticsearch/kibana-service.yaml</span><br></pre></td></tr></table></figure><h1 id="本文至此结束"><a href="#本文至此结束" class="headerlink" title="本文至此结束"></a>本文至此结束</h1></div><div><ul class="post-copyright"><li class="post-copyright-author"><strong>本文作者：</strong> 乱愣黎</li><li class="post-copyright-link"><strong>本文链接：</strong> <a href="https://luanlengli.github.io/2018/12/08/二进制部署 kubernetes v1.11.x 高可用集群.html" title="【不定时更新】二进制部署 kubernetes v1.11.x 高可用集群">https://luanlengli.github.io/2018/12/08/二进制部署 kubernetes v1.11.x 高可用集群.html</a></li><li class="post-copyright-license"><strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/3.0/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0</a> 许可协议。转载请注明出处！</li></ul></div><footer class="post-footer"><div class="post-tags"><a href="/tags/kubernetes/" rel="tag"><i class="fa fa-tag"></i> kubernetes</a> <a href="/tags/docker/" rel="tag"><i class="fa fa-tag"></i> docker</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/2018/12/05/CentOS-7-6-1810-虚拟机模板制作.html" rel="next" title="CentOS-7.6(1810)虚拟机模板制作"><i class="fa fa-chevron-left"></i> CentOS-7.6(1810)虚拟机模板制作</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/2018/12/11/使用Docker打包shadowsocks-libev镜像.html" rel="prev" title="使用Docker打包shadowsocks-libev镜像">使用Docker打包shadowsocks-libev镜像 <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"></div></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" src="/images/avatar.png" alt="乱愣黎"><p class="site-author-name" itemprop="name">乱愣黎</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">20</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/index.html"><span class="site-state-item-count">1</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">20</span> <span class="site-state-item-name">标签</span></a></div></nav><div class="links-of-author motion-element"><span class="links-of-author-item"><a href="https://github.com/luanlengli" target="_blank" title="GitHub"><i class="fa fa-fw fa-globe"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:huangbopei@gmail.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-globe"></i>E-Mail</a></span></div></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#更新记录"><span class="nav-number">1.</span> <span class="nav-text">更新记录</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#介绍"><span class="nav-number">2.</span> <span class="nav-text">介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#参考博文"><span class="nav-number">2.1.</span> <span class="nav-text">参考博文</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#软件版本"><span class="nav-number">2.2.</span> <span class="nav-text">软件版本</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#网络信息"><span class="nav-number">2.3.</span> <span class="nav-text">网络信息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#节点信息"><span class="nav-number">2.4.</span> <span class="nav-text">节点信息</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#目录说明"><span class="nav-number">2.5.</span> <span class="nav-text">目录说明</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#事前准备"><span class="nav-number">3.</span> <span class="nav-text">事前准备</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#定义集群变量"><span class="nav-number">4.</span> <span class="nav-text">定义集群变量</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#下载所需软件包"><span class="nav-number">5.</span> <span class="nav-text">下载所需软件包</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#生成集群Key和Certificates"><span class="nav-number">6.</span> <span class="nav-text">生成集群Key和Certificates</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#说明"><span class="nav-number">6.1.</span> <span class="nav-text">说明</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#下载CFSSL工具"><span class="nav-number">6.2.</span> <span class="nav-text">下载CFSSL工具</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#创建工作目录"><span class="nav-number">6.3.</span> <span class="nav-text">创建工作目录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#创建用于生成证书的json文件"><span class="nav-number">6.4.</span> <span class="nav-text">创建用于生成证书的json文件</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ca-config-json"><span class="nav-number">6.4.1.</span> <span class="nav-text">ca-config.json</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#ca-csr-json"><span class="nav-number">6.4.2.</span> <span class="nav-text">ca-csr.json</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#etcd-ca-csr-json"><span class="nav-number">6.4.3.</span> <span class="nav-text">etcd-ca-csr.json</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#etcd-server-csr-json"><span class="nav-number">6.4.4.</span> <span class="nav-text">etcd-server-csr.json</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#etcd-client-csr-json"><span class="nav-number">6.4.5.</span> <span class="nav-text">etcd-client-csr.json</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-apiserver-csr-json"><span class="nav-number">6.4.6.</span> <span class="nav-text">kube-apiserver-csr.json</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-manager-csr-json"><span class="nav-number">6.4.7.</span> <span class="nav-text">kube-manager-csr.json</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-scheduler-csr-json"><span class="nav-number">6.4.8.</span> <span class="nav-text">kube-scheduler-csr.json</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-proxy-csr-json"><span class="nav-number">6.4.9.</span> <span class="nav-text">kube-proxy-csr.json</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-admin-csr-json"><span class="nav-number">6.4.10.</span> <span class="nav-text">kube-admin-csr.json</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#front-proxy-ca-csr-json"><span class="nav-number">6.4.11.</span> <span class="nav-text">front-proxy-ca-csr.json</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#front-proxy-client-csr-json"><span class="nav-number">6.4.12.</span> <span class="nav-text">front-proxy-client-csr.json</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#sa-csr-json"><span class="nav-number">6.4.13.</span> <span class="nav-text">sa-csr.json</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#创建etcd证书"><span class="nav-number">6.5.</span> <span class="nav-text">创建etcd证书</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#etcd-ca证书"><span class="nav-number">6.5.1.</span> <span class="nav-text">etcd-ca证书</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#etcd-server证书"><span class="nav-number">6.5.2.</span> <span class="nav-text">etcd-server证书</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#etcd-client证书"><span class="nav-number">6.5.3.</span> <span class="nav-text">etcd-client证书</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#创建kubernetes证书"><span class="nav-number">6.6.</span> <span class="nav-text">创建kubernetes证书</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#kubernetes-CA-证书"><span class="nav-number">6.6.1.</span> <span class="nav-text">kubernetes-CA 证书</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-apiserver证书"><span class="nav-number">6.6.2.</span> <span class="nav-text">kube-apiserver证书</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-controller-manager证书"><span class="nav-number">6.6.3.</span> <span class="nav-text">kube-controller-manager证书</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-scheduler证书"><span class="nav-number">6.6.4.</span> <span class="nav-text">kube-scheduler证书</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-proxy证书"><span class="nav-number">6.6.5.</span> <span class="nav-text">kube-proxy证书</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-admin证书"><span class="nav-number">6.6.6.</span> <span class="nav-text">kube-admin证书</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Front-Proxy证书"><span class="nav-number">6.6.7.</span> <span class="nav-text">Front Proxy证书</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Service-Account证书"><span class="nav-number">6.6.8.</span> <span class="nav-text">Service Account证书</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bootstrap-token"><span class="nav-number">6.6.9.</span> <span class="nav-text">bootstrap-token</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#encryption-yaml"><span class="nav-number">6.6.10.</span> <span class="nav-text">encryption.yaml</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#audit-policy-yaml"><span class="nav-number">6.6.11.</span> <span class="nav-text">audit-policy.yaml</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#创建kubeconfig文件"><span class="nav-number">6.7.</span> <span class="nav-text">创建kubeconfig文件</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#说明-1"><span class="nav-number">6.7.1.</span> <span class="nav-text">说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-controller-manager-kubeconfig"><span class="nav-number">6.7.2.</span> <span class="nav-text">kube-controller-manager.kubeconfig</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-scheduler-kubeconfig"><span class="nav-number">6.7.3.</span> <span class="nav-text">kube-scheduler.kubeconfig</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-proxy-kubeconfig"><span class="nav-number">6.7.4.</span> <span class="nav-text">kube-proxy.kubeconfig</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-admin-kubeconfig"><span class="nav-number">6.7.5.</span> <span class="nav-text">kube-admin.kubeconfig</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#bootstrap-kubeconfig"><span class="nav-number">6.7.6.</span> <span class="nav-text">bootstrap.kubeconfig</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#清理证书CSR文件"><span class="nav-number">6.7.7.</span> <span class="nav-text">清理证书CSR文件</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#修改文件权限"><span class="nav-number">6.8.</span> <span class="nav-text">修改文件权限</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#检查生成的文件"><span class="nav-number">6.9.</span> <span class="nav-text">检查生成的文件</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#kubernetes-master节点"><span class="nav-number">7.</span> <span class="nav-text">kubernetes-master节点</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#master节点说明"><span class="nav-number">7.1.</span> <span class="nav-text">master节点说明</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#添加用户"><span class="nav-number">7.2.</span> <span class="nav-text">添加用户</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#创建目录"><span class="nav-number">7.3.</span> <span class="nav-text">创建目录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分发证书文件和kubeconfig到master节点"><span class="nav-number">7.4.</span> <span class="nav-text">分发证书文件和kubeconfig到master节点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分发二进制文件"><span class="nav-number">7.5.</span> <span class="nav-text">分发二进制文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#部署配置Keepalived和HAProxy"><span class="nav-number">7.6.</span> <span class="nav-text">部署配置Keepalived和HAProxy</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#切换工作目录"><span class="nav-number">7.6.1.</span> <span class="nav-text">切换工作目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装Keepalived和HAProxy"><span class="nav-number">7.6.2.</span> <span class="nav-text">安装Keepalived和HAProxy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#配置keepalived"><span class="nav-number">7.6.3.</span> <span class="nav-text">配置keepalived</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#配置haproxy"><span class="nav-number">7.6.4.</span> <span class="nav-text">配置haproxy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分发配置文件到master节点"><span class="nav-number">7.6.5.</span> <span class="nav-text">分发配置文件到master节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动keepalived和haproxy"><span class="nav-number">7.6.6.</span> <span class="nav-text">启动keepalived和haproxy</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#验证VIP"><span class="nav-number">7.6.7.</span> <span class="nav-text">验证VIP</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#部署etcd集群"><span class="nav-number">7.7.</span> <span class="nav-text">部署etcd集群</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#配置etcd-service文件"><span class="nav-number">7.7.1.</span> <span class="nav-text">配置etcd.service文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#etcd-config-yaml模板"><span class="nav-number">7.7.2.</span> <span class="nav-text">etcd.config.yaml模板</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分发配置文件"><span class="nav-number">7.7.3.</span> <span class="nav-text">分发配置文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动etcd集群"><span class="nav-number">7.7.4.</span> <span class="nav-text">启动etcd集群</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#验证etcd集群状态"><span class="nav-number">7.7.5.</span> <span class="nav-text">验证etcd集群状态</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Master组件服务"><span class="nav-number">7.8.</span> <span class="nav-text">Master组件服务</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#master组件配置模板"><span class="nav-number">7.8.1.</span> <span class="nav-text">master组件配置模板</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#kube-apiserver-conf"><span class="nav-number">7.8.1.1.</span> <span class="nav-text">kube-apiserver.conf</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#kube-controller-manager-conf"><span class="nav-number">7.8.1.2.</span> <span class="nav-text">kube-controller-manager.conf</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#kube-scheduler-conf"><span class="nav-number">7.8.1.3.</span> <span class="nav-text">kube-scheduler.conf</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#systemd服务文件"><span class="nav-number">7.8.2.</span> <span class="nav-text">systemd服务文件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#kube-apiserver-service"><span class="nav-number">7.8.2.1.</span> <span class="nav-text">kube-apiserver.service</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#kube-controller-manager-service"><span class="nav-number">7.8.2.2.</span> <span class="nav-text">kube-controller-manager.service</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#kube-scheduler-service"><span class="nav-number">7.8.2.3.</span> <span class="nav-text">kube-scheduler.service</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#分发配置文件到各master节点"><span class="nav-number">7.8.3.</span> <span class="nav-text">分发配置文件到各master节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#启动kubernetes服务"><span class="nav-number">7.8.4.</span> <span class="nav-text">启动kubernetes服务</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#设置kubectl"><span class="nav-number">7.8.5.</span> <span class="nav-text">设置kubectl</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#设置命令补全"><span class="nav-number">7.8.6.</span> <span class="nav-text">设置命令补全</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#设置kubelet的bootstrap启动所需的RBAC"><span class="nav-number">7.8.7.</span> <span class="nav-text">设置kubelet的bootstrap启动所需的RBAC</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#创建工作目录-1"><span class="nav-number">7.8.7.1.</span> <span class="nav-text">创建工作目录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#kubelet-bootstrap-rbac-yaml"><span class="nav-number">7.8.7.2.</span> <span class="nav-text">kubelet-bootstrap-rbac.yaml</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#tls-bootstrap-clusterrole-yaml"><span class="nav-number">7.8.7.3.</span> <span class="nav-text">tls-bootstrap-clusterrole.yaml</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#node-client-auto-approve-csr-yaml"><span class="nav-number">7.8.7.4.</span> <span class="nav-text">node-client-auto-approve-csr.yaml</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#node-client-auto-renew-crt-yaml"><span class="nav-number">7.8.7.5.</span> <span class="nav-text">node-client-auto-renew-crt.yaml</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#node-server-auto-renew-crt-yaml"><span class="nav-number">7.8.7.6.</span> <span class="nav-text">node-server-auto-renew-crt.yaml</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建tls-bootstrap-rbac"><span class="nav-number">7.8.7.7.</span> <span class="nav-text">创建tls-bootstrap-rbac</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#设置kube-apiserver获取node信息的权限"><span class="nav-number">7.8.8.</span> <span class="nav-text">设置kube-apiserver获取node信息的权限</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#说明-2"><span class="nav-number">7.8.8.1.</span> <span class="nav-text">说明</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建yaml文件"><span class="nav-number">7.8.8.2.</span> <span class="nav-text">创建yaml文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建RBAC"><span class="nav-number">7.8.8.3.</span> <span class="nav-text">创建RBAC</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#kubernetes-worker节点"><span class="nav-number">8.</span> <span class="nav-text">kubernetes worker节点</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#worker节点说明"><span class="nav-number">8.1.</span> <span class="nav-text">worker节点说明</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#切换工作目录-1"><span class="nav-number">8.2.</span> <span class="nav-text">切换工作目录</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#worker组件配置模板"><span class="nav-number">8.3.</span> <span class="nav-text">worker组件配置模板</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet-conf"><span class="nav-number">8.3.1.</span> <span class="nav-text">kubelet.conf</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet-config-file"><span class="nav-number">8.3.2.</span> <span class="nav-text">kubelet.config.file</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-proxy-conf"><span class="nav-number">8.3.3.</span> <span class="nav-text">kube-proxy.conf</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-proxy-config-file"><span class="nav-number">8.3.4.</span> <span class="nav-text">kube-proxy.config.file</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#systemd服务文件-1"><span class="nav-number">8.4.</span> <span class="nav-text">systemd服务文件</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#kubelet-service"><span class="nav-number">8.4.1.</span> <span class="nav-text">kubelet.service</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-proxy-service"><span class="nav-number">8.4.2.</span> <span class="nav-text">kube-proxy.service</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分发证书和kubeconfig文件"><span class="nav-number">8.5.</span> <span class="nav-text">分发证书和kubeconfig文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分发二进制文件-1"><span class="nav-number">8.6.</span> <span class="nav-text">分发二进制文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分发配置文件和服务文件"><span class="nav-number">8.7.</span> <span class="nav-text">分发配置文件和服务文件</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#启动服务"><span class="nav-number">8.8.</span> <span class="nav-text">启动服务</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#获取节点信息"><span class="nav-number">8.9.</span> <span class="nav-text">获取节点信息</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#kubernetes-Core-Addons"><span class="nav-number">9.</span> <span class="nav-text">kubernetes Core Addons</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#网络组件部署（二选其一）"><span class="nav-number">9.1.</span> <span class="nav-text">网络组件部署（二选其一）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#创建工作目录-2"><span class="nav-number">9.1.1.</span> <span class="nav-text">创建工作目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#kube-flannel"><span class="nav-number">9.1.2.</span> <span class="nav-text">kube-flannel</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#说明-3"><span class="nav-number">9.1.2.1.</span> <span class="nav-text">说明</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#架构图"><span class="nav-number">9.1.2.2.</span> <span class="nav-text">架构图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#切换工作目录-2"><span class="nav-number">9.1.2.3.</span> <span class="nav-text">切换工作目录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#下载yaml文件"><span class="nav-number">9.1.2.4.</span> <span class="nav-text">下载yaml文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#修改backend"><span class="nav-number">9.1.2.5.</span> <span class="nav-text">修改backend</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#部署kube-flannel"><span class="nav-number">9.1.2.6.</span> <span class="nav-text">部署kube-flannel</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#检查部署情况"><span class="nav-number">9.1.2.7.</span> <span class="nav-text">检查部署情况</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Calico"><span class="nav-number">9.1.3.</span> <span class="nav-text">Calico</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#说明-4"><span class="nav-number">9.1.3.1.</span> <span class="nav-text">说明</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#架构图-1"><span class="nav-number">9.1.3.2.</span> <span class="nav-text">架构图</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#切换工作目录-3"><span class="nav-number">9.1.3.3.</span> <span class="nav-text">切换工作目录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#下载yaml文件-1"><span class="nav-number">9.1.3.4.</span> <span class="nav-text">下载yaml文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#部署Calico"><span class="nav-number">9.1.3.5.</span> <span class="nav-text">部署Calico</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#检查部署情况-1"><span class="nav-number">9.1.3.6.</span> <span class="nav-text">检查部署情况</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#检查节点状态"><span class="nav-number">9.1.4.</span> <span class="nav-text">检查节点状态</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#服务发现组件部署"><span class="nav-number">9.2.</span> <span class="nav-text">服务发现组件部署</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#创建工作目录-3"><span class="nav-number">9.2.1.</span> <span class="nav-text">创建工作目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CoreDNS"><span class="nav-number">9.2.2.</span> <span class="nav-text">CoreDNS</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#创建yaml文件-1"><span class="nav-number">9.2.2.1.</span> <span class="nav-text">创建yaml文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#修改yaml文件"><span class="nav-number">9.2.2.2.</span> <span class="nav-text">修改yaml文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#部署CoreDNS"><span class="nav-number">9.2.2.3.</span> <span class="nav-text">部署CoreDNS</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#检查部署状态"><span class="nav-number">9.2.2.4.</span> <span class="nav-text">检查部署状态</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#验证集群DNS服务"><span class="nav-number">9.2.3.</span> <span class="nav-text">验证集群DNS服务</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Metrics-Server"><span class="nav-number">9.3.</span> <span class="nav-text">Metrics Server</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#额外参数"><span class="nav-number">9.3.1.</span> <span class="nav-text">额外参数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建工作目录-4"><span class="nav-number">9.3.2.</span> <span class="nav-text">创建工作目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#切换工作目录-4"><span class="nav-number">9.3.3.</span> <span class="nav-text">切换工作目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#下载yaml文件-2"><span class="nav-number">9.3.4.</span> <span class="nav-text">下载yaml文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建metrics-server-deployment-yaml"><span class="nav-number">9.3.5.</span> <span class="nav-text">创建metrics-server-deployment.yaml</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#部署metrics-server"><span class="nav-number">9.3.6.</span> <span class="nav-text">部署metrics-server</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#查看pod状态"><span class="nav-number">9.3.7.</span> <span class="nav-text">查看pod状态</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#验证metrics"><span class="nav-number">9.3.8.</span> <span class="nav-text">验证metrics</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#至此集群已具备基本功能"><span class="nav-number">10.</span> <span class="nav-text">至此集群已具备基本功能</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#kubernetes-Extra-Addons"><span class="nav-number">11.</span> <span class="nav-text">kubernetes Extra Addons</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Dashboard"><span class="nav-number">11.1.</span> <span class="nav-text">Dashboard</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#创建工作目录-5"><span class="nav-number">11.1.1.</span> <span class="nav-text">创建工作目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#切换工作目录-5"><span class="nav-number">11.1.2.</span> <span class="nav-text">切换工作目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#获取yaml文件"><span class="nav-number">11.1.3.</span> <span class="nav-text">获取yaml文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#修改镜像地址"><span class="nav-number">11.1.4.</span> <span class="nav-text">修改镜像地址</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建kubernetes-Dashboard"><span class="nav-number">11.1.5.</span> <span class="nav-text">创建kubernetes-Dashboard</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建ServiceAccount-RBAC"><span class="nav-number">11.1.6.</span> <span class="nav-text">创建ServiceAccount RBAC</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#获取ServiceAccount的Token"><span class="nav-number">11.1.7.</span> <span class="nav-text">获取ServiceAccount的Token</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#查看部署情况"><span class="nav-number">11.1.8.</span> <span class="nav-text">查看部署情况</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#访问Dashboard"><span class="nav-number">11.1.9.</span> <span class="nav-text">访问Dashboard</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Dashboard-UI预览图"><span class="nav-number">11.1.10.</span> <span class="nav-text">Dashboard UI预览图</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Ingress-Controller"><span class="nav-number">11.2.</span> <span class="nav-text">Ingress Controller</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#创建工作目录-6"><span class="nav-number">11.2.1.</span> <span class="nav-text">创建工作目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#切换工作目录-6"><span class="nav-number">11.2.2.</span> <span class="nav-text">切换工作目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#下载yaml文件-3"><span class="nav-number">11.2.3.</span> <span class="nav-text">下载yaml文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#修改镜像地址-1"><span class="nav-number">11.2.4.</span> <span class="nav-text">修改镜像地址</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建ingress-nginx"><span class="nav-number">11.2.5.</span> <span class="nav-text">创建ingress-nginx</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#检查部署情况-2"><span class="nav-number">11.2.6.</span> <span class="nav-text">检查部署情况</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#访问ingress"><span class="nav-number">11.2.7.</span> <span class="nav-text">访问ingress</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建kubernetes-Dashboard的Ingress"><span class="nav-number">11.2.8.</span> <span class="nav-text">创建kubernetes-Dashboard的Ingress</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#创建HTTPS证书"><span class="nav-number">11.2.8.1.</span> <span class="nav-text">创建HTTPS证书</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建secret对象"><span class="nav-number">11.2.8.2.</span> <span class="nav-text">创建secret对象</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建dashboard-ingress-yaml"><span class="nav-number">11.2.8.3.</span> <span class="nav-text">创建dashboard-ingress.yaml</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建ingress"><span class="nav-number">11.2.8.4.</span> <span class="nav-text">创建ingress</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#检查ingress"><span class="nav-number">11.2.8.5.</span> <span class="nav-text">检查ingress</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#访问kubernetes-Dashboard"><span class="nav-number">11.2.8.6.</span> <span class="nav-text">访问kubernetes-Dashboard</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Helm"><span class="nav-number">11.3.</span> <span class="nav-text">Helm</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#环境要求"><span class="nav-number">11.3.1.</span> <span class="nav-text">环境要求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装客户端"><span class="nav-number">11.3.2.</span> <span class="nav-text">安装客户端</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#直接脚本安装"><span class="nav-number">11.3.2.1.</span> <span class="nav-text">直接脚本安装</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#下载二进制文件安装"><span class="nav-number">11.3.2.2.</span> <span class="nav-text">下载二进制文件安装</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建工作目录-7"><span class="nav-number">11.3.3.</span> <span class="nav-text">创建工作目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#切换工作目录-7"><span class="nav-number">11.3.4.</span> <span class="nav-text">切换工作目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#创建RBAC规则"><span class="nav-number">11.3.5.</span> <span class="nav-text">创建RBAC规则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装服务端"><span class="nav-number">11.3.6.</span> <span class="nav-text">安装服务端</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#检查安装情况"><span class="nav-number">11.3.7.</span> <span class="nav-text">检查安装情况</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#添加命令行补全"><span class="nav-number">11.3.8.</span> <span class="nav-text">添加命令行补全</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Rook（测试用途）"><span class="nav-number">11.4.</span> <span class="nav-text">Rook（测试用途）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#说明-5"><span class="nav-number">11.4.1.</span> <span class="nav-text">说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Rook与kubernetes的集成"><span class="nav-number">11.4.2.</span> <span class="nav-text">Rook与kubernetes的集成</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Rook架构图"><span class="nav-number">11.4.3.</span> <span class="nav-text">Rook架构图</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#安装"><span class="nav-number">11.4.4.</span> <span class="nav-text">安装</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#创建工作目录-8"><span class="nav-number">11.4.4.1.</span> <span class="nav-text">创建工作目录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#进入工作目录"><span class="nav-number">11.4.4.2.</span> <span class="nav-text">进入工作目录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#下载yaml文件-4"><span class="nav-number">11.4.4.3.</span> <span class="nav-text">下载yaml文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#部署operator"><span class="nav-number">11.4.4.4.</span> <span class="nav-text">部署operator</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#检查operator安装情况"><span class="nav-number">11.4.4.5.</span> <span class="nav-text">检查operator安装情况</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#部署cluster"><span class="nav-number">11.4.4.6.</span> <span class="nav-text">部署cluster</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#检查cluster部署情况"><span class="nav-number">11.4.4.7.</span> <span class="nav-text">检查cluster部署情况</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#检查ceph集群状态"><span class="nav-number">11.4.4.8.</span> <span class="nav-text">检查ceph集群状态</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#暴露ceph-mgr的dashboard"><span class="nav-number">11.4.5.</span> <span class="nav-text">暴露ceph-mgr的dashboard</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#访问已暴露的dashboard"><span class="nav-number">11.4.6.</span> <span class="nav-text">访问已暴露的dashboard</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#添加StorageClass"><span class="nav-number">11.4.7.</span> <span class="nav-text">添加StorageClass</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#检查StorageClass"><span class="nav-number">11.4.8.</span> <span class="nav-text">检查StorageClass</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#卸载Rook-ceph"><span class="nav-number">11.4.9.</span> <span class="nav-text">卸载Rook-ceph</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#删除StorageClass"><span class="nav-number">11.4.9.1.</span> <span class="nav-text">删除StorageClass</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#删除Rook-Ceph-Cluster"><span class="nav-number">11.4.9.2.</span> <span class="nav-text">删除Rook-Ceph-Cluster</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#删除Rook-Operator"><span class="nav-number">11.4.9.3.</span> <span class="nav-text">删除Rook-Operator</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#清理目录"><span class="nav-number">11.4.9.4.</span> <span class="nav-text">清理目录</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Prometheus-Operator"><span class="nav-number">11.5.</span> <span class="nav-text">Prometheus Operator</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#说明-6"><span class="nav-number">11.5.1.</span> <span class="nav-text">说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Prometheus"><span class="nav-number">11.5.2.</span> <span class="nav-text">Prometheus</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Prometheus组成架构"><span class="nav-number">11.5.2.1.</span> <span class="nav-text">Prometheus组成架构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#架构图-2"><span class="nav-number">11.5.2.2.</span> <span class="nav-text">架构图</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Operator架构"><span class="nav-number">11.5.3.</span> <span class="nav-text">Operator架构</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#部署Prometheus-Operator"><span class="nav-number">11.5.4.</span> <span class="nav-text">部署Prometheus-Operator</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#切换工作目录-8"><span class="nav-number">11.5.4.1.</span> <span class="nav-text">切换工作目录</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#添加coreos源"><span class="nav-number">11.5.4.2.</span> <span class="nav-text">添加coreos源</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#创建命名空间"><span class="nav-number">11.5.4.3.</span> <span class="nav-text">创建命名空间</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#部署prometheus-operator"><span class="nav-number">11.5.4.4.</span> <span class="nav-text">部署prometheus-operator</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#部署kube-prometheus"><span class="nav-number">11.5.4.5.</span> <span class="nav-text">部署kube-prometheus</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#检查部署情况-3"><span class="nav-number">11.5.4.6.</span> <span class="nav-text">检查部署情况</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#访问Prometheus-Operator"><span class="nav-number">11.5.5.</span> <span class="nav-text">访问Prometheus-Operator</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#EFK"><span class="nav-number">11.6.</span> <span class="nav-text">EFK</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#说明-7"><span class="nav-number">11.6.1.</span> <span class="nav-text">说明</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#注意"><span class="nav-number">11.6.2.</span> <span class="nav-text">注意</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#解压源代码"><span class="nav-number">11.6.3.</span> <span class="nav-text">解压源代码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#切换工作目录-9"><span class="nav-number">11.6.4.</span> <span class="nav-text">切换工作目录</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#修改yaml文件-1"><span class="nav-number">11.6.5.</span> <span class="nav-text">修改yaml文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#修改镜像地址-2"><span class="nav-number">11.6.6.</span> <span class="nav-text">修改镜像地址</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#给节点打Label"><span class="nav-number">11.6.7.</span> <span class="nav-text">给节点打Label</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#部署EFK"><span class="nav-number">11.6.8.</span> <span class="nav-text">部署EFK</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#查看部署情况-1"><span class="nav-number">11.6.9.</span> <span class="nav-text">查看部署情况</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#访问EFK"><span class="nav-number">11.6.10.</span> <span class="nav-text">访问EFK</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#在github上获取yaml文件"><span class="nav-number">11.6.11.</span> <span class="nav-text">在github上获取yaml文件</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#本文至此结束"><span class="nav-number">12.</span> <span class="nav-text">本文至此结束</span></a></li></ol></div></div></section><div class="back-to-top"><i class="fa fa-arrow-up"></i> <span id="scrollpercent"><span>0</span>%</span></div></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2019</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">乱愣黎</span> <span class="post-meta-divider">|</span> <span class="post-meta-item-icon"><i class="fa fa-area-chart"></i> </span><span class="post-meta-item-text">Site words total count&#58;</span> <span title="Site words total count">59.3k</span></div><div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div><span class="post-meta-divider">|</span><div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div></div></footer></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script><script type="text/javascript">// Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });</script><script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script><script>AV.initialize("Ud2l4uLerav3PFrmAnVI4tDz-gzGzoHsz","vy29JxqPATrJXMXqS1I3nlg1")</script><script>function showTime(e){var t=new AV.Query(e),c=[],u=$(".leancloud_visitors");u.each(function(){c.push($(this).attr("id").trim())}),t.containedIn("url",c),t.find().done(function(e){var t=".leancloud-visitors-count";if(0!==e.length){for(var n=0;n<e.length;n++){var o=e[n],i=o.get("url"),s=o.get("time"),r=document.getElementById(i);$(r).find(t).text(s)}for(n=0;n<c.length;n++){i=c[n],r=document.getElementById(i);var l=$(r).find(t);""==l.text()&&l.text(0)}}else u.find(t).text(0)}).fail(function(e,t){console.log("Error: "+t.code+" "+t.message)})}function addCount(i){var e=$(".leancloud_visitors"),s=e.attr("id").trim(),r=e.attr("data-flag-title").trim(),t=new AV.Query(i);t.equalTo("url",s),t.find({success:function(e){if(0<e.length){var t=e[0];t.fetchWhenSave(!0),t.increment("time"),t.save(null,{success:function(e){$(document.getElementById(s)).find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to save Visitor num, with error message: "+t.message)}})}else{var n=new i,o=new AV.ACL;o.setPublicReadAccess(!0),o.setPublicWriteAccess(!0),n.setACL(o),n.set("title",r),n.set("url",s),n.set("time",1),n.save(null,{success:function(e){$(document.getElementById(s)).find(".leancloud-visitors-count").text(e.get("time"))},error:function(e,t){console.log("Failed to create")}})}},error:function(e){console.log("Error:"+e.code+" "+e.message)}})}$(function(){var e=AV.Object.extend("Counter");1==$(".leancloud_visitors").length?addCount(e):1<$(".post-title-link").length&&showTime(e)})</script></body></html>